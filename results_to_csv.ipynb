{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Template to Quickly Test Things Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists\n",
    "# from parse_config import ConfigParser\n",
    "# from data_loader import data_loaders\n",
    "# import model.model as module_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants, paths\n",
    "# config_path = 'configs/'\n",
    "load_dir = 'saved/edit/trials/CINIC10_ImageNet-VGG_16/0110_120730/dog-train-n02114712_211/felzenszwalb_gaussian_0/models'\n",
    "knn_analysis_results_path = os.path.join(load_dir, 'knn_analysis_results.pth')\n",
    "pre_edit_path = os.path.join(load_dir, 'pre_edit_metrics.pth')\n",
    "post_edit_path = os.path.join(load_dir, 'post_edit_metrics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "knn_analysis = torch.load(knn_analysis_results_path)\n",
    "pre_edit_metrics = torch.load(pre_edit_path)\n",
    "post_edit_metrics = torch.load(post_edit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file, models, and dataloader\n",
    "# config_json = read_json(config_path)\n",
    "# config = ConfigParser(config_json)\n",
    "\n",
    "# device, device_ids = prepare_device(config['n_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "# data_loader_args = dict(config.config[\"data_loader\"][\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# layernum = config.config['layernum']\n",
    "# model = config.init_obj('arch', module_arch, layernum=layernum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dictionaries(data_id,\n",
    "                         knn_analysis=None,\n",
    "                         pre_edit_metrics=None,\n",
    "                         post_edit_metrics=None,\n",
    "                         target_class_idx=None,\n",
    "                         original_class_idx=None):\n",
    "    '''\n",
    "    Given list of dictionaries, combine into 1 dictionary\n",
    "\n",
    "    Arg(s):\n",
    "        knn_analysis : dict{str : any}\n",
    "            dictionary of results from knn_analysis.ipynb\n",
    "        pre_edit_metrics : dict{str : any}\n",
    "            dictionary of pre edit metrics\n",
    "        post_edit_metrics : dict{str : any}\n",
    "            dictionary of post edit metrics\n",
    "\n",
    "    Returns:\n",
    "        master_dict : dict{str: any}\n",
    "    '''\n",
    "    master_dict = {}\n",
    "\n",
    "    master_dict['ID'] = data_id\n",
    "    # Data from metric dictionaries\n",
    "    if pre_edit_metrics is not None and post_edit_metrics is not None:\n",
    "        # Store Accuracy\n",
    "        master_dict['Pre Accuracy'] = pre_edit_metrics['accuracy']\n",
    "        master_dict['Post Accuracy'] = post_edit_metrics['accuracy']\n",
    "\n",
    "        # Store Mean Precision\n",
    "        master_dict['Pre Mean Precision'] = pre_edit_metrics['precision_mean']\n",
    "        master_dict['Post Mean Precision'] = post_edit_metrics['precision_mean']\n",
    "\n",
    "        # Store Mean Recall\n",
    "        master_dict['Pre Mean Recall'] = pre_edit_metrics['recall_mean']\n",
    "        master_dict['Post Mean Recall'] = post_edit_metrics['recall_mean']\n",
    "\n",
    "        # Store Mean F1\n",
    "        master_dict['Pre Mean F1'] = pre_edit_metrics['f1_mean']\n",
    "        master_dict['Post Mean F1'] = post_edit_metrics['f1_mean']\n",
    "\n",
    "        if target_class_idx is not None:\n",
    "            # Store Target Precision\n",
    "            master_dict['Pre Target Precision'] = pre_edit_metrics['precision'][target_class_idx]\n",
    "            master_dict['Post Target Precision'] = post_edit_metrics['precision'][target_class_idx]\n",
    "\n",
    "            # Store Target Recall\n",
    "            master_dict['Pre Target Recall'] = pre_edit_metrics['recall'][target_class_idx]\n",
    "            master_dict['Post Target Recall'] = post_edit_metrics['recall'][target_class_idx]\n",
    "\n",
    "            # Store Target F1\n",
    "            master_dict['Pre Target F1'] = pre_edit_metrics['f1'][target_class_idx]\n",
    "            master_dict['Post Target F1'] = post_edit_metrics['f1'][target_class_idx]\n",
    "        if original_class_idx is not None:\n",
    "            # Store Incorrect Class Precision\n",
    "            master_dict['Pre Orig Pred Precision'] = pre_edit_metrics['precision'][original_class_idx]\n",
    "            master_dict['Post Orig Pred Precision'] = post_edit_metrics['precision'][original_class_idx]\n",
    "\n",
    "            # Store Target Recall\n",
    "            master_dict['Pre Orig Pred Recall'] = pre_edit_metrics['recall'][original_class_idx]\n",
    "            master_dict['Post Orig Pred Recall'] = post_edit_metrics['recall'][original_class_idx]\n",
    "\n",
    "            # Store Target F1\n",
    "            master_dict['Pre Orig Pred F1'] = pre_edit_metrics['f1'][original_class_idx]\n",
    "            master_dict['Post Orig Pred F1'] = post_edit_metrics['f1'][original_class_idx]\n",
    "\n",
    "    # Data from knn analysis dictionaries\n",
    "    if knn_analysis is not None:\n",
    "        # Examine Prediction Shifts\n",
    "        prediction_changes = knn_analysis['prediction_changes']\n",
    "\n",
    "        # Predictions of key and value\n",
    "        master_dict['Pre key Prediction'] = prediction_changes['pre_key_prediction']\n",
    "        master_dict[\"Post key Prediction\"] = prediction_changes['post_key_prediction']\n",
    "        master_dict['Pre val Prediction'] = prediction_changes['pre_val_prediction']\n",
    "        master_dict[\"Post val Prediction\"] = prediction_changes['post_val_prediction']\n",
    "\n",
    "        # Number of neighbors that became target\n",
    "        master_dict[\"Num of key's Neighbors Became Target (F)\"] = prediction_changes['features_key']['n_changed_to_target']\n",
    "        master_dict[\"Num of key's Neighbors Became Target (L)\"] = prediction_changes['logits_key']['n_changed_to_target']\n",
    "        master_dict[\"Num of val's Neighbors Became Target (F)\"] = prediction_changes['features_value']['n_changed_to_target']\n",
    "        master_dict[\"Num of val's Neighbors Became Target (L)\"] = prediction_changes['logits_value']['n_changed_to_target']\n",
    "\n",
    "        # Examine Distances\n",
    "        distances = knn_analysis['distance_results']\n",
    "\n",
    "        # Distance between key-val\n",
    "        master_dict[\"Pre key-val (F)\"] = distances['features']['key_val'][0]\n",
    "        master_dict[\"Post key-val (F)\"] = distances['features']['key_val'][1]\n",
    "        master_dict[\"Pre key-val (L)\"] = distances['logits']['key_val'][0]\n",
    "        master_dict[\"Post key-val (L)\"] = distances['logits']['key_val'][1]\n",
    "\n",
    "        # Distance between key's neighbors -> B\n",
    "        master_dict[\"Pre keyN-val (F)\"] = distances['features']['val_keyN'][0]\n",
    "        master_dict[\"Post keyN-val (F)\"] = distances['features']['val_keyN'][1]\n",
    "        master_dict[\"Pre keyN-val (L)\"] = distances['logits']['val_keyN'][0]\n",
    "        master_dict[\"Post keyN-val (L)\"] = distances['logits']['val_keyN'][1]\n",
    "\n",
    "    return master_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics(df, data_dictionary, keys, row=None):\n",
    "    '''\n",
    "    Given an existing dataframe, add the data in data_dictionary specified by keys\n",
    "    \n",
    "    Arg(s):\n",
    "        df : pandas.datafraome\n",
    "            current data frame of data\n",
    "        data_dictionary : dict{str : any}\n",
    "            dictionary of current data\n",
    "        keys : list[str]\n",
    "            list of keys (stored like paths) showing which data to access\n",
    "        row : int or None\n",
    "            index of which row to update or None if add new row\n",
    "            \n",
    "    Returns: \n",
    "        df : pandas.dataframe\n",
    "            updated data frame\n",
    "    '''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedal to the metal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog-train-n02114712_211/felzenszwalb_gaussian_0\n",
      "(2, 37)\n"
     ]
    }
   ],
   "source": [
    "# Combine dictionaries\n",
    "id_ = os.path.basename(os.path.dirname(os.path.dirname(load_dir))) + \"/\" + os.path.basename(os.path.dirname(load_dir))\n",
    "print(id_)\n",
    "master_dictionary = combine_dictionaries(\n",
    "    data_id=id_,\n",
    "    knn_analysis=knn_analysis,\n",
    "    pre_edit_metrics=pre_edit_metrics,\n",
    "    post_edit_metrics=post_edit_metrics,\n",
    "    target_class_idx=5,\n",
    "    original_class_idx=6)\n",
    "\n",
    "column_headers = list(master_dictionary.keys())\n",
    "values = np.expand_dims(np.array(list(master_dictionary.values())), axis=0)\n",
    "values = np.concatenate([values, values], axis=0)\n",
    "print(values.shape)\n",
    "df = pd.DataFrame(values, columns=column_headers)\n",
    "\n",
    "# Create a dataframe\n",
    "# df = pd.DataFrame(master_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Pre Accuracy', 'Post Accuracy', 'Pre Mean Precision',\n",
      "       'Post Mean Precision', 'Pre Mean Recall', 'Post Mean Recall',\n",
      "       'Pre Mean F1', 'Post Mean F1', 'Pre Target Precision',\n",
      "       'Post Target Precision', 'Pre Target Recall', 'Post Target Recall',\n",
      "       'Pre Target F1', 'Post Target F1', 'Pre Orig Pred Precision',\n",
      "       'Post Orig Pred Precision', 'Pre Orig Pred Recall',\n",
      "       'Post Orig Pred Recall', 'Pre Orig Pred F1', 'Post Orig Pred F1',\n",
      "       'Pre key Prediction', 'Post key Prediction', 'Pre val Prediction',\n",
      "       'Post val Prediction', 'Num of key's Neighbors Became Target (F)',\n",
      "       'Num of key's Neighbors Became Target (L)',\n",
      "       'Num of val's Neighbors Became Target (F)',\n",
      "       'Num of val's Neighbors Became Target (L)', 'Pre key-val (F)',\n",
      "       'Post key-val (F)', 'Pre key-val (L)', 'Post key-val (L)',\n",
      "       'Pre keyN-val (F)', 'Post keyN-val (F)', 'Pre keyN-val (L)',\n",
      "       'Post keyN-val (L)'],\n",
      "      dtype='object')\n",
      "  Pre Target Precision\n",
      "0   0.7061880018894662\n",
      "1   0.7061880018894662   Post Target Precision\n",
      "0    0.6763683753258036\n",
      "1    0.6763683753258036\n",
      "     Pre Target Recall\n",
      "0  0.42714285714285716\n",
      "1  0.42714285714285716     Post Target Recall\n",
      "0  0.44485714285714284\n",
      "1  0.44485714285714284\n",
      "  Pre Orig Pred Precision\n",
      "0      0.7437245367328164\n",
      "1      0.7437245367328164   Post Orig Pred Precision\n",
      "0       0.8606741573033708\n",
      "1       0.8606741573033708\n",
      "  Pre Orig Pred Recall\n",
      "0   0.8084285714285714\n",
      "1   0.8084285714285714   Post Orig Pred Recall\n",
      "0    0.7112857142857143\n",
      "1    0.7112857142857143\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())\n",
    "\n",
    "print(df[['Pre Target Precision']], df[['Post Target Precision']])\n",
    "print(df[['Pre Target Recall']], df[['Post Target Recall']])\n",
    "\n",
    "print(df[['Pre Orig Pred Precision']], df[['Post Orig Pred Precision']])\n",
    "print(df[['Pre Orig Pred Recall']], df[['Post Orig Pred Recall']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
