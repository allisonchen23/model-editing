{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image Pair Candidates for Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists, write_lists, load_image\n",
    "from utils.knn_utils import _get_k_nearest_neighbors as get_k_nearest_neighbors\n",
    "from utils.model_utils import prepare_device\n",
    "from utils.visualizations import show_image_rows, show_image\n",
    "from parse_config import ConfigParser\n",
    "from data_loader import data_loaders\n",
    "import datasets.datasets as module_data\n",
    "import model.model as module_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants, paths\n",
    "config_path = 'configs/cinic10_imagenet_edit_knn.json'\n",
    "class_list_path = 'metadata/cinic-10/class_names.txt'\n",
    "# target_class =  3  # 5 (dog) is worst accuracy (40.914%) followed by 3 () with 54.94%\n",
    "np.random.seed(0)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in config file from configs/cinic10_imagenet_edit_knn.json\n",
      "Initialized model from external_code/PyTorch_CIFAR10/cifar10_models/state_dicts/vgg16_bn.pt\n"
     ]
    }
   ],
   "source": [
    "# Load config file, models\n",
    "config_json = read_json(config_path)\n",
    "config = ConfigParser(config_json)\n",
    "\n",
    "layernum = config.config['layernum']\n",
    "device, device_ids = prepare_device(config['n_gpu'])\n",
    "print(\"Read in config file from {}\".format(config_path))\n",
    "      \n",
    "model = config.init_obj('arch', module_arch, layernum=layernum)\n",
    "model.eval()\n",
    "print(\"Initialized model from {}\".format(config.config['arch']['args']['checkpoint_path']))\n",
    "\n",
    "class_list = read_lists(class_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized train data loader\n"
     ]
    }
   ],
   "source": [
    "data_loader_args = dict(config_json[\"data_loader\"][\"args\"])\n",
    "dataset_args = dataset_args = dict(config_json[\"dataset_args\"])\n",
    "\n",
    "# Create training data loader\n",
    "image_paths = read_lists(config_json['dataset_paths']['train_images'])\n",
    "labels = read_lists(config_json['dataset_paths']['train_labels'])\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=image_paths,\n",
    "        labels=labels,\n",
    "        return_paths=True,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Initialized train data loader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find correct and incorrectly predicted images from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target class: airplane (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [05:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6142 (87.74 %) correct images and 858 (12.26 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/airplane/vgg16_bn\n",
      "Target class: automobile (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:28<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5283 (75.47 %) correct images and 1717 (24.53 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/automobile/vgg16_bn\n",
      "Target class: bird (2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:31<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5113 (73.04 %) correct images and 1887 (26.96 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/bird/vgg16_bn\n",
      "Target class: cat (3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:23<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3761 (53.73 %) correct images and 3239 (46.27 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/cat/vgg16_bn\n",
      "Target class: deer (4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:12<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4248 (60.69 %) correct images and 2752 (39.31 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/deer/vgg16_bn\n",
      "Target class: dog (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:38<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975 (42.50 %) correct images and 4025 (57.50 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/dog/vgg16_bn\n",
      "Target class: frog (6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:10<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5633 (80.47 %) correct images and 1367 (19.53 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/frog/vgg16_bn\n",
      "Target class: horse (7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:07<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5176 (73.94 %) correct images and 1824 (26.06 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/horse/vgg16_bn\n",
      "Target class: ship (8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:08<00:00, 31.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4765 (68.07 %) correct images and 2235 (31.93 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/ship/vgg16_bn\n",
      "Target class: truck (9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:07<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4793 (68.47 %) correct images and 2207 (31.53 %) incorrect images\n",
      "Saving lists to metadata/CINIC10-ImageNet/truck/vgg16_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pedal to the metal!\n",
    "for target_class in range(len(class_list)):\n",
    "    print(\"Target class: {} ({})\".format(class_list[target_class], target_class))\n",
    "    \n",
    "    correct_image_paths = []\n",
    "    correct_images = []\n",
    "    incorrect_image_paths = []\n",
    "    incorrect_images = []\n",
    "    incorrect_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for idx, item in enumerate(tqdm(train_data_loader)):\n",
    "            image, target, path = item\n",
    "\n",
    "            # Skip any batches with no examples from target class\n",
    "            if (target != target_class).all():\n",
    "                continue\n",
    "\n",
    "            # Find indices where target = target class\n",
    "            target_idxs = (target == target_class).nonzero()\n",
    "            target_idxs = torch.squeeze(target_idxs)\n",
    "\n",
    "            image = image[target_idxs]\n",
    "            target = target[target_idxs]\n",
    "            path = [path[idx] for idx in target_idxs]  # path[target_idxs]\n",
    "\n",
    "            # Move data and label to GPU\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            # print(\"image shape {}\".format(image.shape))\n",
    "            output = model(image)\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "\n",
    "            # Obtain indices of where model predicted correctly and incorrectly\n",
    "            correct_idxs = torch.squeeze((prediction == target_class).nonzero())\n",
    "            incorrect_idxs = torch.squeeze((prediction != target_class).nonzero())\n",
    "\n",
    "            correct_image_paths += [path[idx] for idx in correct_idxs] \n",
    "            correct_images.append(image[correct_idxs])\n",
    "\n",
    "            incorrect_image_paths += [path[idx] for idx in incorrect_idxs]\n",
    "            incorrect_images.append(image[incorrect_idxs])\n",
    "            incorrect_predictions.append(prediction[incorrect_idxs])\n",
    "            \n",
    "    n_correct = len(correct_image_paths)\n",
    "    n_incorrect = len(incorrect_image_paths)\n",
    "    n_total = n_correct + n_incorrect\n",
    "\n",
    "    correct_images = torch.cat(correct_images, dim=0)\n",
    "    correct_images = correct_images.cpu()\n",
    "\n",
    "    incorrect_images = torch.cat(incorrect_images, dim=0)\n",
    "    incorrect_images = incorrect_images.cpu()\n",
    "    \n",
    "    print(\"{} ({:.2f} %) correct images and {} ({:.2f} %) incorrect images\".format(\n",
    "        n_correct,\n",
    "        100 * n_correct / n_total,\n",
    "        n_incorrect,\n",
    "        100 * n_incorrect / n_total))\n",
    "    \n",
    "    save_dir = os.path.join(\n",
    "        'metadata', \n",
    "        'CINIC10-ImageNet', \n",
    "        class_list[target_class],\n",
    "        config.config['arch']['args']['type'])\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Save list of correct image paths and the images\n",
    "    correct_image_paths_filepath = os.path.join(save_dir, 'correct_image_paths.txt')\n",
    "    correct_images_save_path = os.path.join(save_dir, 'correct_images.pth')\n",
    "\n",
    "\n",
    "    incorrect_image_paths_filepath = os.path.join(save_dir, 'incorrect_image_paths.txt')\n",
    "    incorrect_images_save_path = os.path.join(save_dir, 'incorrect_images.pth')\n",
    "\n",
    "    print(\"Saving lists to {}\".format(save_dir))\n",
    "    \n",
    "    write_lists(correct_image_paths_filepath, correct_image_paths)\n",
    "    write_lists(incorrect_image_paths_filepath, incorrect_image_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
