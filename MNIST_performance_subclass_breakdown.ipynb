{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7207c5dd-a90b-475e-a7d2-a0dfa5be31ea",
   "metadata": {},
   "source": [
    "### Analyze the data from `setup/setup_datasets.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "958ed250-9592-41f9-80e9-c501651ad0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.visualizations import show_image_rows, make_grid\n",
    "import model.metric as module_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063789df-b3c1-4319-932d-840778efdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = '2_Spurious_MNIST'\n",
    "train_path = os.path.join(data_root_dir, dataset_type, 'training.pt')\n",
    "train_data = torch.load(train_path)\n",
    "\n",
    "test_path = os.path.join(data_root_dir, dataset_type, 'test.pt')\n",
    "test_data = torch.load(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c276c-38a7-4c9d-887f-68ecda7ebb0a",
   "metadata": {},
   "source": [
    "### Load colors and labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ac710-f645-40c0-adba-18850b0cfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = train_data['images']\n",
    "# train_labels = train_data['labels']\n",
    "\n",
    "# test_imgs = test_data['images']\n",
    "# test_labels = test_data['labels']\n",
    "\n",
    "n_show = 20\n",
    "for idx, data in enumerate([train_data, test_data]):\n",
    "    imgs = data['images']\n",
    "    labels = data['labels']\n",
    "    print(imgs[0].shape)\n",
    "    print(np.amax(imgs[0]))\n",
    "    show_imgs = imgs[:n_show]\n",
    "    show_labels = labels[:n_show]\n",
    "    show_imgs = make_grid(show_imgs, items_per_row=5)\n",
    "    show_labels = make_grid(show_labels, items_per_row=5)\n",
    "    show_image_rows(\n",
    "        images=show_imgs,\n",
    "        image_titles=show_labels,\n",
    "        image_size=(1.5, 1.5),\n",
    "        figure_title='{} {}'.format(dataset_type, 'Train' if idx == 0 else 'Test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee838b3f-556b-4b39-af9f-11894cacdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = '2_Spurious_MNIST'\n",
    "\n",
    "data_dir = os.path.join('data', dataset_type)\n",
    "test_data_path = os.path.join(data_dir, 'test.pt')\n",
    "\n",
    "test_data = torch.load(test_data_path)\n",
    "test_labels = np.array(test_data['labels'])\n",
    "test_colors = np.array(test_data['color_idxs'])\n",
    "\n",
    "congruent_idxs_path = os.path.join(data_dir, 'test_congruent_idxs.pt')\n",
    "incongruent_idxs_path = os.path.join(data_dir, 'test_incongruent_idxs.pt')\n",
    "\n",
    "congruent_idxs = torch.load(congruent_idxs_path)\n",
    "incongruent_idxs = torch.load(incongruent_idxs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959522f-e3dc-45e4-a3a9-2ec01aea2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bd659da-c51f-48de-afde-03f1109463df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_timestamp = '0314_114855'\n",
    "model_arch = 'VGG_16'\n",
    "trial_dir = os.path.join('saved', 'test', '{}-{}'.format(dataset_type, model_arch), trial_timestamp)\n",
    "\n",
    "trial_logits_path = os.path.join(trial_dir, 'log', 'logits.pth')\n",
    "trial_logits = torch.load(trial_logits_path).cpu().numpy()\n",
    "trial_predictions = np.argmax(trial_logits, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72f8c2-230b-4680-b68b-aeb282ba8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print test set metrics for overall, congruent, and incongruent test set samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e419ea28-5d2a-400f-8b71-26a10f89c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test set performance\n",
      "TP: [471 562 546 530 480 447 467 495 484 477]\n",
      "TN: [8765 8822 8644 7953 8202 8675 8798 8343 8305 8452]\n",
      "FPs: [ 255   43  324 1037  816  433  244  629  721  539]\n",
      "FNs: [509 573 486 480 502 445 491 533 490 532]\n",
      "accuracy: 0.4959\n",
      "per_class_accuracy: [0.9236 0.9384 0.919  0.8483 0.8682 0.9122 0.9265 0.8838 0.8789 0.8929]\n",
      "per_class_accuracy_mean: 0.8991800000000001\n",
      "precision: [0.64876033 0.92892562 0.62758621 0.33822591 0.37037037 0.50795455\n",
      " 0.65682138 0.44039146 0.40165975 0.46948819]\n",
      "precision_mean: 0.5390183759944495\n",
      "recall: [0.48061224 0.49515419 0.52906977 0.52475248 0.48879837 0.50112108\n",
      " 0.4874739  0.48151751 0.49691992 0.47274529]\n",
      "recall_mean: 0.4958164743442034\n",
      "predicted_class_distribution: [ 726  605  870 1567 1296  880  711 1124 1205 1016]\n",
      "f1: [0.55216882 0.64597701 0.57413249 0.41133101 0.4214223  0.50451467\n",
      " 0.55961654 0.46003717 0.44424048 0.47111111]\n",
      "f1_mean: 0.5044551597509661\n",
      "\n",
      "Metrics for congruent indices in test set\n",
      "TP: [471 562 546 530 480 447 467 495 484 477]\n",
      "TN: [4528 4441 4446 4471 4520 4547 4532 4498 4507 4509]\n",
      "FPs: [ 3  1  7  2  2  8  1  5 10  7]\n",
      "FNs: [ 3  1  6  2  3  3  5  7  4 12]\n",
      "accuracy: 0.9908091908091908\n",
      "per_class_accuracy: [0.9988012 0.9996004 0.9974026 0.9992008 0.999001  0.9978022 0.9988012\n",
      " 0.9976024 0.9972028 0.9962038]\n",
      "per_class_accuracy_mean: 0.998161838161838\n",
      "precision: [0.99367089 0.9982238  0.98734177 0.9962406  0.99585062 0.98241758\n",
      " 0.99786325 0.99       0.97975709 0.98553719]\n",
      "precision_mean: 0.9906902788587683\n",
      "recall: [0.99367089 0.9982238  0.98913043 0.9962406  0.99378882 0.99333333\n",
      " 0.98940678 0.98605578 0.99180328 0.97546012]\n",
      "recall_mean: 0.9907113834578505\n",
      "predicted_class_distribution: [474 563 553 532 482 455 468 500 494 484]\n",
      "f1: [0.99367089 0.9982238  0.98823529 0.9962406  0.99481865 0.9878453\n",
      " 0.99361702 0.98802395 0.98574338 0.98047276]\n",
      "f1_mean: 0.9906891658353446\n",
      "\n",
      "Metrics for incongruent indices in test set\n",
      "TP: [0 0 0 0 0 0 0 0 0 0]\n",
      "TN: [4237 4381 4198 3482 3682 4128 4266 3845 3798 3943]\n",
      "FPs: [ 252   42  317 1035  814  425  243  624  711  532]\n",
      "FNs: [506 572 480 478 499 442 486 526 486 520]\n",
      "accuracy: 0.0\n",
      "per_class_accuracy: [0.84824825 0.87707708 0.84044044 0.6970971  0.73713714 0.82642643\n",
      " 0.85405405 0.76976977 0.76036036 0.78938939]\n",
      "per_class_accuracy_mean: 0.8\n",
      "precision: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "precision_mean: 0.0\n",
      "recall: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "recall_mean: 0.0\n",
      "predicted_class_distribution: [ 252   42  317 1035  814  425  243  624  711  532]\n",
      "f1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "f1_mean: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-editing/model-editing/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    }
   ],
   "source": [
    "partition_labels = ['congruent', 'incongruent']\n",
    "metric_names = [\n",
    "    \"accuracy\",\n",
    "    \"per_class_accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"f1\",\n",
    "    \"predicted_class_distribution\"]\n",
    "metric_fns = [getattr(module_metric, metric_name) for metric_name in metric_names]\n",
    "\n",
    "print(\"Overall test set performance\")\n",
    "metrics = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=trial_predictions,\n",
    "        target=test_labels,\n",
    "        unique_labels=[i for i in range(10)],\n",
    "        save_mean=True)\n",
    "for metric_name, metric in metrics.items():\n",
    "    print(\"{}: {}\".format(metric_name, metric))\n",
    "    \n",
    "print(\"\")\n",
    "for i, idxs in enumerate([congruent_idxs, incongruent_idxs]):\n",
    "    partitioned_labels = test_labels[idxs]\n",
    "    partitioned_predictions = trial_predictions[idxs]\n",
    "    \n",
    "    metrics = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=partitioned_predictions,\n",
    "        target=partitioned_labels,\n",
    "        unique_labels=[i for i in range(10)],\n",
    "        save_mean=True)\n",
    "    print(\"Metrics for {} indices in test set\".format(partition_labels[i]))\n",
    "    \n",
    "    for metric_name, metric in metrics.items():\n",
    "        print(\"{}: {}\".format(metric_name, metric))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e8232-37a9-4732-8eb6-df9b9a9e7f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
