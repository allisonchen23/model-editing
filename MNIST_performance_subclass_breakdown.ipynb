{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7207c5dd-a90b-475e-a7d2-a0dfa5be31ea",
   "metadata": {},
   "source": [
    "### Analyze the data from `setup/setup_datasets.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "958ed250-9592-41f9-80e9-c501651ad0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.visualizations import show_image_rows, make_grid\n",
    "import model.metric as module_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063789df-b3c1-4319-932d-840778efdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = '2_Spurious_MNIST'\n",
    "train_path = os.path.join(data_root_dir, dataset_type, 'training.pt')\n",
    "train_data = torch.load(train_path)\n",
    "\n",
    "test_path = os.path.join(data_root_dir, dataset_type, 'test.pt')\n",
    "test_data = torch.load(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c276c-38a7-4c9d-887f-68ecda7ebb0a",
   "metadata": {},
   "source": [
    "### Load colors and labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ac710-f645-40c0-adba-18850b0cfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = train_data['images']\n",
    "# train_labels = train_data['labels']\n",
    "\n",
    "# test_imgs = test_data['images']\n",
    "# test_labels = test_data['labels']\n",
    "\n",
    "n_show = 20\n",
    "for idx, data in enumerate([train_data, test_data]):\n",
    "    imgs = data['images']\n",
    "    labels = data['labels']\n",
    "    print(imgs[0].shape)\n",
    "    print(np.amax(imgs[0]))\n",
    "    show_imgs = imgs[:n_show]\n",
    "    show_labels = labels[:n_show]\n",
    "    show_imgs = make_grid(show_imgs, items_per_row=5)\n",
    "    show_labels = make_grid(show_labels, items_per_row=5)\n",
    "    show_image_rows(\n",
    "        images=show_imgs,\n",
    "        image_titles=show_labels,\n",
    "        image_size=(1.5, 1.5),\n",
    "        figure_title='{} {}'.format(dataset_type, 'Train' if idx == 0 else 'Test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee838b3f-556b-4b39-af9f-11894cacdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = '2_Spurious_MNIST'\n",
    "\n",
    "data_dir = os.path.join('data', dataset_type)\n",
    "test_data_path = os.path.join(data_dir, 'test.pt')\n",
    "\n",
    "test_data = torch.load(test_data_path)\n",
    "test_labels = np.array(test_data['labels'])\n",
    "test_colors = np.array(test_data['colors'])\n",
    "\n",
    "congruent_idxs_path = os.path.join(data_dir, 'test_congruent_idxs.pt')\n",
    "incongruent_idxs_path = os.path.join(data_dir, 'test_incongruent_idxs.pt')\n",
    "\n",
    "congruent_idxs = torch.load(congruent_idxs_path)\n",
    "incongruent_idxs = torch.load(incongruent_idxs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959522f-e3dc-45e4-a3a9-2ec01aea2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bd659da-c51f-48de-afde-03f1109463df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_timestamp = '0316_093312'\n",
    "model_arch = 'VGG_16'\n",
    "trial_dir = os.path.join('saved', 'test', '{}-{}'.format(dataset_type, model_arch), trial_timestamp)\n",
    "\n",
    "trial_logits_path = os.path.join(trial_dir, 'log', 'logits.pth')\n",
    "trial_logits = torch.load(trial_logits_path).cpu().numpy()\n",
    "trial_predictions = np.argmax(trial_logits, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72f8c2-230b-4680-b68b-aeb282ba8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print test set metrics for overall, congruent, and incongruent test set samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e419ea28-5d2a-400f-8b71-26a10f89c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test set performance\n",
      "TP: [448 537 520 498 452 422 437 473 454 454]\n",
      "TN: [8329 8374 8213 7556 7783 8245 8366 7921 7886 8022]\n",
      "FPs: [241  41 305 984 785 413 226 601 690 519]\n",
      "FNs: [482 548 462 462 480 420 471 505 470 505]\n",
      "accuracy: 0.4942105263157895\n",
      "per_class_accuracy: [0.92389474 0.938      0.91926316 0.84778947 0.86684211 0.91231579\n",
      " 0.92663158 0.88357895 0.87789474 0.89221053]\n",
      "per_class_accuracy_mean: 0.8988421052631578\n",
      "precision: [0.65021771 0.92906574 0.63030303 0.33603239 0.36540016 0.50538922\n",
      " 0.65912519 0.44040968 0.39685315 0.46659815]\n",
      "precision_mean: 0.537939442183942\n",
      "recall: [0.48172043 0.49493088 0.52953157 0.51875    0.48497854 0.50118765\n",
      " 0.48127753 0.48364008 0.49134199 0.4734098 ]\n",
      "recall_mean: 0.4940768471198444\n",
      "predicted_class_distribution: [ 689  578  825 1482 1237  835  663 1074 1144  973]\n",
      "f1: [0.55342804 0.64582081 0.57553957 0.40786241 0.41678193 0.50327967\n",
      " 0.55633355 0.46101365 0.43907157 0.4699793 ]\n",
      "f1_mean: 0.5029110470741379\n",
      "\n",
      "Metrics for congruent indices in test set\n",
      "TP: [448 537 520 498 452 422 437 473 454 454]\n",
      "TN: [4284 4199 4206 4236 4282 4305 4295 4253 4272 4267]\n",
      "FPs: [3 1 6 2 2 8 1 5 8 7]\n",
      "FNs: [ 3  1  6  2  2  3  5  7  4 10]\n",
      "accuracy: 0.9909244406922753\n",
      "per_class_accuracy: [0.99873364 0.99957788 0.99746729 0.99915576 0.99915576 0.99767835\n",
      " 0.99873364 0.99746729 0.99746729 0.99641199]\n",
      "per_class_accuracy_mean: 0.9981848881384551\n",
      "precision: [0.99334812 0.99814126 0.98859316 0.996      0.99559471 0.98139535\n",
      " 0.99771689 0.98953975 0.98268398 0.98481562]\n",
      "precision_mean: 0.9907828842463372\n",
      "recall: [0.99334812 0.99814126 0.98859316 0.996      0.99559471 0.99294118\n",
      " 0.98868778 0.98541667 0.99126638 0.97844828]\n",
      "recall_mean: 0.9908437526140386\n",
      "predicted_class_distribution: [451 538 526 500 454 430 438 478 462 461]\n",
      "f1: [0.99334812 0.99814126 0.98859316 0.996      0.99559471 0.9871345\n",
      " 0.99318182 0.9874739  0.98695652 0.98162162]\n",
      "f1_mean: 0.9908045617222925\n",
      "\n",
      "Metrics for incongruent indices in test set\n",
      "TP: [0 0 0 0 0 0 0 0 0 0]\n",
      "TN: [4045 4175 4007 3320 3501 3940 4071 3668 3614 3755]\n",
      "FPs: [238  40 299 982 783 405 225 596 682 512]\n",
      "FNs: [479 547 456 460 478 417 466 498 466 495]\n",
      "accuracy: 0.0\n",
      "per_class_accuracy: [0.84943301 0.87673247 0.84145317 0.69718606 0.7351953  0.82738345\n",
      " 0.8548929  0.77026459 0.75892482 0.78853423]\n",
      "per_class_accuracy_mean: 0.8\n",
      "precision: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "precision_mean: 0.0\n",
      "recall: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "recall_mean: 0.0\n",
      "predicted_class_distribution: [238  40 299 982 783 405 225 596 682 512]\n",
      "f1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "f1_mean: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-editing/model-editing/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    }
   ],
   "source": [
    "partition_labels = ['congruent', 'incongruent']\n",
    "metric_names = [\n",
    "    \"accuracy\",\n",
    "    \"per_class_accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"f1\",\n",
    "    \"predicted_class_distribution\"]\n",
    "metric_fns = [getattr(module_metric, metric_name) for metric_name in metric_names]\n",
    "\n",
    "print(\"Overall test set performance\")\n",
    "metrics = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=trial_predictions,\n",
    "        target=test_labels,\n",
    "        unique_labels=[i for i in range(10)],\n",
    "        save_mean=True)\n",
    "for metric_name, metric in metrics.items():\n",
    "    print(\"{}: {}\".format(metric_name, metric))\n",
    "    \n",
    "print(\"\")\n",
    "for i, idxs in enumerate([congruent_idxs, incongruent_idxs]):\n",
    "    partitioned_labels = test_labels[idxs]\n",
    "    partitioned_predictions = trial_predictions[idxs]\n",
    "    \n",
    "    metrics = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=partitioned_predictions,\n",
    "        target=partitioned_labels,\n",
    "        unique_labels=[i for i in range(10)],\n",
    "        save_mean=True)\n",
    "    print(\"Metrics for {} indices in test set\".format(partition_labels[i]))\n",
    "    \n",
    "    for metric_name, metric in metrics.items():\n",
    "        print(\"{}: {}\".format(metric_name, metric))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e8232-37a9-4732-8eb6-df9b9a9e7f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
