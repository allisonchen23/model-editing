{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Edits that match post edit class distribution of target class to real edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists, list_to_dict, ensure_dir, informal_log, write_lists\n",
    "from utils.df_utils import load_and_preprocess_csv\n",
    "from utils.visualizations import histogram\n",
    "from utils.model_utils import prepare_device, quick_predict\n",
    "from parse_config import ConfigParser\n",
    "from test import predict\n",
    "import datasets.datasets as module_data\n",
    "import model.model as module_arch\n",
    "import model.metric as module_metric\n",
    "import model.loss as module_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants, paths\n",
    "class_list_path = os.path.join('metadata', 'cinic-10', 'class_names.txt')\n",
    "\n",
    "config_path = 'configs/copies/edit_experiments/cinic10_imagenet-bump_edit.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file, models, and dataloader\n",
    "class_list = read_lists(class_list_path)\n",
    "class_idx_dict = list_to_dict(class_list)\n",
    "\n",
    "config_dict = read_json(config_path)\n",
    "\n",
    "device, device_ids = prepare_device(config_dict['n_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class_name = 'automobile'\n",
    "target_class_idx = class_idx_dict[target_class_name]\n",
    "n_select = 100\n",
    "timestamp = '0127_103716'\n",
    "save_timestamp = '0208_112555'\n",
    "\n",
    "root_dir = os.path.join('saved', 'edit', 'trials', 'CINIC10_ImageNet-VGG_16', '{}' + '_{}'.format(n_select), timestamp)\n",
    "csv_path_template = os.path.join(root_dir, 'results_table.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get the Target Class Distribution Across All Edits for Specific Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_distribution(csv_path, \n",
    "                            target_class_idx,\n",
    "                            target_class_name,\n",
    "                            show=False):\n",
    "    \n",
    "    df = load_and_preprocess_csv(\n",
    "        csv_path=csv_path,\n",
    "        drop_duplicates=['ID']\n",
    "    )\n",
    "    \n",
    "    # Obtain number of predictions for target class pre edit\n",
    "    pre_edit_class_distribution = df['Pre Class Dist'].to_numpy()\n",
    "    pre_edit_class_distribution = np.stack(pre_edit_class_distribution)\n",
    "    target_pre_edit_class_predictions = np.mean(pre_edit_class_distribution[:, target_class_idx])\n",
    "    \n",
    "    # Obtain number of predictions for target class post edit for each trial\n",
    "    class_distribution = df['Post Class Dist'].to_numpy()\n",
    "    class_distribution = np.stack(class_distribution, axis=0)\n",
    "    target_class_distribution = class_distribution[:, target_class_idx]\n",
    "    # target_class_bins = np.bincount(target_class_distribution)\n",
    "\n",
    "    histogram_save_path = os.path.join(os.path.dirname(csv_path), 'graphs', 'summary', 'target_class_distribution.png')\n",
    "    title = 'Post Edit {} Class Distribution for {} Edits'.format(target_class_name, target_class_name)\n",
    "    xlabel = 'Num. {} Predictions Post Edit'.format(target_class_name)\n",
    "    ylabel = 'Num. Edits'\n",
    "    \n",
    "    bin_values, bins, _ = histogram(\n",
    "        data=target_class_distribution,\n",
    "        n_bins=50,\n",
    "        save_path=histogram_save_path,\n",
    "        title=title,\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        marker=target_pre_edit_class_predictions,\n",
    "        show=show)\n",
    "    \n",
    "    bin_tuples = []\n",
    "    for bin_idx in range(len(bins) - 1):\n",
    "        bin_tuples.append((bins[bin_idx], bins[bin_idx+1]))\n",
    "\n",
    "    save_data = {\n",
    "        \"n_target_predictions\": target_class_distribution,\n",
    "        \"histogram_bin_values\": bin_values,\n",
    "        \"histogram_bins\": bins\n",
    "    }\n",
    "    target_class_dist_save_path = os.path.join(os.path.dirname(csv_path), 'target_class_distribution.pth')\n",
    "    torch.save(save_data, target_class_dist_save_path)\n",
    "    \n",
    "    print(\"Saved target class distribution & histogram data to {}\".format(target_class_dist_save_path))\n",
    "    \n",
    "    plt.close('all')\n",
    "    return save_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loop over all classes and save histograms and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_list:\n",
    "    csv_path = csv_path_template.format(class_name)\n",
    "    save_class_distribution(\n",
    "        csv_path=csv_path,\n",
    "        target_class_idx=class_idx_dict[class_name],\n",
    "        target_class_name=class_name,\n",
    "        show=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a specific class, make bump edits that match the distribution of target class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "config = ConfigParser(config_dict)\n",
    "data_loader_args = dict(config.config[\"data_loader\"][\"args\"])\n",
    "dataset_args = dict(config[\"dataset_args\"])\n",
    "\n",
    "val_image_paths = read_lists(config_dict['dataset_paths']['valid_images'])\n",
    "val_labels = read_lists(config_dict['dataset_paths']['valid_labels'])\n",
    "val_paths_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=val_image_paths,\n",
    "        labels=val_labels,\n",
    "        return_paths=True,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")\n",
    "\n",
    "# Obtain loss function and metric functions\n",
    "loss_fn = getattr(module_loss, config['loss'])\n",
    "metric_fns = [getattr(module_metric, met) for met in config['metrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "layernum = config.config['layernum']\n",
    "model = config.init_obj('arch', module_arch, layernum=layernum, device=device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_bump(data_loader,\n",
    "                      model,\n",
    "                      target_class_idx,\n",
    "                      bump_amount,\n",
    "                      loss_fn,\n",
    "                      metric_fns,\n",
    "                      device,\n",
    "                      save_path=None):\n",
    "    '''\n",
    "    Run the model on the data_loader, calculate metrics, and log\n",
    "\n",
    "    Arg(s):\n",
    "        data_loader : torch Dataloader\n",
    "            data to test on\n",
    "        model : torch.nn.Module\n",
    "            model to run\n",
    "        loss_fn : module\n",
    "            loss function\n",
    "        metric_fns : list[model.metric modules]\n",
    "            list of metric functions\n",
    "        device : torch.device\n",
    "        save_path : str or None\n",
    "            if not None, save metrics to save_path\n",
    "\n",
    "    Returns :\n",
    "        log : dict{} of metrics\n",
    "    '''\n",
    "\n",
    "    # Hold data for calculating metrics\n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    # Ensure model is in eval mode\n",
    "    if model.training:\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, item in enumerate(tqdm(data_loader)):\n",
    "            if len(item) == 3:\n",
    "                data, target, path = item\n",
    "            else:\n",
    "                data, target = item\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # Store outputs and targets\n",
    "            outputs.append(output)\n",
    "            targets.append(target)\n",
    "\n",
    "    # Concatenate predictions and targets\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    \n",
    "    # Adjust output softmax by bump amount\n",
    "    outputs[:, target_class_idx] += bump_amount\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(outputs, targets).item()\n",
    "    n_samples = len(data_loader.sampler)\n",
    "    log = {'loss': loss}\n",
    "\n",
    "    # Calculate predictions based on argmax\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    # Move predictions and target to cpu and convert to numpy to calculate metrics\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    log = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=predictions,\n",
    "        target=targets)\n",
    "\n",
    "    if save_path is not None:\n",
    "        ensure_dir(os.path.dirname(save_path))\n",
    "        torch.save(log, save_path)\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bump_edits(data_loader,\n",
    "                     model,\n",
    "                     loss_fn,\n",
    "                     metric_fns,\n",
    "                     device,\n",
    "                     bin_lows,\n",
    "                     target_class_idx,\n",
    "                     save_dir,\n",
    "                     debug=True):\n",
    "    '''\n",
    "    Get bins\n",
    "    for each bin, get the mean\n",
    "    until the target class predictions on val match the mean,\n",
    "        adjust the target\n",
    "    store (mean, bump amount)\n",
    "    '''\n",
    "    # save_dir = os.path.dirname(str(config.save_dir))\n",
    "    informal_log_path = os.path.join(save_dir, 'informal_log.txt')\n",
    "    bump_dictionary = {}\n",
    "    \n",
    "    n_bins = len(bin_lows) - 1\n",
    "    \n",
    "    n_bins_left = n_bins\n",
    "    min_bin = bin_lows[0]\n",
    "    bin_width = bin_lows[1] - bin_lows[0]\n",
    "    \n",
    "    bin_means = []\n",
    "    bump_amount = 0.2\n",
    "    delta = 1.25\n",
    "    \n",
    "    bumps = [-1 for i in range(n_bins)]\n",
    "    class_predictions = [-1 for i in range(n_bins)]\n",
    "    logs = [None for i in range(n_bins)]\n",
    "    \n",
    "    cur_bump_idx = 0\n",
    "    cur_itr = 0\n",
    "    delta_reset = 1.25\n",
    "    \n",
    "    # Obtain pre edit metrics\n",
    "    pre_edit_log = predict(\n",
    "        data_loader=data_loader,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        metric_fns=metric_fns,\n",
    "        device=device,\n",
    "        save_path=None)\n",
    "\n",
    "    while cur_bump_idx < n_bins:\n",
    "        cur_itr += 1\n",
    "        if delta <= 1 or delta > 2:\n",
    "            delta = delta_reset\n",
    "        if debug:\n",
    "            informal_log(\"[{}]***NEW ITR {}***\".format(\n",
    "                datetime.now().strftime(r'%m%d_%H%M%S'), cur_itr), informal_log_path)\n",
    "\n",
    "        if bumps[cur_bump_idx] > -1:\n",
    "            bump_amount = bumps[cur_bump_idx]\n",
    "            cur_bump_idx += 1\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        log = predict_with_bump(\n",
    "            data_loader=data_loader,\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            metric_fns=metric_fns,\n",
    "            device=device,\n",
    "            target_class_idx=target_class_idx,\n",
    "            bump_amount=bump_amount,\n",
    "            save_path=None)\n",
    "        \n",
    "        # Obtain num. predictions for target class and determine bin idx\n",
    "        post_class_distribution = log['predicted_class_distribution']\n",
    "        target_class_predictions = post_class_distribution[target_class_idx]\n",
    "        bin_idx = math.floor((target_class_predictions - min_bin) / bin_width)\n",
    "        \n",
    "        # Check for out of bounds/already visited bin index\n",
    "        while bin_idx < cur_bump_idx:\n",
    "            bump_amount *= delta\n",
    "            if debug:\n",
    "                informal_log(\"bin_idx < cur_bump_idx ({} and {}) delta={} new bump_amount: {}\".format(\n",
    "                    bin_idx, cur_bump_idx, delta, bump_amount), informal_log_path)\n",
    "                \n",
    "            log = predict_with_bump(\n",
    "                data_loader=data_loader,\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                metric_fns=metric_fns,\n",
    "                device=device,\n",
    "                target_class_idx=target_class_idx,\n",
    "                bump_amount=bump_amount,\n",
    "                save_path=None)\n",
    "\n",
    "            # Obtain num. predictions for target class and determine bin idx\n",
    "            post_class_distribution = log['predicted_class_distribution']\n",
    "            target_class_predictions = post_class_distribution[target_class_idx]\n",
    "            bin_idx = math.floor((target_class_predictions - min_bin) / bin_width)\n",
    "                \n",
    "            \n",
    "            # continue\n",
    "        if bin_idx >= n_bins:\n",
    "            if cur_bump_idx == 0:\n",
    "                bump_amount /= delta\n",
    "            else:\n",
    "                bump_amount = (bump_amount + bumps[cur_bump_idx - 1]) / 2\n",
    "            informal_log(\"bin_idx > n_bins ({}) delta={} new bump_amount: {}\".format(\n",
    "                bin_idx, delta, bump_amount), informal_log_path)\n",
    "            continue\n",
    "            \n",
    "        # Sanity check correct bin_idx\n",
    "        assert target_class_predictions >= bin_lows[bin_idx] and \\\n",
    "               target_class_predictions <= bin_lows[bin_idx+1]\n",
    "        \n",
    "        # If bump value for this bin yet, assign it\n",
    "        if bumps[bin_idx] == -1:\n",
    "            bumps[bin_idx] = bump_amount\n",
    "            class_predictions[bin_idx] = target_class_predictions\n",
    "            logs[bin_idx] = log\n",
    "            if debug:\n",
    "                informal_log(\"assigned bin_idx {}\".format(bin_idx), informal_log_path)\n",
    "                informal_log(\"Cur bump_idx: {} bump amount: {} target_class_pred: {} bin_idx: {}\".format(\n",
    "                    cur_bump_idx, bump_amount, target_class_predictions, bin_idx), informal_log_path)\n",
    "        \n",
    "        # Check if this is our current bin we're trying to fill\n",
    "        if bin_idx == cur_bump_idx:\n",
    "            cur_bump_idx += 1\n",
    "            bump_amount *= delta\n",
    "            if debug:\n",
    "                informal_log(\"updating cur_bump_idx to {}, bump_amount to {}\"\n",
    "                             .format(cur_bump_idx, bump_amount), informal_log_path)\n",
    "            \n",
    "        # If we're not at the current cell,\n",
    "        else:\n",
    "            # Decrease bump amount by half\n",
    "            if cur_bump_idx == 0:\n",
    "                bump_amount /= 2\n",
    "            # Set bump amount to something in the middle between current and last successful\n",
    "            else:\n",
    "                bump_amount = (bump_amount + bumps[cur_bump_idx-1]) / 2 \n",
    "            if debug:\n",
    "                informal_log(\"Overshot to bin {}. Decreasing bump amount to {} aiming for bin {}\".format(\n",
    "                    bin_idx, bump_amount, cur_bump_idx), informal_log_path)\n",
    "        informal_log(\"bumps: {}\".format(bumps), informal_log_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    save_data = {\n",
    "        'pre_edit_metrics': pre_edit_log,\n",
    "        'bump_amounts': bumps,\n",
    "        'target_class_predictions': class_predictions,\n",
    "        'metrics': logs\n",
    "    }\n",
    "    save_path = os.path.join(save_dir, 'bumps_preds_metrics.pth'.format())\n",
    "    torch.save(save_data, save_path)\n",
    "    if debug:\n",
    "        informal_log(\"Saved data to {}\".format(save_path), informal_log_path)\n",
    "    return save_data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run match_bump_edits() to get how much to bump to match each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_class_distribution_path = os.path.join(root_dir, 'target_class_distribution.pth').format(\n",
    "    target_class_name)\n",
    "target_class_distribution = torch.load(target_class_distribution_path)\n",
    "bin_lows = target_class_distribution['histogram_bins']\n",
    "\n",
    "bump_save_dir = os.path.join(os.path.dirname(os.path.dirname(config.save_dir)), save_timestamp, '{}_{}'.format(target_class_name, n_select))\n",
    "ensure_dir(bump_save_dir)\n",
    "# Save a copy of histogram info to save_dir\n",
    "torch.save(target_class_distribution, os.path.join(bump_save_dir, 'target_class_distribution.pth'))\n",
    "# Run bump experiments\n",
    "print(\"Obtaining class distribution for {} from {}\".format(target_class_name, target_class_distribution_path))\n",
    "print(\"Saving results to {}\".format(bump_save_dir))\n",
    "match_bump_edits(\n",
    "    data_loader=val_paths_data_loader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device,\n",
    "    bin_lows=bin_lows,\n",
    "    target_class_idx=target_class_idx,\n",
    "    save_dir=bump_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check that resulting histogram matches original from real edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bump_save_dir = os.path.join(os.path.dirname(os.path.dirname(config.save_dir)), save_timestamp, '{}_{}'.format(target_class_name, n_select))\n",
    "metrics_save_path = os.path.join(bump_save_dir, 'bumps_preds_metrics.pth')\n",
    "\n",
    "bumped_target_class_dist = torch.load(metrics_save_path)\n",
    "\n",
    "bumped_hist_data = []\n",
    "\n",
    "\n",
    "target_class_dist_dict = torch.load(target_class_distribution_path)\n",
    "\n",
    "for n_target_predictions, bucket_value in zip(\n",
    "    bumped_target_class_dist['target_class_predictions'], \n",
    "    target_class_distribution['histogram_bin_values']):\n",
    "    cur_data = [n_target_predictions for i in range(int(bucket_value))]\n",
    "    bumped_hist_data += cur_data\n",
    "    \n",
    "bins = target_class_distribution['histogram_bins']\n",
    "bin_values = target_class_distribution['histogram_bin_values']\n",
    "\n",
    "histogram_save_path = os.path.join(\n",
    "    bump_save_dir, \n",
    "    'graphs',\n",
    "    'summary',\n",
    "    'bumped_target_class_distribution.png')\n",
    "bump_bin_values, bump_bins, _= histogram(\n",
    "        data=bumped_hist_data,\n",
    "        n_bins=bins, #50,\n",
    "        title='Bumped Post Edit {} Class Distribution to Match {} Edits'.format(target_class_name, target_class_name),\n",
    "        xlabel='Num. {} Predictions Post Bump'.format(target_class_name),\n",
    "        ylabel='Num. Edits',\n",
    "        save_path=histogram_save_path,\n",
    "        show=True)\n",
    "\n",
    "assert (bin_values == bump_bin_values).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy results such that we can call src/utils/results_to_csv.py to get csv of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bump_results(bumps_preds_metrics,\n",
    "                        target_class_distribution,\n",
    "                        results_save_dir,\n",
    "                        trial_paths_path):\n",
    "    '''\n",
    "    Given how much to bump logit by to match target class distribution, create results for each tiral\n",
    "    \n",
    "    Arg(s):\n",
    "        bumps_preds_metrics : dict\n",
    "            result of match_bump_edits()\n",
    "        target_class_distribution : dict\n",
    "            histogram data, result from save_class_distribution()\n",
    "        results_save_dir : str\n",
    "            location of results folder\n",
    "        trial_paths_path : str\n",
    "            path to file to store paths to each trial\n",
    "            \n",
    "    '''\n",
    "    pre_edit_metrics = bumps_preds_metrics['pre_edit_metrics']\n",
    "    \n",
    "    metrics = bumps_preds_metrics['metrics']\n",
    "    bin_values = target_class_distribution['histogram_bin_values']\n",
    "    bins = target_class_distribution['histogram_bins']\n",
    "    bin_lows = bins[:-1]\n",
    "    bin_highs = bins[1:]\n",
    "\n",
    "    trial_paths = []\n",
    "    for bin_idx, bin_value in enumerate(tqdm(bin_values)):\n",
    "        n_repeat = int(bin_value)\n",
    "        if n_repeat == 0:\n",
    "            continue\n",
    "            \n",
    "        # Obtain post edit metrics\n",
    "        post_edit_metrics = metrics[bin_idx]\n",
    "        \n",
    "        for itr in range(n_repeat):\n",
    "            # Create directory for this trial\n",
    "            trial_id = 'bin_{}_{}_itr_{}'.format(bin_lows[bin_idx], bin_highs[bin_idx], itr)\n",
    "            trial_dir = os.path.join(results_save_dir, trial_id)\n",
    "            \n",
    "            # Log path to trial_paths.txt\n",
    "            trial_paths.append(trial_dir)\n",
    "            \n",
    "            trial_save_dir = os.path.join(trial_dir, 'models')\n",
    "            ensure_dir(trial_save_dir)\n",
    "            # Save pre edit metrics\n",
    "            torch.save(pre_edit_metrics, os.path.join(trial_save_dir, 'pre_edit_metrics.pth'))\n",
    "            # Save post edit metrics\n",
    "            torch.save(post_edit_metrics, os.path.join(trial_save_dir, 'post_edit_metrics.pth'))\n",
    "        \n",
    "    return trial_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bump_preds_metrics_path = os.path.join(bump_save_dir, 'bumps_preds_metrics.pth')\n",
    "target_class_distribution_path = os.path.join(bump_save_dir, 'target_class_distribution.pth')\n",
    "\n",
    "# Load objects\n",
    "bumps_preds_metrics = torch.load(bump_preds_metrics_path)\n",
    "target_class_distribution = torch.load(target_class_distribution_path)\n",
    "\n",
    "results_save_dir = os.path.join(bump_save_dir, 'results')\n",
    "ensure_dir(results_save_dir)\n",
    "progress_report_path = os.path.join(bump_save_dir, 'progress_report.txt')\n",
    "trial_paths_path = os.path.join(bump_save_dir, 'trial_paths.txt')\n",
    "# Remove file at trial_paths_path if it exists\n",
    "if os.path.isfile(trial_paths_path):\n",
    "    os.remove(trial_paths_path)\n",
    "\n",
    "trial_paths = create_bump_results(\n",
    "    bumps_preds_metrics=bumps_preds_metrics,\n",
    "    target_class_distribution=target_class_distribution,\n",
    "    results_save_dir=results_save_dir,\n",
    "    trial_paths_path=trial_paths_path)\n",
    "\n",
    "write_lists(trial_paths_path, trial_paths)\n",
    "print(\"Wrote list of trial_paths to {}\".format(trial_paths_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
