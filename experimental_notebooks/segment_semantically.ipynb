{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment and modify an image to produce value images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_lists, write_lists, ensure_dir, list_to_dict, read_json, load_image, informal_log, get_image_id, save_image\n",
    "from utils.model_utils import prepare_device, quick_predict\n",
    "from parse_config import ConfigParser\n",
    "from utils.segmentation_utils import segment_modify_multi_method\n",
    "from utils.visualizations import show_image_rows, make_grid, plot\n",
    "from segment import segment_modify_save\n",
    "import model.model as module_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'configs/copies/cinic10_imagenet_segmentation_edit_trials.json'\n",
    "target_class = 'cat'\n",
    "incorrect_images_path = os.path.join('metadata', 'CINIC10-ImageNet', target_class, 'vgg16_bn', 'incorrect_image_paths.txt')\n",
    "n_select = 50\n",
    "\n",
    "log_path = 'temp/{}_{}_edit_image/log.txt'.format(n_select, target_class)\n",
    "\n",
    "seed = 0 # Set to None if want true randomness\n",
    "debug = True\n",
    "\n",
    "class_list_path = os.path.join('metadata', 'cinic-10', 'class_names.txt')\n",
    "class_list = read_lists(class_list_path)\n",
    "class_to_idx_dict = list_to_dict(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(r'%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain key images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain incorrect images to use for edit\n",
    "all_incorrect_images = np.array(read_lists(incorrect_images_path))\n",
    "n_images = len(all_incorrect_images)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# key_images = all_incorrect_images[np.random.randint(n_images, size=n_select)]\n",
    "# TODO: NEED TO TEST\n",
    "rng = np.random.default_rng(seed)\n",
    "random_idxs = rng.choice(n_images, size=n_select, replace=False)\n",
    "assert len(set(random_idxs)) == len(list(random_idxs))\n",
    "\n",
    "key_images = all_incorrect_images[random_idxs]\n",
    "print(key_images[:10])\n",
    "\n",
    "\n",
    "if not debug:\n",
    "    plt.ioff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables shared across all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain class list\n",
    "# class_list_path = os.path.join('metadata', 'cinic-10', 'class_names.txt')\n",
    "# class_list = read_lists(class_list_path)\n",
    "# class_to_idx_dict = list_to_dict(class_list)\n",
    "\n",
    "# General save directories\n",
    "save_dir_root = os.path.join('saved', 'segmentations', 'semantics', '{}_{}'.format(target_class, n_select))\n",
    "path_save_dir = os.path.join('paths', 'edits', 'semantics', '{}_{}'.format(target_class, n_select), timestamp)\n",
    "ensure_dir(path_save_dir)\n",
    "# Set parameters for segmentation\n",
    "felzenszwalb_params = {\n",
    "    'scale': 0.9,\n",
    "    'sigma': 0.25,\n",
    "    'min_size': 50\n",
    "}\n",
    "# quickshift_params = {\n",
    "#     'max_dist': 25,\n",
    "#     'kernel_size': 3,\n",
    "#     'sigma': 0.9,\n",
    "# }\n",
    "# slic_params = {\n",
    "#     'n_segments': 10,\n",
    "# }\n",
    "\n",
    "# watershed_params = {\n",
    "#     'markers': 10,\n",
    "#     'watershed_line': True\n",
    "# }\n",
    "\n",
    "# Set segmentation methods\n",
    "methods = []\n",
    "methods.append(('felzenszwalb', felzenszwalb_params))\n",
    "# methods.append(('quickshift', quickshift_params))\n",
    "# methods.append(('slic', slic_params))\n",
    "# methods.append(('watershed', watershed_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file, and class names file\n",
    "config_json = read_json(config_path)\n",
    "config = ConfigParser(config_json, make_dirs=False)\n",
    "class_names = read_lists(class_list_path)\n",
    "\n",
    "# Load model and switch to eval mode\n",
    "layernum = config.config['layernum']\n",
    "device, _ = prepare_device(config['n_gpu'])\n",
    "model = config.init_obj('arch', module_arch, layernum=layernum)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition\n",
    "def segment_semantically(image,\n",
    "            image_id,\n",
    "            methods_params,\n",
    "            model,\n",
    "            device,\n",
    "            target_idx,\n",
    "            seed=None,\n",
    "            save_dir=None,\n",
    "            plot_absolute=True,\n",
    "            debug=False):\n",
    "    \n",
    "    # Create save paths\n",
    "    if save_dir is not None:\n",
    "        ensure_dir(save_dir)\n",
    "        segmentation_save_path = os.path.join(save_dir, 'segmentations.pth')\n",
    "        \n",
    "    else:\n",
    "        segmentation_save_path = None\n",
    "        \n",
    "    # Get logits/softmax of original image\n",
    "    \n",
    "    image_logits = quick_predict(model, image, device)\n",
    "    image_softmax = torch.softmax(image_logits, dim=1)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        # image_outputs_save_path = os.path.join(save_dir, 'image_outputs.pth')\n",
    "        image_save_data = {\n",
    "            'original_logits': image_logits,\n",
    "            'original_softmax': image_softmax\n",
    "        }\n",
    "        \n",
    "    segmentation_data = segment_modify_multi_method(\n",
    "        image=image,\n",
    "        methods_params=methods_params,\n",
    "        seed=seed,\n",
    "        save_path=segmentation_save_path)\n",
    "    \n",
    "    if not torch.is_tensor(image):\n",
    "        image = torch.from_numpy(image).to(device)\n",
    "\n",
    "    logit_image_save_paths = []\n",
    "    softmax_image_save_paths = []\n",
    "    unsuccessful_edit_save_paths = []\n",
    "    mod_types = ['masked', 'gaussian']\n",
    "    for seg_idx, (seg_method, _ )in enumerate(methods_params):\n",
    "        for mod_type in mod_types:\n",
    "            # Create one save object for logits/softmax\n",
    "            save_data = { 'image_data': image_save_data }\n",
    "            \n",
    "            # Create save directory\n",
    "            if save_dir is not None:\n",
    "                local_save_dir = os.path.join(save_dir, \"{}_{}\".format(seg_method, mod_type))\n",
    "                ensure_dir(local_save_dir)\n",
    "                    \n",
    "            # Obtain modified images \n",
    "            modified_images = segmentation_data['{}_modified_images'.format(mod_type)][seg_idx]\n",
    "            n_images = len(modified_images)\n",
    "            \n",
    "            # Pass segments through model\n",
    "            modified_images = np.stack(modified_images, axis=0)\n",
    "            modified_images = torch.from_numpy(modified_images).to(device)\n",
    "            segment_logits = quick_predict(\n",
    "                model=model,\n",
    "                image=modified_images,\n",
    "                device=device, \n",
    "                data_format='CHW')\n",
    "            segment_softmax = torch.softmax(segment_logits, dim=1)\n",
    "            \n",
    "            for out_type in ['logits', 'softmax']:\n",
    "                \n",
    "                if out_type == 'softmax':\n",
    "                    segment_out = segment_softmax\n",
    "                    image_out = image_softmax\n",
    "                else: \n",
    "                    segment_out = segment_logits\n",
    "                    image_out = image_logits\n",
    "\n",
    "                # Sort output by target score\n",
    "                segment_out_target_class = segment_out[:, target_idx]\n",
    "                sorted_idx = torch.argsort(segment_out_target_class, descending=True)\n",
    "\n",
    "                # Sort individual segments and model outputs,\n",
    "                sorted_segments = modified_images[sorted_idx]\n",
    "                sorted_segment_out = segment_out[sorted_idx]\n",
    "                sorted_segment_logits = segment_logits[sorted_idx]\n",
    "                sorted_segment_softmax = segment_softmax[sorted_idx]  \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Prepend original image and its output score to tensors\n",
    "                sorted_segments = torch.cat([torch.unsqueeze(image, dim=0), sorted_segments], dim=0)\n",
    "                sorted_segment_out = torch.cat([image_out, sorted_segment_out], dim=0)\n",
    "                sorted_segment_logits = torch.cat([image_logits, sorted_segment_logits], dim=0)\n",
    "                sorted_segment_softmax = torch.cat([image_softmax, sorted_segment_softmax], dim=0)\n",
    "                \n",
    "                # if out_type == 'softmax':\n",
    "                #     sorted_segment_out = sorted_segment_softmax\n",
    "                # else:\n",
    "                #     sorted_segment_out = sorted_segment_logits\n",
    "                \n",
    "                # Obtain predictions for individual segments\n",
    "                segment_predictions = torch.argmax(sorted_segment_out, dim=1)\n",
    "                segment_prediction_strings = [class_list[pred] for pred in segment_predictions]\n",
    "                \n",
    "                # Isolate output (logits/softmax) for the target idx\n",
    "                segment_target_out = sorted_segment_out[:, target_idx]\n",
    "\n",
    "                # Accumulate sorted segments\n",
    "                accumulation_image = torch.clone(image)\n",
    "                cumulative_images = []\n",
    "                for image_segment in sorted_segments:\n",
    "                    # Isolate segment and add to accumulation_image\n",
    "                    segment = torch.where(image_segment != image, 1, 0)\n",
    "                    accumulation_image = torch.where(segment == 1, image_segment, accumulation_image)\n",
    "                    \n",
    "                    # convert to numpy and Add to list\n",
    "                    cumulative_images.append(accumulation_image)\n",
    "\n",
    "                    \n",
    "                # Stack and convert to torch\n",
    "                cumulative_images = torch.stack(cumulative_images, dim=0)\n",
    "                \n",
    "                # Pass through model\n",
    "                cumulative_logits = quick_predict(\n",
    "                    model=model,\n",
    "                    image=cumulative_images,\n",
    "                    device=device,\n",
    "                    data_format='CHW')\n",
    "                cumulative_softmax = torch.softmax(cumulative_logits, dim=1)\n",
    "                if out_type == 'softmax':\n",
    "                    cumulative_out = cumulative_softmax\n",
    "                else: \n",
    "                    cumulative_out = cumulative_logits\n",
    "                \n",
    "                # Get predictions for all cumulative images\n",
    "                cum_predictions = torch.argmax(cumulative_out, dim=1)\n",
    "                cum_prediction_strings = [class_list[pred] for pred in cum_predictions]\n",
    "                    \n",
    "                # For cumulative images, get logits/softmax at target_idx\n",
    "                cum_target_out = cumulative_out[:, target_idx]  # B x 1\n",
    "                \n",
    "                # Get delta from original image logits/softmax\n",
    "                cum_delta_target_out = cum_target_out - image_out[:, target_idx] # B x 1\n",
    "                segment_delta_target_out = segment_target_out - image_out[:, target_idx] # B x 1\n",
    "\n",
    "                # Find cumulative image index with highest positive change in target_idx\n",
    "                out_argmax = torch.argmax(cum_target_out) # 1 val\n",
    "\n",
    "                # Obtain corresponding image\n",
    "                most_change_image = cumulative_images[out_argmax]\n",
    "                \n",
    "                # Obtain final prediction for this image\n",
    "                most_change_image_out = cumulative_out[out_argmax]  # 1 x 10\n",
    "                most_change_image_prediction = torch.argmax(most_change_image_out)\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                Display and save\n",
    "                '''\n",
    "                # Display segments by ranking and accumulation_image\n",
    "                segment_labels = []\n",
    "                cum_labels =  [] \n",
    "                segment_borders = []\n",
    "                cum_borders = []\n",
    "                '''\n",
    "                Define local function definition\n",
    "                '''\n",
    "                def create_borders_labels(inputs,\n",
    "                                          predictions,\n",
    "                                          logits,\n",
    "                                          softmax,\n",
    "                                          labels_arr, \n",
    "                                          borders_arr):\n",
    "                    for image_idx in range(len(inputs)):\n",
    "                        # Create labels for each image in row\n",
    "                        labels_arr.append(\"N: {}\\nTrue: {}\\nPred: {}\\n[L: {}/S: {}]\".format(\n",
    "                            image_idx,\n",
    "                            class_list[target_idx], \n",
    "                            class_list[predictions[image_idx]],\n",
    "                            round(logits[image_idx, target_idx].item(), 2),\n",
    "                            round(softmax[image_idx, target_idx].item(), 2)))\n",
    "\n",
    "                        # Create borders\n",
    "                        if predictions[image_idx] == target_idx:\n",
    "                            borders_arr.append('green')\n",
    "                        else:\n",
    "                            borders_arr.append('red')\n",
    "                '''\n",
    "                End local function definition\n",
    "                '''\n",
    "                # Top row is segments, bottom row is cumulative images\n",
    "                for data_type in ['segment', 'cumulative']:\n",
    "                    if data_type == 'segment':\n",
    "                        create_borders_labels(\n",
    "                            inputs=sorted_segments,\n",
    "                            predictions=segment_predictions,\n",
    "                            logits=sorted_segment_logits,\n",
    "                            softmax=sorted_segment_softmax,\n",
    "                            labels_arr=segment_labels,\n",
    "                            borders_arr=segment_borders)\n",
    "                    else:\n",
    "                        create_borders_labels(\n",
    "                            inputs=cumulative_images,\n",
    "                            predictions=cum_predictions,\n",
    "                            logits=cumulative_logits,\n",
    "                            softmax=cumulative_softmax,\n",
    "                            labels_arr=cum_labels,\n",
    "                            borders_arr=cum_borders)\n",
    "                \n",
    "                # Create grid for visualization\n",
    "                fig, axs = show_image_rows(\n",
    "                    images=[sorted_segments.cpu().numpy(), cumulative_images.cpu().numpy()],\n",
    "                    image_titles=[segment_labels, cum_labels],\n",
    "                    image_borders=[segment_borders, cum_borders], \n",
    "                    row_labels=['Indvidual Segments', 'Cumulative Image'],\n",
    "                    figure_title='Sorted by {} scores for {} class ({}) [{}/{}]'.format(out_type, class_list[target_idx], image_id, seg_method, mod_type),\n",
    "                    subplot_padding=2,\n",
    "                    save_path=None,\n",
    "                    show_figure=False)\n",
    "                \n",
    "                # Bold the selected image (if applicable)\n",
    "                if most_change_image_prediction == target_idx:\n",
    "                    plt.setp(axs[1][out_argmax].spines.values(), color='yellow', linewidth=5.0)\n",
    "                    \n",
    "                # Save figure\n",
    "                if save_dir is not None:\n",
    "                    plt.savefig(os.path.join(local_save_dir, '{}_cumulative_modifying.png'.format(out_type)))\n",
    "                if debug:\n",
    "                    plt.show()\n",
    "                # Add to save_data\n",
    "                save_data.update({\n",
    "                    '{}_sorted_segments'.format(out_type): sorted_segments,\n",
    "                    '{}_cum_modifications'.format(out_type): cumulative_images, # B x C x H x W torch.tensor\n",
    "                    '{}_segment_out'.format(out_type): sorted_segment_out.cpu().numpy(), # B x 10 np.array\n",
    "                    '{}_cum_out'.format(out_type): cumulative_out.cpu().numpy(), # B x 10 np.array\n",
    "                    '{}_most_change_image'.format(out_type): most_change_image.cpu().numpy() # C x H x W np.array\n",
    "                })\n",
    "\n",
    "                if save_dir is not None:\n",
    "                    # Save plots\n",
    "                    plot_save_path = os.path.join(local_save_dir, 'target_{}_v_n_images.png')\n",
    "                   \n",
    "                    if not plot_absolute:  # plot changes\n",
    "                        ylabel = 'Change in {} Score for {} class'.format(out_type, class_list[target_idx])\n",
    "                        \n",
    "                        ys = [cum_delta_target_out.cpu().numpy(), \n",
    "                              segment_delta_target_out.cpu().numpy()]\n",
    "                        \n",
    "                    else:  \n",
    "                        ylabel = '{} Score for {} class'.format(out_type, class_list[target_idx])\n",
    "                        ys = [cum_target_out.cpu().numpy(), \n",
    "                              segment_target_out.cpu().numpy()]\n",
    "                    \n",
    "                    # Set non-y-related values\n",
    "                    xlabel = 'Number of Segments Modified'\n",
    "                    xs = [range(n_images+1) for i in range(2)]\n",
    "                    title = '{} vs {}'.format(ylabel, xlabel)\n",
    "                    labels = ['Cumulative segments', 'Individual segments']\n",
    "                    # Mark on graph which is the most changed\n",
    "                    if most_change_image_prediction == target_idx:\n",
    "                        highlight = (out_argmax.cpu().numpy(), torch.max(most_change_image_out).cpu().numpy())\n",
    "                        highlight_label = 'Selected Image'\n",
    "                    else:\n",
    "                        highlight = None\n",
    "                        highlight_label = None\n",
    "                    plot(\n",
    "                        xs=xs,\n",
    "                        ys=ys,\n",
    "                        labels=labels,\n",
    "                        scatter=True,\n",
    "                        line=[True, False],\n",
    "                        title=title.format(out_type),\n",
    "                        xlabel=xlabel,\n",
    "                        ylabel=ylabel.format(out_type),\n",
    "                        highlight=highlight,\n",
    "                        highlight_label=highlight_label,\n",
    "                        save_path=plot_save_path.format(out_type),\n",
    "                        show=debug)\n",
    "                    \n",
    "                    # Save images\n",
    "                    image_save_path = os.path.join(local_save_dir, '{}_{}_{}.png'.format(seg_method, mod_type, out_type))\n",
    "                    save_image(\n",
    "                        most_change_image.cpu().numpy(), \n",
    "                        image_save_path)\n",
    "                    \n",
    "                    if most_change_image_prediction == target_idx:\n",
    "                        if out_type == 'softmax':\n",
    "                            softmax_image_save_paths.append(image_save_path)\n",
    "                        else:\n",
    "                            logit_image_save_paths.append(image_save_path)\n",
    "                    else:\n",
    "                        unsuccessful_edit_save_paths.append(image_save_path)\n",
    "\n",
    "            if save_dir is not None:\n",
    "                # Save torch data\n",
    "                torch_save_path = os.path.join(local_save_dir, 'cumulative_segment_results.pth')\n",
    "                torch.save(save_data, torch_save_path)\n",
    "                \n",
    "                    \n",
    "    return logit_image_save_paths, softmax_image_save_paths, unsuccessful_edit_save_paths\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = key_images[0]\n",
    "print(image_path)\n",
    "image = load_image(image_path, data_format='CHW')\n",
    "image_id = get_image_id(image_path)\n",
    "class_idx = class_to_idx_dict[target_class]\n",
    "image_save_dir = os.path.join(save_dir_root, image_id)\n",
    "\n",
    "informal_log(\"Target idx: {}\".format(class_idx), log_path)\n",
    "informal_log('Image save directory: {}'.format(image_save_dir), log_path)\n",
    "\n",
    "segment_semantically(\n",
    "        image=image,\n",
    "        image_id=image_id,\n",
    "        methods_params=methods,\n",
    "        model=model,\n",
    "        device=device,\n",
    "        target_idx=class_idx,\n",
    "        seed=seed,\n",
    "        save_dir=image_save_dir,\n",
    "        debug=debug)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through modification method for all key images of specified class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_idx = class_to_idx_dict[target_class]\n",
    "key_paths_logits = []\n",
    "key_paths_softmax = []\n",
    "key_paths_failures = []\n",
    "value_paths_logits = []\n",
    "value_paths_softmax = []\n",
    "value_paths_failures = []\n",
    "all_value_dirs = []\n",
    "\n",
    "for idx, image_path in enumerate(key_images):\n",
    "    informal_log(\"[{}] Trial {}/{} with image {}...\".format(\n",
    "        datetime.now().strftime(r'%m%d_%H%M%S'),\n",
    "        idx+1,\n",
    "        len(key_images),\n",
    "        image_path), log_path)\n",
    "    \n",
    "    # Load image, get ID, create save directory\n",
    "    image = load_image(image_path, data_format='CHW')\n",
    "    image_id = get_image_id(image_path)\n",
    "    image_save_dir = os.path.join(save_dir_root, image_id)\n",
    "    \n",
    "    # Run semantic segmentation-modification method\n",
    "    logit_save_image_paths, \\\n",
    "        softmax_save_image_paths, \\\n",
    "        unsucessful_edit_save_paths = segment_semantically(\n",
    "            image=image,\n",
    "            image_id=image_id,\n",
    "            methods_params=methods,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            target_idx=class_idx,\n",
    "            seed=seed,\n",
    "            save_dir=image_save_dir,\n",
    "            debug=debug)\n",
    "    \n",
    "    informal_log(\"[{}] Saved results to {}\".format(datetime.now().strftime(r'%m%d_%H%M%S'), image_save_dir), \n",
    "         log_path)\n",
    "    \n",
    "    # Create correct number of key paths\n",
    "    key_paths_l = [image_path for i in range(len(logit_save_image_paths))]\n",
    "    key_paths_s = [image_path for i in range(len(softmax_save_image_paths))]\n",
    "    key_paths_f = [image_path for i in range(len(unsucessful_edit_save_paths))]\n",
    "    \n",
    "    # Append to key paths lists\n",
    "    key_paths_logits += key_paths_l\n",
    "    key_paths_softmax += key_paths_s\n",
    "    key_paths_failures += key_paths_f\n",
    "    \n",
    "    # Append to value paths lists\n",
    "    value_paths_logits += logit_save_image_paths\n",
    "    value_paths_softmax += softmax_save_image_paths\n",
    "    value_paths_failures += unsucessful_edit_save_paths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save paths\n",
    "write_lists(os.path.join(path_save_dir, 'key_images_logits.txt'), key_paths_logits)\n",
    "write_lists(os.path.join(path_save_dir, 'key_images_softmax.txt'), key_paths_softmax)\n",
    "write_lists(os.path.join(path_save_dir, 'key_images_failures.txt'), key_paths_failures)\n",
    "\n",
    "write_lists(os.path.join(path_save_dir, 'value_images_logits.txt'), value_paths_logits)\n",
    "write_lists(os.path.join(path_save_dir, 'value_images_softmax.txt'), value_paths_softmax)\n",
    "write_lists(os.path.join(path_save_dir, 'value_images_failures.txt'), value_paths_failures)\n",
    "\n",
    "print(\"Wrote paths to {}\".format(path_save_dir))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post modifications: graph target softmax - argmax of remaining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 'airplane'\n",
    "n_select = 100\n",
    "paths_timestamp = '0126_161209'\n",
    "value_paths_path = os.path.join('paths', \n",
    "                                'edits', \n",
    "                                'semantics', \n",
    "                                '{}_{}'.format(target_class, n_select), \n",
    "                                paths_timestamp, \n",
    "                                'value_images_softmax.txt')\n",
    "\n",
    "value_paths = read_lists(value_paths_path)\n",
    "target_class_idx = class_to_idx_dict[target_class]\n",
    "\n",
    "for path_idx, value_path in enumerate(tqdm(value_paths)):\n",
    "    pwd = os.path.dirname(value_path)\n",
    "    cumulative_segments = torch.load(os.path.join(pwd, 'cumulative_segment_results.pth'))\n",
    "    \n",
    "    softmaxes = cumulative_segments['softmax_cum_out']\n",
    "    target_class_softmax = softmaxes[:, target_class_idx]\n",
    "    selected_idx = np.argmax(target_class_softmax)\n",
    "    selected_target_softmax = np.amax(target_class_softmax)\n",
    "    \n",
    "    other_class_idxs = []\n",
    "    for i in range(len(class_list)):\n",
    "        if i != target_class_idx:\n",
    "            other_class_idxs.append(i)\n",
    "    other_class_softmax = np.copy(softmaxes)\n",
    "    other_class_softmax[:, target_class_idx] = np.zeros_like(target_class_softmax)\n",
    "    \n",
    "    non_target_max = np.amax(other_class_softmax, axis=1)\n",
    "    non_target_argmax = np.argmax(other_class_softmax, axis=1)\n",
    "    \n",
    "    softmax_diff = target_class_softmax - non_target_max\n",
    "    max_non_target_class = [class_list[i] for i in non_target_argmax]\n",
    "    \n",
    "    xs = [i for i in range(softmaxes.shape[0])]\n",
    "    xlabel = 'Number of Segments Modified'\n",
    "    ylabel = 'Target Softmax - Highest Softmax [excl. target]'\n",
    "    fig, ax = plot(\n",
    "        xs=[xs],\n",
    "        ys=[softmax_diff],\n",
    "        point_annotations=[max_non_target_class],\n",
    "        ylimits=[-1, 1],\n",
    "        title='{} vs.\\n{}'.format(ylabel, xlabel),\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        scatter=True,\n",
    "        line=True,\n",
    "        highlight=(selected_idx, target_class_softmax[selected_idx] - non_target_max[selected_idx]),\n",
    "        show=False)\n",
    "    ax.plot(\n",
    "        [0, softmaxes.shape[0]],\n",
    "        [0, 0],\n",
    "        'r--')\n",
    "    \n",
    "    save_path = os.path.join(pwd, 'softmax_delta_v_n_images.png')\n",
    "    plt.savefig(save_path)\n",
    "    # plt.show()\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "308e6c6b8b936526d9e5740fbb6d189809c67403351ef790dfc7ad94346820d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
