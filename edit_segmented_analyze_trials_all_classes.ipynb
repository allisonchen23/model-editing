{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide list of paths for edits and run trials for all 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists, informal_log, list_to_dict, write_lists, write_json, ensure_files\n",
    "from utils.model_utils import prepare_device\n",
    "from parse_config import ConfigParser\n",
    "# from data_loader import data_loaders\n",
    "import datasets.datasets as module_data\n",
    "import model.model as module_arch\n",
    "from utils.knn_utils import load_and_analyze_knn\n",
    "from utils.results_to_csv import store_csv\n",
    "from edit_knn import main as edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants, paths\n",
    "config_path = 'configs/copies/cinic10_imagenet_segmentation_edit_trials.json'\n",
    "class_list_path = 'metadata/cinic-10/class_names.txt'\n",
    "\n",
    "analyze_in_edit = True\n",
    "sort_type = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_dict = read_json(config_path)\n",
    "# Load class list and obtain target class idx\n",
    "class_list = read_lists(class_list_path)\n",
    "class_idx_dict = list_to_dict(class_list)\n",
    "\n",
    "n_select = 100\n",
    "\n",
    "# Set K\n",
    "K = config_dict['editor']['K']\n",
    "\n",
    "device, device_ids = prepare_device(config_dict['n_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_loader_args = dict(config_dict[\"data_loader\"][\"args\"])\n",
    "dataset_args = dict(config_dict[\"dataset_args\"])\n",
    "\n",
    "# Create validation data loader\n",
    "val_image_paths = read_lists(config_dict['dataset_paths']['valid_images'])\n",
    "val_labels = read_lists(config_dict['dataset_paths']['valid_labels'])\n",
    "val_paths_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=val_image_paths,\n",
    "        labels=val_labels,\n",
    "        return_paths=True,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")\n",
    "\n",
    "# Create data loader for covariance matrix\n",
    "covariance_image_paths = read_lists(config_dict['covariance_dataset']['images'])\n",
    "covariance_labels = read_lists(config_dict['covariance_dataset']['labels'])\n",
    "\n",
    "covariance_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=covariance_image_paths,\n",
    "        labels=covariance_labels,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain timestamp\n",
    "paths_timestamp = '0126_161209'\n",
    "timestamp = datetime.now().strftime(r'%m%d_%H%M%S')\n",
    "# timestamp = '0120_155829'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current target class: automobile\n",
      "Printing progress reports to saved/edit/trials/CINIC10_ImageNet-VGG_16/automobile_100/0131_171733/progress_report.txt\n",
      "Saving path to directories for each trial to saved/edit/trials/CINIC10_ImageNet-VGG_16/automobile_100/0131_171733/trial_paths.txt\n",
      "Key image paths stored at paths/edits/semantics/automobile_100/0126_161209/key_images_softmax.txt\n",
      "Value image paths stored at paths/edits/semantics/automobile_100/0126_161209/value_images_softmax.txt\n",
      "(0131_171735) Starting Trial 1/122...\n",
      "Current run_id: automobile_100/0131_171733/results/automobile-train-n04037443_3590/felzenszwalb_masked_softmax\n",
      "saved/edit/trials/CINIC10_ImageNet-VGG_16/automobile_100/0131_171733/automobile_100/0131_171733/results/automobile-train-n04037443_3590/felzenszwalb_masked_softmax\n",
      "Calling edit()...\n",
      "Created CIFAR10PretrainedModelEdit model with 33646666 trainable parameters\n",
      "Restored weights from external_code/PyTorch_CIFAR10/cifar10_models/state_dicts/vgg16_bn.pt\n",
      "Using passed in data loader for validation.\n",
      "Key images: data/cinic-10-imagenet/train/automobile/n04037443_3590.png\n",
      "Value images: saved/segmentations/semantics/automobile_100/automobile-train-n04037443_3590/felzenszwalb_masked/felzenszwalb_masked_softmax.png\n",
      "Masks: None\n",
      "Prepared data for editing\n",
      "Performing pre-edit metric & KNN calculations on validation set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 274/274 [00:08<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-edit metrics: {'TP': array([6142, 5382, 5202, 3841, 4270, 2990, 5659, 5135, 4819, 4679]), 'TN': array([60112, 61110, 59444, 59899, 60157, 61754, 61051, 61747, 61643,\n",
      "       61202]), 'FPs': array([2888, 1890, 3556, 3101, 2843, 1246, 1949, 1253, 1357, 1798]), 'FNs': array([ 858, 1618, 1798, 3159, 2730, 4010, 1341, 1865, 2181, 2321]), 'accuracy': 0.6874142857142858, 'per_class_accuracy': array([0.94648571, 0.94988571, 0.92351429, 0.91057143, 0.92038571,\n",
      "       0.92491429, 0.953     , 0.95545714, 0.94945714, 0.94115714]), 'per_class_accuracy_mean': 0.9374828571428573, 'precision': array([0.68017719, 0.74009901, 0.59397123, 0.55329876, 0.60030929,\n",
      "       0.70585458, 0.74382229, 0.80385097, 0.7802785 , 0.72240235]), 'precision_mean': 0.6924064164231064, 'recall': array([0.87742857, 0.76885714, 0.74314286, 0.54871429, 0.61      ,\n",
      "       0.42714286, 0.80842857, 0.73357143, 0.68842857, 0.66842857]), 'recall_mean': 0.6874142857142858, 'predicted_class_distribution': array([9030, 7272, 8758, 6942, 7113, 4236, 7608, 6388, 6176, 6477]), 'f1': array([0.76631316, 0.75420404, 0.66023607, 0.55099699, 0.60511585,\n",
      "       0.53221787, 0.77478094, 0.76710487, 0.73148148, 0.69436818]), 'f1_mean': 0.6836819454837861}\n",
      "Saved pre-edit metrics to saved/edit/trials/CINIC10_ImageNet-VGG_16/automobile_100/0131_171733/automobile_100/0131_171733/results/automobile-train-n04037443_3590/felzenszwalb_masked_softmax/models/pre_edit_metrics.pth\n",
      "Saved pre-edit KNN results with K=100 to saved/edit/trials/CINIC10_ImageNet-VGG_16/automobile_100/0131_171733/automobile_100/0131_171733/results/automobile-train-n04037443_3590/felzenszwalb_masked_softmax/models/pre_edit_100-nn.pth\n",
      "Using passed in covariance data loader.\n",
      "Looking for covariance matrix weights in cache/cinic-10-imagenet-dummy/vgg16_bn-12\n",
      "Found precomputed cov matrices, returning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>):  97%|██████▊| 38626/40000 [00:47<00:01, 821.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 90\u001b[0m\n\u001b[1;32m     86\u001b[0m informal_log(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(config\u001b[38;5;241m.\u001b[39msave_dir), save_trials_path)\n\u001b[1;32m     88\u001b[0m informal_log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling edit()...\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_report_path)\n\u001b[0;32m---> 90\u001b[0m \u001b[43medit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_paths_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_paths_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariance_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariance_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_analyze_knn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_in_edit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Print progress\u001b[39;00m\n\u001b[1;32m     97\u001b[0m informal_log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished trial \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Results saved to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_trials, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(config\u001b[38;5;241m.\u001b[39msave_dir)),\n\u001b[1;32m     98\u001b[0m             progress_report_path)\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/edit_knn.py:218\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config, val_paths_data_loader, covariance_data_loader, do_analyze_knn)\u001b[0m\n\u001b[1;32m    216\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m'\u001b[39m, val_data_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_arch, layernum))\n\u001b[1;32m    217\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLooking for covariance matrix weights in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(cache_dir))\n\u001b[0;32m--> 218\u001b[0m     \u001b[43meditor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43medit_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medit_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariance_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     editor\u001b[38;5;241m.\u001b[39mrandom_edit(\n\u001b[1;32m    225\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/src/trainer/editor.py:75\u001b[0m, in \u001b[0;36mEditor.edit\u001b[0;34m(self, edit_data, model, val_data_loader, cache_dir)\u001b[0m\n\u001b[1;32m     71\u001b[0m         n_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel[layernum \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfinal\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39min_channels\n\u001b[1;32m     73\u001b[0m     key_method \u001b[38;5;241m=\u001b[39m n_features\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_model \u001b[38;5;241m=\u001b[39m \u001b[43medit_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# layernum=layernum,\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medit_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m edited_weights \u001b[38;5;241m=\u001b[39m get_target_weights(target_model)\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_diff \u001b[38;5;241m=\u001b[39m edited_weights \u001b[38;5;241m-\u001b[39m original_weights\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/external_code/EditingClassifiers/helpers/rewrite_helpers.py:146\u001b[0m, in \u001b[0;36medit_classifier\u001b[0;34m(args, train_data, context_model, target_model, val_loader, key_method, caching_dir)\u001b[0m\n\u001b[1;32m    140\u001b[0m     kstar \u001b[38;5;241m=\u001b[39m (kstar[\u001b[38;5;241m0\u001b[39m][Nims\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone(),\n\u001b[1;32m    141\u001b[0m              kstar[\u001b[38;5;241m1\u001b[39m][Nims\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39march\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m kstar[Nims\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    144\u001b[0m     mstar \u001b[38;5;241m=\u001b[39m ch\u001b[38;5;241m.\u001b[39mmax(cp_masks[:Nims\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 146\u001b[0m     \u001b[43medit_classifier_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvstar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcontext_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mpiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsteps_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mlow_rank_insert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestrict_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmstar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39march \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/external_code/EditingClassifiers/helpers/rewrite_helpers.py:84\u001b[0m, in \u001b[0;36medit_classifier_weights\u001b[0;34m(target_model, key, val, context, niter, piter, lr, low_rank_insert, low_rank_gradient, unfold, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m---> 84\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     86\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/external_code/EditingClassifiers/helpers/rewrite_helpers.py:64\u001b[0m, in \u001b[0;36medit_classifier_weights.<locals>.compute_loss\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 64\u001b[0m     reps \u001b[38;5;241m=\u001b[39m val, \u001b[43mtarget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         mask \u001b[38;5;241m=\u001b[39m downscale_mask(mask, val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/nn/modules/module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for target_class_idx, target_class_name in enumerate(class_list):\n",
    "    # Create save directories and logging paths\n",
    "    save_root = os.path.join(\n",
    "        config_dict['trainer']['save_dir'], \n",
    "        config_dict['name'], \n",
    "        '{}_{}'.format(target_class_name, n_select), \n",
    "        timestamp)\n",
    "    \n",
    "    save_trials_path = os.path.join(save_root, 'trial_paths.txt')\n",
    "    progress_report_path = os.path.join(save_root, 'progress_report.txt')\n",
    "    informal_log(\"Current target class: {}\".format(target_class_name), progress_report_path)\n",
    "    \n",
    "    \n",
    "    if os.path.exists(save_trials_path):\n",
    "        print(\"Path {} already exists. Overwriting.\".format(save_trials_path))\n",
    "    else:\n",
    "        if os.path.exists(progress_report_path):\n",
    "            os.remove(progress_report_path)\n",
    "        print(\"Printing progress reports to {}\".format(progress_report_path))\n",
    "        informal_log(\"Saving path to directories for each trial to {}\".format(save_trials_path), progress_report_path)\n",
    "    \n",
    "    # Obtain paths for keys and values\n",
    "    paths_dir = os.path.join('paths', 'edits', 'semantics', '{}_{}'.format(target_class_name, n_select), paths_timestamp)\n",
    "    key_image_paths_path = os.path.join(paths_dir, 'key_images_{}.txt'.format(sort_type))\n",
    "    key_image_paths = read_lists(key_image_paths_path)\n",
    "\n",
    "    value_image_paths_path = os.path.join(paths_dir, 'value_images_{}.txt'.format(sort_type))\n",
    "    value_image_paths = read_lists(value_image_paths_path)\n",
    "    n_trials = len(value_image_paths)\n",
    "    assert len(key_image_paths) == n_trials\n",
    "\n",
    "    # print(\"{} edit image pairs\".format(n_trials))\n",
    "    # print(\"First key image path: {}\".format(key_image_paths[0]))\n",
    "    # print(\"First value image path: {}\".format(value_image_paths[0]))\n",
    "    \n",
    "    # Ensure all keys and value paths exist\n",
    "    # non_existent_key_paths = []\n",
    "    # non_existent_value_paths = []\n",
    "    # for key_path, value_path in zip(key_image_paths, value_image_paths):\n",
    "    #     if not os.path.exists(key_path):\n",
    "    #         non_existent_key_paths.append(key_path)\n",
    "    #     if not os.path.exists(value_path):\n",
    "    #         non_existent_value_paths.append(value_path)\n",
    "\n",
    "    non_existent_key_paths = ensure_files(key_image_paths)\n",
    "    non_existent_value_paths = ensure_files(value_image_paths)\n",
    "    \n",
    "    if len(non_existent_key_paths) > 0:\n",
    "        raise ValueError(\"Following paths are non existent: {}\".format(non_existent_key_paths))\n",
    "\n",
    "    if len(non_existent_value_paths) > 0:\n",
    "        raise ValueError(\"Following paths are non existent: {}\".format(non_existent_value_paths))\n",
    "        \n",
    "    informal_log(\"Key image paths stored at {}\".format(key_image_paths_path), progress_report_path)\n",
    "    informal_log(\"Value image paths stored at {}\".format(value_image_paths_path), progress_report_path)\n",
    "    \n",
    "    # Run edit for each key and value pair\n",
    "    for idx, (key_path, value_path) in enumerate(zip(key_image_paths, value_image_paths)):\n",
    "        split = os.path.basename(os.path.dirname(os.path.dirname(key_path)))\n",
    "        class_name = os.path.basename(os.path.dirname(key_path))\n",
    "        file_name = os.path.basename(key_path).split(\".\")[0]\n",
    "        key_image_id = \"{}-{}-{}\".format(class_name, split, file_name)\n",
    "        # Print Progress\n",
    "        informal_log(\"({}) Starting Trial {}/{}...\".format(datetime.now().strftime(r'%m%d_%H%M%S'), idx + 1, n_trials), progress_report_path)\n",
    "\n",
    "        # Create run id \n",
    "        value_image_id = os.path.splitext(os.path.basename(value_path))[0]\n",
    "        run_id = os.path.join('{}_{}'.format(target_class_name, n_select), timestamp, 'results', key_image_id, value_image_id)\n",
    "        informal_log(\"Current run_id: {}\".format(run_id), progress_report_path)\n",
    "\n",
    "        # Read config file as json and make updates to key and value paths\n",
    "        config_dict = read_json(config_path)\n",
    "        config_dict['editor'].update({\n",
    "            'key_paths_file': key_path,\n",
    "            'value_paths_file': value_path\n",
    "        })\n",
    "        config_dict['trainer']['save_dir'] = save_root\n",
    "        config_dict['name'] = ''\n",
    "\n",
    "        # Create config object\n",
    "        config = ConfigParser(config_dict, run_id=run_id)\n",
    "\n",
    "        # Log the current trial path\n",
    "        informal_log(os.path.dirname(config.save_dir), save_trials_path)\n",
    "\n",
    "        informal_log(\"Calling edit()...\", progress_report_path)\n",
    "\n",
    "        edit(\n",
    "            config=config,\n",
    "            val_paths_data_loader=val_paths_data_loader,\n",
    "            covariance_data_loader=covariance_data_loader,\n",
    "            do_analyze_knn=analyze_in_edit)\n",
    "\n",
    "        # Print progress\n",
    "        informal_log(\"Finished trial {}/{}. Results saved to {}\".format(idx + 1, n_trials, os.path.dirname(config.save_dir)),\n",
    "                    progress_report_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "# target_class_name = 'airplane'\n",
    "# n_select = 100\n",
    "# paths_dir = os.path.join('paths', 'edits', 'semantics', '{}_{}'.format(target_class_name, n_select), paths_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_image_paths_path = os.path.join(paths_dir, 'key_images_{}.txt'.format(sort_type))\n",
    "# key_image_paths = read_lists(key_image_paths_path)\n",
    "\n",
    "# value_image_paths_path = os.path.join(paths_dir, 'value_images_{}.txt'.format(sort_type))\n",
    "# value_image_paths = read_lists(value_image_paths_path)\n",
    "# n_trials = len(value_image_paths)\n",
    "# assert len(key_image_paths) == n_trials\n",
    "\n",
    "# print(\"{} edit image pairs\".format(n_trials))\n",
    "# print(\"First key image path: {}\".format(key_image_paths[0]))\n",
    "# print(\"First value image path: {}\".format(value_image_paths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log and save paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create log path to store the paths to each trial\n",
    "# save_root = config_dict['trainer']['save_dir']\n",
    "# save_trials_path = os.path.join(save_root, config_dict['name'], timestamp, 'trial_paths.txt')\n",
    "# progress_report_path = os.path.join(save_root, config_dict['name'], timestamp, 'progress_report.txt')\n",
    "# if os.path.exists(save_trials_path):\n",
    "#     # os.remove(save_trials_path)\n",
    "#     print(\"Path {} already exists. Aborting.\".format(save_trials_path))\n",
    "# else:\n",
    "#     # progress_report_path = os.path.join(save_root, config_dict['name'], timestamp, 'progress_report.txt')\n",
    "#     if os.path.exists(progress_report_path):\n",
    "#         os.remove(progress_report_path)\n",
    "#     print(\"Saving path to directories for each trial to {}\".format(save_trials_path))\n",
    "#     print(\"Printing progress reports to {}\".format(progress_report_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure all paths for keys and values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_existent_key_paths = []\n",
    "# non_existent_value_paths = []\n",
    "# for key_path, value_path in zip(key_image_paths, value_image_paths):\n",
    "#     if not os.path.exists(key_path):\n",
    "#         non_existent_key_paths.append(key_path)\n",
    "#     if not os.path.exists(value_path):\n",
    "#         non_existent_value_paths.append(value_path)\n",
    "\n",
    "# if len(non_existent_key_paths) > 0:\n",
    "#     raise ValueError(\"Following paths are non existent: {}\".format(non_existent_key_paths))\n",
    "    \n",
    "# if len(non_existent_value_paths) > 0:\n",
    "#     raise ValueError(\"Following paths are non existent: {}\".format(non_existent_value_paths))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log where key and val image paths are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informal_log(\"Key image paths stored at {}\".format(key_image_paths_path), progress_report_path)\n",
    "# informal_log(\"Value image paths stored at {}\".format(value_image_paths_path), progress_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run edit for each modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for idx, (key_path, value_path) in enumerate(zip(key_image_paths, value_image_paths)):\n",
    "#     split = os.path.basename(os.path.dirname(os.path.dirname(key_path)))\n",
    "#     class_name = os.path.basename(os.path.dirname(key_path))\n",
    "#     file_name = os.path.basename(key_path).split(\".\")[0]\n",
    "#     key_image_id = \"{}-{}-{}\".format(class_name, split, file_name)\n",
    "#     # Print Progress\n",
    "#     informal_log(\"({}) Starting Trial {}/{}...\".format(datetime.now().strftime(r'%m%d_%H%M%S'), idx + 1, n_trials), progress_report_path)\n",
    "    \n",
    "#     # Create run id \n",
    "#     value_image_id = os.path.splitext(os.path.basename(value_path))[0]\n",
    "#     run_id = os.path.join('{}_{}'.format(target_class_name, n_select), timestamp, 'results', key_image_id, value_image_id)\n",
    "#     informal_log(\"Current run_id: {}\".format(run_id), progress_report_path)\n",
    "    \n",
    "#     # Read config file as json and make updates to key and value paths\n",
    "#     config_dict = read_json(config_path)\n",
    "#     config_dict['editor'].update({\n",
    "#         'key_paths_file': key_path,\n",
    "#         'value_paths_file': value_path\n",
    "#     })\n",
    "    \n",
    "#     # Create config object\n",
    "#     config = ConfigParser(config_dict, run_id=run_id)\n",
    "    \n",
    "#     # Log the current trial path\n",
    "#     informal_log(os.path.dirname(config.save_dir), save_trials_path)\n",
    "    \n",
    "#     informal_log(\"Calling edit()...\", progress_report_path)\n",
    "    \n",
    "#     edit(\n",
    "#         config=config,\n",
    "#         val_paths_data_loader=val_paths_data_loader,\n",
    "#         covariance_data_loader=covariance_data_loader,\n",
    "#         do_analyze_knn=analyze_in_edit)\n",
    "    \n",
    "#     # Print progress\n",
    "#     informal_log(\"Finished trial {}/{}. Results saved to {}\".format(idx + 1, n_trials, os.path.dirname(config.save_dir)),\n",
    "#                 progress_report_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trials_path = 'saved/edit/trials/CINIC10_ImageNet-VGG_16/0125_114341/trial_paths.txt'\n",
    "trial_dirs = read_lists(save_trials_path)\n",
    "knn_analysis_filename = 'knn_analysis_results.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not os.path.exists(save_trials_path):\n",
    "        print(\"Path {} does not exist\".format(save_trials_path))\n",
    "    else:\n",
    "        print(\"Obtaining trial paths from {}\".format(save_trials_path))\n",
    "except:\n",
    "    print(\"Need to define save_trials_path.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process KNN results for each\n",
    "n_trials = len(trial_dirs)\n",
    "n_log = n_trials // 10 + 1  # log every 10%\n",
    "progress_report_path = os.path.join(os.path.dirname(save_trials_path), 'progress_report_analysis.txt')\n",
    "\n",
    "informal_log(\"Starting KNN analysis...\", progress_report_path)\n",
    "for trial_idx, trial_dir in tqdm(enumerate(trial_dirs)):\n",
    "    # if trial_idx % n_log == 0:\n",
    "    informal_log(\"Processing {}/{} trials. Currently processing {}\".format(\n",
    "        trial_idx+1, n_trials, os.path.basename(trial_dir)), progress_report_path)\n",
    "                     \n",
    "    results_save_dir = os.path.join(trial_dir, 'models')\n",
    "    load_and_analyze_knn(\n",
    "        restore_dir=results_save_dir,\n",
    "        pre_edit_knn_path=os.path.join(results_save_dir, 'pre_edit_{}-nn.pth'.format(K)),\n",
    "        post_edit_knn_path=os.path.join(results_save_dir, 'post_edit_{}-nn.pth'.format(K)),\n",
    "        knn_analysis_filename=knn_analysis_filename,\n",
    "        target_class_idx=target_class_idx,\n",
    "        class_list=class_list,\n",
    "        progress_report_path=progress_report_path,\n",
    "        save_images=False,\n",
    "        save_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV for all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_path = os.path.join(os.path.dirname(save_trials_path), 'results_table.csv')\n",
    "store_csv(\n",
    "    trial_dirs=trial_dirs,\n",
    "    class_list=class_list,\n",
    "    save_path=csv_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
