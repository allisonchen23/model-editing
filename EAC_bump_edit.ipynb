{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Edits that match post edit class distribution of target class to real edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import collections\n",
    "\n",
    "import warnings\n",
    "from argparse import Namespace\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from helpers import classifier_helpers\n",
    "import helpers.data_helpers as dh\n",
    "import helpers.context_helpers as coh\n",
    "import helpers.rewrite_helpers as rh\n",
    "import helpers.vis_helpers as vh\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/n/fs/ac-editing/model-editing/src', '/n/fs/ac-editing/model-editing/external_code/EditingClassifiersRepo', '/n/fs/ac-project/anaconda3/envs/editing/lib/python38.zip', '/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8', '/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/lib-dynload', '', '/u/ac4802/.local/lib/python3.8/site-packages', '/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '/n/fs/ac-editing/model-editing/src')\n",
    "print(sys.path)\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "from utils.model_utils import prepare_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'ImageNet'\n",
    "LAYERNUM = 12\n",
    "REWRITE_MODE = 'editing'\n",
    "ARCH = 'vgg16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset imagenet..\n"
     ]
    }
   ],
   "source": [
    "base_dataset, train_loader, val_loader = dh.get_dataset(DATASET_NAME, DATASET_PATH,\n",
    "                                                        batch_size=32, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = classifier_helpers.get_default_paths(DATASET_NAME, arch=ARCH)\n",
    "DATASET_PATH, MODEL_PATH, MODEL_CLASS, ARCH, CD = ret\n",
    "ret = classifier_helpers.load_classifier(MODEL_PATH, MODEL_CLASS, ARCH,\n",
    "                            DATASET_NAME, LAYERNUM) \n",
    "model, context_model, target_model = ret[:3]\n",
    "n_classes = len(CD) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data stats...\n",
      "ImageNet class: school bus; # Images: 22 \n",
      "\n",
      "ImageNet class: motor scooter, scooter; # Images: 21 \n",
      "\n",
      "ImageNet class: traffic light, traffic signal, stoplight; # Images: 9 \n",
      "\n",
      "ImageNet class: fire engine, fire truck; # Images: 20 \n",
      "\n",
      "ImageNet class: tank, army tank, armored combat vehicle, armoured combat vehicle; # Images: 17 \n",
      "\n",
      "ImageNet class: racer, race car, racing car; # Images: 20 \n",
      "\n",
      "ImageNet class: car wheel; # Images: 20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = dh.get_vehicles_on_snow_data(DATASET_NAME, CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({803: 23, 802: 21, 555: 18, 779: 14, 847: 8, 751: 8, 479: 8, 920: 6, 670: 5, 408: 4, 609: 2, 829: 1, 665: 1, 450: 1, 348: 1, 928: 1, 471: 1, 874: 1, 586: 1, 866: 1, 961: 1, 717: 1, 643: 1}) Counter({779: 17, 555: 17, 751: 17, 803: 15, 670: 9, 847: 9, 479: 9, 802: 8, 920: 7, 408: 3, 665: 2, 609: 2, 866: 2, 829: 1, 450: 1, 348: 1, 928: 1, 251: 1, 471: 1, 867: 1, 874: 1, 586: 1, 961: 1, 717: 1, 643: 1})\n",
      "[0, 3, 1, 1, 1, 4, 0, 13, 8, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 9, 1]\n"
     ]
    }
   ],
   "source": [
    "# Load post edit counter\n",
    "restore_dir = os.path.join('edited_checkpoints', 'vehicles_on_snow')\n",
    "post_edit_counter = torch.load(os.path.join(restore_dir, 'post_edit_counter.pth'))\n",
    "pre_edit_counter = torch.load(os.path.join(restore_dir, 'pre_edit_counter.pth'))\n",
    "\n",
    "print(pre_edit_counter, post_edit_counter)\n",
    "# Sort classes based on largest change\n",
    "all_classes = list(set(list(pre_edit_counter.keys()) + list(post_edit_counter.keys())))\n",
    "deltas = []\n",
    "for class_idx in all_classes:\n",
    "    pre_edit_count = pre_edit_counter[class_idx] if class_idx in pre_edit_counter else 0\n",
    "    post_edit_count = post_edit_counter[class_idx] if class_idx in post_edit_counter else 0\n",
    "    deltas.append(np.abs(post_edit_count - pre_edit_count))\n",
    "print(deltas)\n",
    "# Sorts in ascending order\n",
    "sorted_idxs = np.argsort(deltas)\n",
    "sorted_idxs = np.flip(sorted_idxs)\n",
    "\n",
    "# Two lists with corresponding classes and amount they changed by\n",
    "deltas_sorted = np.array(deltas)[sorted_idxs]\n",
    "classes_sorted = np.array(all_classes)[sorted_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get device and metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'per_class_accuracy', 'recall', 'precision', 'f1', 'predicted_class_distribution']\n",
    "metric_fns = [getattr(module_metric, met) for met in metrics]\n",
    "\n",
    "device, device_ids = prepare_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_bump(data_loader,\n",
    "                      model,\n",
    "                      loss_fn,\n",
    "                      metric_fns,\n",
    "                      device,\n",
    "                      # target_class_idx=0,\n",
    "                      bump_amounts,\n",
    "                      output_save_path=None,\n",
    "                      log_save_path=None):\n",
    "    '''\n",
    "    Run the model on the data_loader, calculate metrics, and log\n",
    "\n",
    "    Arg(s):\n",
    "        data_loader : torch Dataloader\n",
    "            data to test on\n",
    "        model : torch.nn.Module\n",
    "            model to run\n",
    "        loss_fn : module\n",
    "            loss function\n",
    "        metric_fns : list[model.metric modules]\n",
    "            list of metric functions\n",
    "        device : torch.device\n",
    "            device to move data to\n",
    "        bump_amounts :  np.array(float)\n",
    "            array of bump amounts \n",
    "        output_save_path : str or None\n",
    "            if not None, save model_outputs to save_path\n",
    "        log_save_path : str or None\n",
    "            if not None, save metrics to save_path\n",
    "\n",
    "    Returns :\n",
    "        log : dict{} of metrics\n",
    "    '''\n",
    "\n",
    "    # Hold data for calculating metrics\n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    # Ensure model is in eval mode\n",
    "    if model.training:\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, item in enumerate(tqdm(data_loader)):\n",
    "            if len(item) == 3:\n",
    "                data, target, path = item\n",
    "            else:\n",
    "                data, target = item\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            assert output.shape[1] == bump_amounts.shape[0], \\\n",
    "                \"Logits shape: {} bump_amounts shape: {}\".format(output.shape, bump_amounts.shape)\n",
    "            # Store outputs and targets\n",
    "            outputs.append(output)\n",
    "            targets.append(target)\n",
    "            # if idx == 1:\n",
    "            #     break\n",
    "\n",
    "    # Concatenate predictions and targets\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "\n",
    "    # Adjust output softmax by bump amount\n",
    "    # if is instance(bump_amount, np.array):\n",
    "    outputs += torch.tensor(bump_amounts).to(device)\n",
    "    # else: \n",
    "    #     outputs[:, target_class_idx] += bump_amount\n",
    "\n",
    "    # Calculate loss\n",
    "    if loss_fn is not None:\n",
    "        loss = loss_fn(outputs, targets).item()\n",
    "        log.update({'loss': loss})\n",
    "    n_samples = len(data_loader.sampler)\n",
    "\n",
    "    # Calculate predictions based on argmax\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    # Move predictions and target to cpu and convert to numpy to calculate metrics\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    log = module_metric.compute_metrics(\n",
    "        metric_fns=metric_fns,\n",
    "        prediction=predictions,\n",
    "        target=targets)\n",
    "\n",
    "    # Add bump amount to log\n",
    "    \n",
    "    log.update({'bump_amounts': bump_amounts})\n",
    "\n",
    "    if output_save_path is not None:\n",
    "        ensure_dir(os.path.dirname(output_save_path))\n",
    "        torch.save(outputs, output_save_path)\n",
    "\n",
    "    if log_save_path is not None:\n",
    "        ensure_dir(os.path.dirname(log_save_path))\n",
    "        torch.save(log, log_save_path)\n",
    "\n",
    "    return {\n",
    "        'metrics': log,\n",
    "        'logits': outputs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_predict_with_bump(bump_amounts,\n",
    "                      data,\n",
    "                      model,\n",
    "                      debug=True):\n",
    "    \n",
    "    '''\n",
    "    Arg(s):\n",
    "        bump_amounts : C length np.array\n",
    "            bump amount for each class\n",
    "        data : (list(int), B x Ch x H x W torch.tensor)\n",
    "            labels and image data tensors\n",
    "        model : torch.nn.Module\n",
    "            model to make prediction\n",
    "    '''\n",
    "    predictions = []\n",
    "    accuracies = []\n",
    "    all_logits = []\n",
    "    total_correct = 0\n",
    "    if not torch.is_tensor(bump_amounts):\n",
    "        bump_amounts = torch.tensor(bump_amounts)\n",
    "    bump_amounts = bump_amounts.cuda()\n",
    "        \n",
    "    for c, x in data.items():\n",
    "        with torch.no_grad():\n",
    "            logits = model(x.cuda())\n",
    "            assert logits.shape[1] == bump_amounts.shape[0], \"Logits shape: {} bump_amounts shape: {}\".format(logits.shape, bump_amounts.shape)\n",
    "            pred = logits.argmax(axis=1)\n",
    "            predictions.append(pred)\n",
    "            all_logits.append(logits)\n",
    "        correct = [p for p in pred if p == c]\n",
    "        total_correct += len(correct)\n",
    "        acc = 100 * len(correct) / len(x)\n",
    "        if debug:\n",
    "            print(f'Class: {c}/{CD[c]} | Accuracy: {acc:.2f}',) \n",
    "        accuracies.append(acc)\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    counter = collections.Counter(predictions.tolist())\n",
    "    results = {\n",
    "        'predictions': predictions,\n",
    "        'logits': all_logits,\n",
    "        'counter': counter,\n",
    "        'accuracies': accuracies,\n",
    "        'n_correct': total_correct\n",
    "    }\n",
    "    return results\n",
    "        \n",
    "def find_bump_bounds(n_target_predictions,\n",
    "                    target_class_idx,\n",
    "                    n_classes,\n",
    "                    test_data,\n",
    "                    model,\n",
    "                    delta=2,\n",
    "                    debug=True):\n",
    "    # Get baseline predictions\n",
    "    bump_amounts = np.zeros(n_classes)\n",
    "    baseline_predictions, baseline_counter, _ = quick_predict_with_bump(\n",
    "        bump_amounts=bump_amounts,\n",
    "        data=test_data,\n",
    "        model=model,\n",
    "        debug=debug)\n",
    "    \n",
    "    cur_target_predictions = baseline_counter[target_class_idx]\n",
    "    if debug:\n",
    "        print(\"Baseline target predictions: {} Target n predictions: {}\".format(\n",
    "            cur_target_predictions, n_target_predictions))\n",
    "    \n",
    "    # If no need to bump, return now!\n",
    "    if cur_target_predictions == n_target_predictions:\n",
    "        return 0, 0\n",
    "    elif cur_target_predictions < n_target_predictions:\n",
    "        \n",
    "        bump_lower_bound = 0\n",
    "        target_predictions_lower = cur_target_predictions\n",
    "        # Find upper bound\n",
    "        if debug:\n",
    "            print(\"Searching for upper bound...\")\n",
    "        while cur_target_predictions < n_target_predictions:\n",
    "            bump_amounts[target_class_idx] += delta\n",
    "            if debug:\n",
    "                print(\"cur bump amount: {}\".format(bump_amounts[target_class_idx]))\n",
    "            cur_predictions, cur_counter, _ = quick_predict_with_bump(\n",
    "                bump_amounts=bump_amounts,\n",
    "                data=test_data,\n",
    "                model=model,\n",
    "                debug=debug)\n",
    "            cur_target_predictions = cur_counter[target_class_idx]\n",
    "            if debug:\n",
    "                print(\"cur target_predictions: {} target n predictions: {}\".format(\n",
    "                    cur_target_predictions, n_target_predictions))\n",
    "        bump_upper_bound = bump_amounts[target_class_idx]\n",
    "        target_predictions_upper = cur_target_predictions\n",
    "        \n",
    "    elif cur_target_predictions > n_target_predictions:\n",
    "        bump_upper_bound = 0\n",
    "        target_predictions_upper = cur_target_predictions\n",
    "        # Find lower bound\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Searching for lower bound...\")\n",
    "        while cur_target_predictions > n_target_predictions:\n",
    "            bump_amounts[target_class_idx] -= delta\n",
    "            if debug:\n",
    "                print(\"cur bump amount: {}\".format(bump_amounts[target_class_idx]))\n",
    "            cur_predictions, cur_counter, _ = quick_predict_with_bump(\n",
    "                bump_amounts=bump_amounts,\n",
    "                data=test_data,\n",
    "                model=model,\n",
    "                debug=debug)\n",
    "            cur_target_predictions = cur_counter[target_class_idx]\n",
    "            if debug:\n",
    "                print(\"cur target_predictions: {} target n predictions: {}\".format(\n",
    "                    cur_target_predictions, n_target_predictions))\n",
    "        bump_lower_bound = bump_amounts[target_class_idx]\n",
    "        target_predictions_lower = cur_target_predictions\n",
    "    \n",
    "    print(\"lower bound: {} target class predictions: {}\".format(\n",
    "        bump_lower_bound, target_predictions_lower))\n",
    "    print(\"upper bound: {} target class predictions: {}\".format(\n",
    "        bump_upper_bound, target_predictions_upper))\n",
    "    return bump_lower_bound, bump_upper_bound\n",
    "    \n",
    "def bump_amount_binary_search(n_target_predictions,\n",
    "                              target_class_idx,\n",
    "                              n_classes,\n",
    "                              bump_lower_bound,\n",
    "                              bump_upper_bound,\n",
    "                              cushion,\n",
    "                              test_data,\n",
    "                              model,\n",
    "                              debug=True):\n",
    "    '''\n",
    "    Perform binary search to find the right bump amount\n",
    "    '''\n",
    "    bump_amounts = np.zeros(n_classes)\n",
    "    baseline_predictions, baseline_counter, _ = quick_predict_with_bump(\n",
    "        bump_amounts=bump_amounts,\n",
    "        data=test_data,\n",
    "        model=model,\n",
    "        debug=debug)\n",
    "    \n",
    "    cur_target_predictions = baseline_counter[target_class_idx]\n",
    "    \n",
    "    while abs(cur_target_predictions - n_target_predictions) > cushion:\n",
    "        # Update bump amount\n",
    "        cur_bump_amount = (bump_lower_bound + bump_upper_bound) / 2\n",
    "        # Check before we undergo an infinite loop\n",
    "        if cur_bump_amount == 0:\n",
    "            print(\"cur_bump_amount is 0, exiting loop\")\n",
    "            break\n",
    "            \n",
    "        # predict using logit bump\n",
    "        bump_amounts[target_class_idx] = cur_bump_amount\n",
    "        cur_predictions, cur_counter, _ = quick_predict_with_bump(\n",
    "            bump_amounts=bump_amounts,\n",
    "            data=test_data,\n",
    "            model=model,\n",
    "            debug=debug)\n",
    "\n",
    "        # Obtain num. predictions for target class and determine bin idx\n",
    "        # post_class_distribution = log['predicted_class_distribution']\n",
    "        cur_target_predictions = cur_counter[target_class_idx]\n",
    "        if debug:\n",
    "            print(\"cur_bump_amount: {}, cur_target_predictions: {}\".format(cur_bump_amount, cur_target_predictions))\n",
    "        \n",
    "        # Update bump bounds of binary search\n",
    "        if cur_target_predictions > n_target_predictions:\n",
    "            bump_upper_bound = cur_bump_amount\n",
    "            if debug:\n",
    "                print(\"Updated upper bound to {}\".format(bump_upper_bound))\n",
    "        elif cur_target_predictions < n_target_predictions:\n",
    "            bump_lower_bound = cur_bump_amount\n",
    "            if debug:\n",
    "                print(\"Updated lower bound to {}\".format(bump_lower_bound))\n",
    "    return bump_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bump(#pre_edit_counter,\n",
    "               #post_edit_counter,\n",
    "               n_classes,\n",
    "               n_target_predictions,\n",
    "               target_class_idx,\n",
    "               # bump_amount_lower_bound,\n",
    "               # bump_amount_upper_bound,\n",
    "               # bumps_preds_metrics,\n",
    "               results_save_dir,\n",
    "               # data_loader,\n",
    "               test_data,\n",
    "               model,\n",
    "               # loss_fn,\n",
    "               # metric_fns,\n",
    "               # device,\n",
    "               cushion=5,\n",
    "               # n_stop=10,\n",
    "               debug=True):\n",
    "    '''\n",
    "    Given a number of predictions for target class, obtain bump amount to match and save post edit metrics in results_save_dir\n",
    "    \n",
    "    Arg(s):\n",
    "        n_target_predictions : int\n",
    "            Number of predictions to obtain for target class\n",
    "        target_class_idx : int\n",
    "            index of target class\n",
    "        bumps_preds_metrics : dict\n",
    "            saved data from match_bump_edits()\n",
    "        results_save_dir : str\n",
    "            directory to save results to\n",
    "        data_loader : torch.utils.data.DataLoader\n",
    "            validation data loader to obtain metrics for\n",
    "        model : torch.nn.Module\n",
    "            model\n",
    "        loss_fn : module\n",
    "            loss function\n",
    "        metric_fns : list[model.metric modules]\n",
    "            list of metric functions\n",
    "        device : torch.device\n",
    "            GPU device to run model on\n",
    "        cushion : int\n",
    "            how far away cur_n_target_predictions can be from n_target_predictions on either side to break loop (buffer)\n",
    "        n_stop : int\n",
    "            how many iterations when stuck at the same cur_n_target_predictions until to break the loop\n",
    "        debug : bool\n",
    "            control verbosity\n",
    "        \n",
    "            \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    if debug:\n",
    "        print(\"Target class idx: {}\".format(target_class_idx))\n",
    "    empty_bumps = np.zeros(n_classes)\n",
    "\n",
    "    bump_lower_bound, bump_upper_bound = find_bump_bounds(\n",
    "        n_target_predictions=n_target_predictions,\n",
    "        target_class_idx=target_class_idx,\n",
    "        n_classes=n_classes,\n",
    "        test_data=test_data,\n",
    "        model=model,\n",
    "        debug=debug)\n",
    "        \n",
    "    bump_amounts = bump_amount_binary_search(\n",
    "        n_target_predictions=n_target_predictions,\n",
    "        target_class_idx=target_class_idx,\n",
    "        n_classes=n_classes,\n",
    "        bump_lower_bound=bump_lower_bound,\n",
    "        bump_upper_bound=bump_upper_bound,\n",
    "        cushion=cushion,\n",
    "        test_data=test_data,\n",
    "        model=model,\n",
    "        debug=debug)\n",
    "    \n",
    "    return bump_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### For each class with significant change on the test set, figure out how much to bump to achieve same # of predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding bump for snowmobile class (802)\n",
      "lower bound: -2.0 target class predictions: 6\n",
      "upper bound: 0 target class predictions: 21\n",
      "Target class: snowmobile (802)\n",
      "Pre prediction bumps: 21 Post bump # predictions: 8\n",
      "Bump amount: -1.5\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 38.10\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 65.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for racer, race car, racing car class (751)\n",
      "lower bound: 0 target class predictions: 8\n",
      "upper bound: 2.0 target class predictions: 18\n",
      "Target class: racer, race car, racing car (751)\n",
      "Pre prediction bumps: 8 Post bump # predictions: 17\n",
      "Bump amount: 1.875\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 85.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for snowplow, snowplough class (803)\n",
      "lower bound: -2.0 target class predictions: 8\n",
      "upper bound: 0 target class predictions: 23\n",
      "Target class: snowplow, snowplough (803)\n",
      "Pre prediction bumps: 23 Post bump # predictions: 15\n",
      "Bump amount: -0.875\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 77.78\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 52.94\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 45.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 45.00\n",
      "---***---\n",
      "\n",
      "Finding bump for motor scooter, scooter class (670)\n",
      "lower bound: 0 target class predictions: 5\n",
      "upper bound: 2.0 target class predictions: 12\n",
      "Target class: motor scooter, scooter (670)\n",
      "Pre prediction bumps: 5 Post bump # predictions: 9\n",
      "Bump amount: 0.5\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 42.86\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for school bus class (779)\n",
      "lower bound: 0 target class predictions: 14\n",
      "upper bound: 2.0 target class predictions: 19\n",
      "Target class: school bus (779)\n",
      "Pre prediction bumps: 14 Post bump # predictions: 17\n",
      "Bump amount: 1.09375\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 77.27\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for dalmatian, coach dog, carriage dog class (251)\n",
      "lower bound: 0 target class predictions: 0\n",
      "upper bound: 2.0 target class predictions: 1\n",
      "Target class: dalmatian, coach dog, carriage dog (251)\n",
      "Pre prediction bumps: 0 Post bump # predictions: 1\n",
      "Bump amount: 1.0\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for fire engine, fire truck class (555)\n",
      "lower bound: -2.0 target class predictions: 15\n",
      "upper bound: 0 target class predictions: 18\n",
      "Target class: fire engine, fire truck (555)\n",
      "Pre prediction bumps: 18 Post bump # predictions: 17\n",
      "Bump amount: -1.0\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 85.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi class (867)\n",
      "lower bound: 0 target class predictions: 0\n",
      "upper bound: 2.0 target class predictions: 2\n",
      "Target class: trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi (867)\n",
      "Pre prediction bumps: 0 Post bump # predictions: 1\n",
      "Bump amount: 1.0\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 85.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for tractor class (866)\n",
      "lower bound: 0 target class predictions: 1\n",
      "upper bound: 2.0 target class predictions: 3\n",
      "Target class: tractor (866)\n",
      "Pre prediction bumps: 1 Post bump # predictions: 2\n",
      "Bump amount: 1.0\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for amphibian, amphibious vehicle class (408)\n",
      "lower bound: -2.0 target class predictions: 0\n",
      "upper bound: 0 target class predictions: 4\n",
      "Target class: amphibian, amphibious vehicle (408)\n",
      "Pre prediction bumps: 4 Post bump # predictions: 3\n",
      "Bump amount: -0.25\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for car wheel class (479)\n",
      "lower bound: 0 target class predictions: 8\n",
      "upper bound: 2.0 target class predictions: 11\n",
      "Target class: car wheel (479)\n",
      "Pre prediction bumps: 8 Post bump # predictions: 9\n",
      "Bump amount: 0.25\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 45.00\n",
      "---***---\n",
      "\n",
      "Finding bump for traffic light, traffic signal, stoplight class (920)\n",
      "lower bound: 0 target class predictions: 6\n",
      "upper bound: 2.0 target class predictions: 8\n",
      "Target class: traffic light, traffic signal, stoplight (920)\n",
      "Pre prediction bumps: 6 Post bump # predictions: 7\n",
      "Bump amount: 1.0\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 77.78\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for moped class (665)\n",
      "lower bound: 0 target class predictions: 1\n",
      "upper bound: 2.0 target class predictions: 5\n",
      "Target class: moped (665)\n",
      "Pre prediction bumps: 1 Post bump # predictions: 2\n",
      "Bump amount: 1.25\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 19.05\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n",
      "Finding bump for tank, army tank, armored combat vehicle, armoured combat vehicle class (847)\n",
      "lower bound: 0 target class predictions: 8\n",
      "upper bound: 2.0 target class predictions: 12\n",
      "Target class: tank, army tank, armored combat vehicle, armoured combat vehicle (847)\n",
      "Pre prediction bumps: 8 Post bump # predictions: 9\n",
      "Bump amount: 0.25\n",
      "Class: 779/school bus | Accuracy: 63.64 -> 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81 -> 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67 -> 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00 -> 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06 -> 52.94\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00 -> 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00 -> 40.00\n",
      "---***---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_idxs = np.where(deltas_sorted > 0)[0]\n",
    "selected_deltas = deltas_sorted[selected_idxs]\n",
    "selected_classes = classes_sorted[selected_idxs]\n",
    "\n",
    "accumulated_bump_amounts = np.zeros(n_classes)\n",
    "for selected_class in selected_classes:\n",
    "    print(\"Finding bump for {} class ({})\".format(CD[selected_class], selected_class))\n",
    "    bump_amounts = match_bump(\n",
    "        n_classes=n_classes,\n",
    "        n_target_predictions=post_edit_counter[selected_class],\n",
    "        target_class_idx=selected_class,\n",
    "        # bumps_preds_metrics,\n",
    "        results_save_dir=None,\n",
    "        # data_loader,\n",
    "        test_data=test_data,\n",
    "        cushion=0,\n",
    "        model=model,\n",
    "        debug=False)\n",
    "\n",
    "    pre_predictions, pre_counter, pre_accuracies = quick_predict_with_bump(\n",
    "        bump_amounts=np.zeros(n_classes),\n",
    "        data=test_data,\n",
    "        model=model,\n",
    "        debug=False)\n",
    "\n",
    "    post_predictions, post_counter, post_accuracies = quick_predict_with_bump(\n",
    "        bump_amounts=bump_amounts,\n",
    "        data=test_data,\n",
    "        model=model,\n",
    "        debug=False)\n",
    "    print(\"Target class: {} ({})\".format(CD[selected_class], selected_class))\n",
    "    print(\"Pre prediction bumps: {} Post bump # predictions: {}\".format(\n",
    "        pre_counter[selected_class],\n",
    "        post_counter[selected_class]))\n",
    "    print(\"Bump amount: {}\".format(bump_amounts[selected_class]))\n",
    "\n",
    "    for idx, c in enumerate(test_data):\n",
    "        print(f'Class: {c}/{CD[c]} | Accuracy: {pre_accuracies[idx]:.2f} -> {post_accuracies[idx]:.2f}',) \n",
    "    print(\"---***---\\n\")\n",
    "    \n",
    "    accumulated_bump_amounts += bump_amounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compare the accumulated logit bumping results to the edited model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accumulated_bump_amounts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m acc_predictions, acc_counter, acc_accuracies \u001b[38;5;241m=\u001b[39m quick_predict_with_bump(\n\u001b[0;32m----> 2\u001b[0m     bump_amounts\u001b[38;5;241m=\u001b[39m\u001b[43maccumulated_bump_amounts\u001b[49m,\n\u001b[1;32m      3\u001b[0m     data\u001b[38;5;241m=\u001b[39mtest_data,\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_data):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCD[c]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Accuracy change: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpre_accuracies[idx]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_accuracies[idx]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accumulated_bump_amounts' is not defined"
     ]
    }
   ],
   "source": [
    "acc_predictions, acc_counter, acc_accuracies = quick_predict_with_bump(\n",
    "    bump_amounts=accumulated_bump_amounts,\n",
    "    data=test_data,\n",
    "    model=model,\n",
    "    debug=False)\n",
    "for idx, c in enumerate(test_data):\n",
    "        print(f'Class: {c}/{CD[c]} \\n Accuracy change: {pre_accuracies[idx]:.2f} -> {acc_accuracies[idx]:.2f}\\n',) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load accumulated bump amounts and edited model to run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_calibration_path = os.path.join(restore_dir, 'logit_calibration.pth')\n",
    "accumulated_bump_amounts = torch.load(logit_calibration_path)\n",
    "print(accumulated_bump_amounts.shape)\n",
    "\n",
    "edited_model_path = os.path.join(restore_dir, 'edited_imagenet_vgg.pt.best')\n",
    "edited_ret = classifier_helpers.get_default_paths(DATASET_NAME, arch=ARCH)\n",
    "DATASET_PATH, MODEL_PATH, MODEL_CLASS, ARCH, CD = edited_ret\n",
    "edited_ret = classifier_helpers.load_classifier(MODEL_PATH, MODEL_CLASS, ARCH,\n",
    "                            DATASET_NAME, LAYERNUM) \n",
    "\n",
    "edited_model, edited_context_model, edited_target_model = edited_ret[:3]\n",
    "edited_state_dict = torch.load(edited_model_path)\n",
    "edited_model.load_state_dict(edited_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 779/school bus | Accuracy: 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00\n",
      "Class: 779/school bus | Accuracy: 63.64\n",
      "Class: 670/motor scooter, scooter | Accuracy: 23.81\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 66.67\n",
      "Class: 555/fire engine, fire truck | Accuracy: 90.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 47.06\n",
      "Class: 751/racer, race car, racing car | Accuracy: 40.00\n",
      "Class: 479/car wheel | Accuracy: 40.00\n",
      "Class: 779/school bus | Accuracy: 77.27\n",
      "Class: 670/motor scooter, scooter | Accuracy: 42.86\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 77.78\n",
      "Class: 555/fire engine, fire truck | Accuracy: 85.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 52.94\n",
      "Class: 751/racer, race car, racing car | Accuracy: 85.00\n",
      "Class: 479/car wheel | Accuracy: 45.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Original model: \")\n",
    "original_results = quick_predict_with_bump(\n",
    "    bump_amounts=np.zeros_like(accumulated_bump_amounts),\n",
    "    data=test_data,\n",
    "    model=model,\n",
    "    debug=True)\n",
    "\n",
    "print(\"Calibrated model: \")\n",
    "calibrated_results = quick_predict_with_bump(\n",
    "    bump_amounts=accumulated_bump_amounts,\n",
    "    data=test_data,\n",
    "    model=model,\n",
    "    debug=True)\n",
    "\n",
    "print(\"Edited model: \")\n",
    "edited_results = quick_predict_with_bump(\n",
    "    bump_amounts=np.zeros_like(accumulated_bump_amounts),\n",
    "    data=test_data,\n",
    "    model=edited_model,\n",
    "    debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "original_results_save_path = os.path.join(restore_dir, 'vos_original_results.pth')\n",
    "calibrated_results_save_path = os.path.join(restore_dir, 'vos_calibrated_results.pth')\n",
    "edited_results_save_path = os.path.join(restore_dir, 'vos_edited_results.pth')\n",
    "\n",
    "torch.save(original_results, original_results_save_path)\n",
    "torch.save(calibrated_results, calibrated_results_save_path)\n",
    "torch.save(edited_results, edited_results_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results from original, edited, and calibrated model to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results\n",
    "original_results_save_path = os.path.join(restore_dir, 'vos_original_results.pth')\n",
    "calibrated_results_save_path = os.path.join(restore_dir, 'vos_calibrated_results.pth')\n",
    "edited_results_save_path = os.path.join(restore_dir, 'vos_edited_results.pth')\n",
    "\n",
    "original_results = torch.load(original_results_save_path)\n",
    "calibrated_results = torch.load(calibrated_results_save_path)\n",
    "edited_results = torch.load(edited_results_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IOU(predictions_a, \n",
    "            predictions_b, \n",
    "            target_class_idx, \n",
    "            modes=['binary']):\n",
    "    \n",
    "    IOUs = []\n",
    "    \n",
    "    if torch.is_tensor(predictions_a):\n",
    "        predictions_a = predictions_a.cpu().numpy()\n",
    "    if torch.is_tensor(predictions_b):\n",
    "        predictions_b = predictions_b.cpu().numpy()\n",
    "\n",
    "\n",
    "    for mode in modes:\n",
    "        try:\n",
    "            if mode == 'binary':\n",
    "                # Binarize predictions based on target class\n",
    "                binary_predictions_a = np.where(\n",
    "                    predictions_a == target_class_idx,\n",
    "                    1, 0)\n",
    "                binary_predictions_b = np.where(\n",
    "                    predictions_b == target_class_idx,\n",
    "                    1, 0)\n",
    "                \n",
    "                IOU = metrics.jaccard_score(\n",
    "                    y_true=binary_predictions_a,\n",
    "                    y_pred=binary_predictions_b,\n",
    "                    average=mode)\n",
    "            else:\n",
    "                IOU = metrics.jaccard_score(\n",
    "                    y_true=predictions_a,\n",
    "                    y_pred=predictions_b,\n",
    "                    average=mode)\n",
    "            IOUs.append(IOU)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return IOUs\n",
    "\n",
    "def get_ranking(logits, target_class_idx):\n",
    "    if not torch.is_tensor(logits):\n",
    "        logits = torch.from_numpy(logits)\n",
    "    \n",
    "    softmax = torch.softmax(logits, dim=1)\n",
    "    target_softmax = softmax[:, target_class_idx]\n",
    "    ranking = target_softmax.argsort().argsort()\n",
    "    \n",
    "    return ranking.cpu().numpy()\n",
    "\n",
    "def get_spearman(logits_a, logits_b, target_class_idx):\n",
    "    ranking_a = get_ranking(\n",
    "        logits=logits_a,\n",
    "        target_class_idx=target_class_idx)\n",
    "    ranking_b = get_ranking(\n",
    "        logits=logits_b,\n",
    "        target_class_idx=target_class_idx)\n",
    "    \n",
    "    if torch.is_tensor(ranking_a):\n",
    "        ranking_a = ranking_a.cpu().numpy()\n",
    "    if torch.is_tensor(ranking_b):\n",
    "        ranking_b = ranking_b.cpu().numpy()\n",
    "    spearman = stats.spearmanr(\n",
    "        a=ranking_a,\n",
    "        b=ranking_b)\n",
    "    return spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare test set accuracy, IOU of calibrated and edited model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU of edited and calibrated: 0.7297347542544712\n",
      "Original overall accuracy: 0.5193798449612403\n",
      "Edited overall accuracy: 0.6589147286821705\n",
      "Calibrated overall accuracy: 0.5193798449612403\n"
     ]
    }
   ],
   "source": [
    "edited_predictions = edited_results['predictions']\n",
    "calibrated_predictions = calibrated_results['predictions']\n",
    "IOUs = get_IOU(\n",
    "    predictions_a=edited_predictions,\n",
    "    predictions_b=calibrated_predictions,\n",
    "    target_class_idx=None,\n",
    "    modes=['weighted'])\n",
    "\n",
    "n_samples = edited_predictions.shape[0]\n",
    "print(\"IOU of edited and calibrated: {}\".format(IOUs[0]))\n",
    "print(\"Original overall accuracy: {}\\nEdited overall accuracy: {}\\nCalibrated overall accuracy: {}\".format(\n",
    "    original_results['n_correct'] / n_samples,\n",
    "    edited_results['n_correct'] / n_samples,\n",
    "    calibrated_results['n_correct'] / n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman's correlation: 0.9770875926399185 (0.006029611771177532)\n"
     ]
    }
   ],
   "source": [
    "#### Calculate Spearman's correlation coefficient for each class in \n",
    "calibrated_logits = calibrated_results['logits']\n",
    "edited_logits = edited_results['logits']\n",
    "\n",
    "correlations = []\n",
    "for class_idx, _ in test_data.items():\n",
    "    spearman = get_spearman(\n",
    "        logits_a=calibrated_logits,\n",
    "        logits_b=edited_logits,\n",
    "        target_class_idx=class_idx)\n",
    "    correlations.append(spearman.correlation)\n",
    "    \n",
    "correlations = np.array(correlations)\n",
    "print(\"Mean Spearman's correlation: {} ({})\".format(np.mean(correlations), np.std(correlations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run original model on ImageNet validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1563/1563 [02:31<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre edit results:\n",
      "{'TP': array([45, 44, 40, 41, 43, 39, 43, 37, 44, 50, 45, 47, 47, 48, 46, 46, 43,\n",
      "       45, 48, 44, 42, 38, 48, 48, 47, 48, 32, 36, 45, 45, 40, 43, 19, 38,\n",
      "       30, 31, 23, 44, 42, 42, 31, 46, 40, 43, 34, 39, 26, 39, 46, 33, 43,\n",
      "       45, 37, 45, 30, 28, 42, 44, 38, 31, 19, 40, 29, 42, 33, 39, 27, 40,\n",
      "       18, 49, 45, 47, 48, 21, 32, 42, 46, 41, 36, 41, 46, 41, 42, 47, 47,\n",
      "       46, 38, 47, 48, 47, 49, 46, 48, 48, 46, 47, 45, 46, 45, 40, 49, 31,\n",
      "       49, 37, 44, 44, 36, 44, 34, 45, 40, 44, 37, 41, 40, 41, 40, 40, 42,\n",
      "       33, 32, 43, 40, 41, 27, 44, 36, 44, 42, 50, 48, 45, 45, 45, 35, 49,\n",
      "       48, 45, 46, 49, 43, 46, 46, 47, 46, 46, 46, 43, 45, 43, 40, 36, 37,\n",
      "       39, 43, 39, 45, 48, 30, 41, 45, 40, 40, 22, 44, 27, 34, 15, 37, 44,\n",
      "       34, 40, 35, 35, 46, 30, 42, 40, 45, 35, 31, 45, 43, 40, 34, 35, 32,\n",
      "       36, 31, 36, 39, 39, 39, 29, 41, 48, 37, 38, 43, 38, 36, 31, 32, 46,\n",
      "       34, 38, 39, 44, 42, 40, 40, 41, 38, 43, 45, 44, 46, 46, 41, 37, 38,\n",
      "       41, 33, 40, 40, 47, 30, 39, 43, 43, 41, 30, 41, 38, 46, 39, 34, 40,\n",
      "       33, 45, 15, 38, 36, 42, 46, 43, 35, 48, 21, 39, 26, 49, 41, 46, 48,\n",
      "       50, 42, 40, 50, 49, 45, 44, 48, 44, 37, 32, 22, 42, 47, 37, 45, 31,\n",
      "       29, 37, 45, 49, 43, 30, 34, 47, 35, 36, 11, 45, 46, 19, 45, 34, 40,\n",
      "       45, 38, 46, 47, 46, 47, 44, 45, 37, 35, 43, 47, 42, 34, 38, 37, 40,\n",
      "       41, 44, 43, 40, 35, 28, 31, 35, 39, 35, 45, 45, 39, 38, 47, 50, 48,\n",
      "       47, 45, 46, 45, 44, 43, 33, 39, 42, 47, 50, 45, 41, 45, 38, 42, 47,\n",
      "       49, 25, 44, 46, 47, 31, 42, 46, 34, 35, 47, 47, 42, 35, 45, 41, 21,\n",
      "       39, 22, 38, 41, 47, 40, 45, 49, 43, 39, 41, 39, 35, 43, 35, 42, 36,\n",
      "       29, 42, 50, 38, 41, 43, 31, 20, 39, 33, 46, 33, 29, 46, 48, 40, 34,\n",
      "       40, 47, 45, 36, 37, 47, 44, 40, 38, 22, 39, 30, 43, 45, 37, 31, 43,\n",
      "       34, 24, 45, 31, 17, 26, 19, 25, 42, 45, 28, 35, 44, 35, 28, 35, 30,\n",
      "       45, 41, 33, 36, 39, 47, 37, 41, 36, 29, 14, 34, 38, 26, 41, 31, 35,\n",
      "       33, 29, 42, 26, 29, 28, 44, 39, 43, 38, 34, 34, 29, 35, 33, 36, 45,\n",
      "       28, 29, 19, 32, 26, 20, 30, 44, 38, 32, 21, 28, 43, 48, 31, 36, 45,\n",
      "       46, 32, 27, 18, 38, 28, 18, 38, 36, 25, 43, 36, 15, 32, 38, 43, 30,\n",
      "       14, 28, 43, 46, 34, 33, 10, 46, 20, 27, 30, 25, 26, 28, 38, 31, 27,\n",
      "       42, 34, 42, 27, 35, 33, 12, 40, 47, 29, 39, 33, 40, 23, 23, 39, 24,\n",
      "       31, 46, 36, 33, 32, 41, 47, 29, 48, 27, 46, 38, 27, 44, 26, 29, 29,\n",
      "       32, 42, 36, 42, 46, 26, 34, 34, 41, 39, 47, 38, 27, 36, 20, 37, 46,\n",
      "       43, 46, 42, 43, 49, 37, 22, 42, 46, 41, 40, 30, 46, 41, 39, 47, 30,\n",
      "       33, 35, 42, 37, 34, 41, 28, 24, 38, 28, 34, 32, 27, 40, 38, 36, 46,\n",
      "       37, 28, 36, 30, 33,  8, 33, 32, 45, 49, 41, 38, 49, 33, 39, 42, 45,\n",
      "       47, 34, 44, 35, 38, 41, 10, 22,  7, 40, 27, 14, 30, 47, 31, 39, 45,\n",
      "       41, 45, 33, 25, 19, 38, 30, 34, 37, 15, 23, 47, 36, 41, 30, 36, 48,\n",
      "       39, 35, 28, 40, 24, 29, 31, 32, 33, 33, 20, 24, 37, 39, 33, 49, 33,\n",
      "       29, 21, 31, 40, 31, 48, 47, 42, 38, 44, 20, 44, 21, 27, 29, 32, 46,\n",
      "       38, 20, 39, 33, 43, 48, 27, 43, 47, 16, 40, 26, 26, 33, 46, 35, 35,\n",
      "       34, 34, 42, 33, 46, 27, 37, 42, 24, 29, 41, 24, 38, 25, 38, 31, 48,\n",
      "       38, 40, 43, 35, 26, 42, 38, 32, 41, 43, 40, 27, 44, 47, 20, 25, 37,\n",
      "       26, 43, 24, 41, 29, 42, 34, 40, 47, 23, 36, 21, 31,  9, 33, 44, 29,\n",
      "       20, 36, 29, 41, 39, 36, 30, 47, 38, 40, 29, 35, 37, 39, 22, 39, 22,\n",
      "       35, 44, 31, 40, 38, 42, 41, 26, 31, 36, 31, 33, 36, 27, 45, 40, 45,\n",
      "        6, 45, 16, 39, 38, 32, 44, 43, 24, 40, 33, 36, 33, 40, 37, 31, 34,\n",
      "       21, 47, 47, 47, 46, 26, 46, 32, 36, 32, 28, 23, 24, 45, 13, 47, 39,\n",
      "       47, 26, 12, 40, 47, 42, 43, 28, 25, 39, 30, 26, 33, 43, 29, 39, 44,\n",
      "       41, 32, 34, 10, 16, 13, 33, 42, 13, 34, 40, 29, 29, 33, 41, 17, 38,\n",
      "       38, 33, 35, 42, 38, 30, 29, 35, 36, 30, 26, 34, 33, 48, 31, 31, 41,\n",
      "       41, 25, 28, 41, 39, 35, 45, 49, 35, 22, 42, 33, 29, 41, 36, 35, 25,\n",
      "       41,  7, 46, 31, 41, 34, 45, 33, 31, 30, 36, 42, 42, 39, 26, 14, 45,\n",
      "       34, 37, 41, 33, 27, 14, 23, 30, 22, 28, 20, 35, 42, 39, 48, 48, 34,\n",
      "       42, 38, 43, 26, 42, 22, 36, 30, 41, 46, 31, 34, 31, 33, 37, 45, 39,\n",
      "       38, 45, 45, 44, 37, 39, 42, 36, 30, 43, 43, 45, 16, 44, 29, 37, 39,\n",
      "       43, 48, 43, 47, 44, 44, 41, 44, 29, 16, 34, 38, 33, 42, 32, 31, 20,\n",
      "       24, 26, 41, 28, 38, 50, 29, 28, 31, 15, 40, 38, 39, 35, 43, 48, 49,\n",
      "       49, 20, 49, 47, 47, 47, 43, 47, 42, 49, 43, 35, 25, 22]), 'TN': array([49950, 49946, 49937, 49939, 49938, 49940, 49930, 49947, 49940,\n",
      "       49948, 49943, 49947, 49947, 49948, 49948, 49948, 49946, 49947,\n",
      "       49946, 49949, 49947, 49945, 49945, 49941, 49946, 49947, 49925,\n",
      "       49945, 49943, 49945, 49936, 49941, 49937, 49935, 49942, 49933,\n",
      "       49936, 49933, 49946, 49938, 49932, 49934, 49939, 49942, 49938,\n",
      "       49947, 49915, 49943, 49942, 49942, 49937, 49948, 49928, 49934,\n",
      "       49929, 49929, 49941, 49945, 49928, 49942, 49926, 49934, 49939,\n",
      "       49942, 49930, 49937, 49928, 49937, 49937, 49944, 49939, 49937,\n",
      "       49931, 49940, 49928, 49942, 49945, 49926, 49942, 49946, 49940,\n",
      "       49947, 49923, 49948, 49948, 49940, 49942, 49949, 49947, 49946,\n",
      "       49946, 49946, 49948, 49944, 49940, 49946, 49946, 49945, 49949,\n",
      "       49940, 49950, 49928, 49949, 49941, 49933, 49946, 49944, 49946,\n",
      "       49942, 49940, 49943, 49946, 49938, 49938, 49932, 49941, 49946,\n",
      "       49948, 49939, 49921, 49943, 49937, 49949, 49941, 49936, 49937,\n",
      "       49948, 49944, 49946, 49950, 49949, 49940, 49942, 49948, 49946,\n",
      "       49949, 49946, 49946, 49946, 49947, 49945, 49948, 49943, 49946,\n",
      "       49945, 49950, 49945, 49941, 49941, 49944, 49944, 49930, 49948,\n",
      "       49935, 49939, 49930, 49946, 49940, 49947, 49928, 49947, 49931,\n",
      "       49921, 49947, 49942, 49945, 49928, 49948, 49934, 49946, 49933,\n",
      "       49934, 49938, 49944, 49938, 49948, 49937, 49942, 49943, 49935,\n",
      "       49932, 49944, 49939, 49947, 49932, 49933, 49934, 49930, 49945,\n",
      "       49931, 49946, 49934, 49923, 49939, 49943, 49939, 49942, 49932,\n",
      "       49939, 49935, 49932, 49939, 49936, 49934, 49935, 49935, 49943,\n",
      "       49935, 49924, 49941, 49945, 49933, 49939, 49942, 49946, 49934,\n",
      "       49945, 49933, 49943, 49940, 49949, 49943, 49938, 49937, 49933,\n",
      "       49938, 49936, 49933, 49948, 49946, 49938, 49936, 49928, 49937,\n",
      "       49924, 49940, 49932, 49937, 49920, 49939, 49931, 49934, 49937,\n",
      "       49940, 49947, 49937, 49941, 49945, 49931, 49924, 49924, 49945,\n",
      "       49946, 49943, 49941, 49944, 49939, 49939, 49939, 49941, 49948,\n",
      "       49949, 49945, 49935, 49940, 49918, 49937, 49936, 49948, 49934,\n",
      "       49944, 49937, 49936, 49942, 49938, 49947, 49947, 49934, 49931,\n",
      "       49947, 49935, 49905, 49938, 49943, 49939, 49938, 49946, 49938,\n",
      "       49940, 49946, 49939, 49944, 49933, 49944, 49943, 49934, 49944,\n",
      "       49949, 49941, 49945, 49939, 49942, 49939, 49937, 49941, 49946,\n",
      "       49938, 49944, 49942, 49945, 49933, 49928, 49927, 49938, 49943,\n",
      "       49934, 49940, 49943, 49942, 49946, 49940, 49946, 49943, 49950,\n",
      "       49947, 49949, 49949, 49937, 49946, 49943, 49939, 49943, 49941,\n",
      "       49943, 49943, 49942, 49939, 49946, 49945, 49948, 49950, 49944,\n",
      "       49935, 49942, 49943, 49943, 49942, 49944, 49931, 49935, 49947,\n",
      "       49949, 49935, 49941, 49943, 49948, 49939, 49931, 49932, 49921,\n",
      "       49938, 49946, 49944, 49948, 49945, 49942, 49939, 49939, 49943,\n",
      "       49938, 49945, 49937, 49939, 49932, 49944, 49946, 49945, 49942,\n",
      "       49934, 49930, 49929, 49934, 49925, 49948, 49927, 49929, 49940,\n",
      "       49946, 49946, 49945, 49936, 49938, 49948, 49945, 49945, 49940,\n",
      "       49945, 49947, 49940, 49934, 49933, 49938, 49936, 49940, 49939,\n",
      "       49945, 49925, 49940, 49943, 49937, 49937, 49920, 49932, 49932,\n",
      "       49934, 49911, 49933, 49939, 49938, 49923, 49943, 49923, 49937,\n",
      "       49936, 49897, 49941, 49944, 49936, 49931, 49945, 49946, 49922,\n",
      "       49935, 49934, 49936, 49931, 49915, 49943, 49944, 49945, 49934,\n",
      "       49928, 49931, 49937, 49942, 49924, 49941, 49936, 49934, 49939,\n",
      "       49941, 49940, 49929, 49928, 49924, 49935, 49936, 49932, 49941,\n",
      "       49937, 49927, 49929, 49936, 49921, 49930, 49939, 49947, 49939,\n",
      "       49940, 49939, 49939, 49942, 49938, 49933, 49925, 49942, 49945,\n",
      "       49928, 49936, 49941, 49934, 49933, 49936, 49934, 49932, 49921,\n",
      "       49935, 49926, 49938, 49935, 49942, 49937, 49934, 49944, 49930,\n",
      "       49937, 49928, 49924, 49930, 49939, 49938, 49939, 49934, 49943,\n",
      "       49930, 49918, 49934, 49931, 49909, 49939, 49940, 49938, 49935,\n",
      "       49933, 49933, 49918, 49940, 49936, 49932, 49934, 49938, 49945,\n",
      "       49942, 49920, 49931, 49936, 49904, 49906, 49945, 49922, 49936,\n",
      "       49936, 49928, 49941, 49931, 49946, 49921, 49942, 49934, 49940,\n",
      "       49940, 49936, 49925, 49919, 49931, 49941, 49940, 49941, 49930,\n",
      "       49928, 49937, 49937, 49940, 49934, 49946, 49944, 49942, 49944,\n",
      "       49928, 49938, 49937, 49942, 49932, 49935, 49941, 49940, 49945,\n",
      "       49939, 49940, 49941, 49924, 49943, 49934, 49941, 49946, 49942,\n",
      "       49945, 49939, 49930, 49937, 49937, 49940, 49929, 49938, 49931,\n",
      "       49926, 49939, 49923, 49936, 49932, 49944, 49932, 49939, 49933,\n",
      "       49941, 49933, 49933, 49920, 49932, 49933, 49939, 49932, 49934,\n",
      "       49939, 49946, 49934, 49935, 49946, 49929, 49942, 49932, 49939,\n",
      "       49932, 49936, 49930, 49943, 49939, 49926, 49926, 49927, 49917,\n",
      "       49936, 49939, 49942, 49931, 49943, 49918, 49942, 49943, 49935,\n",
      "       49939, 49920, 49933, 49942, 49939, 49940, 49926, 49939, 49925,\n",
      "       49918, 49943, 49939, 49936, 49934, 49936, 49937, 49940, 49942,\n",
      "       49923, 49943, 49936, 49931, 49919, 49944, 49929, 49921, 49940,\n",
      "       49918, 49936, 49932, 49943, 49934, 49933, 49922, 49916, 49945,\n",
      "       49939, 49928, 49942, 49941, 49943, 49936, 49943, 49937, 49928,\n",
      "       49942, 49943, 49936, 49941, 49903, 49942, 49903, 49935, 49934,\n",
      "       49942, 49947, 49939, 49942, 49943, 49942, 49934, 49941, 49902,\n",
      "       49944, 49948, 49930, 49935, 49927, 49928, 49945, 49936, 49946,\n",
      "       49938, 49929, 49939, 49940, 49930, 49941, 49939, 49910, 49932,\n",
      "       49924, 49940, 49933, 49936, 49943, 49936, 49934, 49923, 49947,\n",
      "       49933, 49922, 49939, 49938, 49940, 49933, 49941, 49946, 49938,\n",
      "       49946, 49942, 49935, 49932, 49938, 49917, 49928, 49945, 49929,\n",
      "       49927, 49936, 49935, 49943, 49937, 49932, 49937, 49924, 49935,\n",
      "       49940, 49925, 49939, 49936, 49918, 49934, 49934, 49924, 49944,\n",
      "       49933, 49940, 49939, 49929, 49934, 49938, 49923, 49938, 49922,\n",
      "       49939, 49933, 49902, 49946, 49937, 49940, 49941, 49939, 49930,\n",
      "       49928, 49927, 49939, 49918, 49937, 49942, 49942, 49939, 49936,\n",
      "       49937, 49926, 49939, 49936, 49926, 49935, 49936, 49939, 49941,\n",
      "       49931, 49941, 49938, 49931, 49944, 49927, 49945, 49923, 49947,\n",
      "       49930, 49940, 49936, 49934, 49940, 49935, 49941, 49940, 49910,\n",
      "       49934, 49942, 49946, 49924, 49938, 49942, 49937, 49935, 49929,\n",
      "       49905, 49949, 49939, 49940, 49933, 49925, 49938, 49938, 49935,\n",
      "       49927, 49946, 49933, 49930, 49947, 49942, 49914, 49934, 49937,\n",
      "       49928, 49941, 49939, 49929, 49943, 49922, 49926, 49930, 49937,\n",
      "       49925, 49933, 49905, 49931, 49930, 49931, 49947, 49949, 49940,\n",
      "       49938, 49942, 49932, 49942, 49944, 49928, 49944, 49942, 49940,\n",
      "       49935, 49924, 49931, 49932, 49933, 49930, 49939, 49938, 49938,\n",
      "       49942, 49943, 49921, 49917, 49935, 49943, 49933, 49937, 49932,\n",
      "       49930, 49935, 49933, 49937, 49944, 49929, 49948, 49943, 49943,\n",
      "       49942, 49928, 49925, 49910, 49929, 49934, 49943, 49924, 49929,\n",
      "       49945, 49943, 49939, 49928, 49934, 49920, 49945, 49925, 49936,\n",
      "       49918, 49924, 49941, 49942, 49938, 49945, 49943, 49932, 49922,\n",
      "       49937, 49940, 49936, 49932, 49935, 49918, 49943, 49936, 49910,\n",
      "       49934, 49927, 49928, 49928, 49939, 49945, 49936, 49934, 49934,\n",
      "       49945, 49939, 49942, 49933, 49940, 49939, 49934, 49931, 49946,\n",
      "       49944, 49945, 49939, 49945, 49940, 49937, 49936, 49944, 49945,\n",
      "       49944, 49945, 49945, 49944, 49945, 49943, 49929, 49936, 49937,\n",
      "       49935, 49935, 49934, 49930, 49929, 49936, 49927, 49935, 49937,\n",
      "       49931, 49924, 49946, 49929, 49931, 49933, 49931, 49927, 49938,\n",
      "       49940, 49935, 49944, 49947, 49942, 49949, 49919, 49944, 49946,\n",
      "       49940, 49946, 49928, 49946, 49943, 49946, 49946, 49931, 49932,\n",
      "       49932]), 'FPs': array([ 0,  4, 13, 11, 12, 10, 20,  3, 10,  2,  7,  3,  3,  2,  2,  2,  4,\n",
      "        3,  4,  1,  3,  5,  5,  9,  4,  3, 25,  5,  7,  5, 14,  9, 13, 15,\n",
      "        8, 17, 14, 17,  4, 12, 18, 16, 11,  8, 12,  3, 35,  7,  8,  8, 13,\n",
      "        2, 22, 16, 21, 21,  9,  5, 22,  8, 24, 16, 11,  8, 20, 13, 22, 13,\n",
      "       13,  6, 11, 13, 19, 10, 22,  8,  5, 24,  8,  4, 10,  3, 27,  2,  2,\n",
      "       10,  8,  1,  3,  4,  4,  4,  2,  6, 10,  4,  4,  5,  1, 10,  0, 22,\n",
      "        1,  9, 17,  4,  6,  4,  8, 10,  7,  4, 12, 12, 18,  9,  4,  2, 11,\n",
      "       29,  7, 13,  1,  9, 14, 13,  2,  6,  4,  0,  1, 10,  8,  2,  4,  1,\n",
      "        4,  4,  4,  3,  5,  2,  7,  4,  5,  0,  5,  9,  9,  6,  6, 20,  2,\n",
      "       15, 11, 20,  4, 10,  3, 22,  3, 19, 29,  3,  8,  5, 22,  2, 16,  4,\n",
      "       17, 16, 12,  6, 12,  2, 13,  8,  7, 15, 18,  6, 11,  3, 18, 17, 16,\n",
      "       20,  5, 19,  4, 16, 27, 11,  7, 11,  8, 18, 11, 15, 18, 11, 14, 16,\n",
      "       15, 15,  7, 15, 26,  9,  5, 17, 11,  8,  4, 16,  5, 17,  7, 10,  1,\n",
      "        7, 12, 13, 17, 12, 14, 17,  2,  4, 12, 14, 22, 13, 26, 10, 18, 13,\n",
      "       30, 11, 19, 16, 13, 10,  3, 13,  9,  5, 19, 26, 26,  5,  4,  7,  9,\n",
      "        6, 11, 11, 11,  9,  2,  1,  5, 15, 10, 32, 13, 14,  2, 16,  6, 13,\n",
      "       14,  8, 12,  3,  3, 16, 19,  3, 15, 45, 12,  7, 11, 12,  4, 12, 10,\n",
      "        4, 11,  6, 17,  6,  7, 16,  6,  1,  9,  5, 11,  8, 11, 13,  9,  4,\n",
      "       12,  6,  8,  5, 17, 22, 23, 12,  7, 16, 10,  7,  8,  4, 10,  4,  7,\n",
      "        0,  3,  1,  1, 13,  4,  7, 11,  7,  9,  7,  7,  8, 11,  4,  5,  2,\n",
      "        0,  6, 15,  8,  7,  7,  8,  6, 19, 15,  3,  1, 15,  9,  7,  2, 11,\n",
      "       19, 18, 29, 12,  4,  6,  2,  5,  8, 11, 11,  7, 12,  5, 13, 11, 18,\n",
      "        6,  4,  5,  8, 16, 20, 21, 16, 25,  2, 23, 21, 10,  4,  4,  5, 14,\n",
      "       12,  2,  5,  5, 10,  5,  3, 10, 16, 17, 12, 14, 10, 11,  5, 25, 10,\n",
      "        7, 13, 13, 30, 18, 18, 16, 39, 17, 11, 12, 27,  7, 27, 13, 14, 53,\n",
      "        9,  6, 14, 19,  5,  4, 28, 15, 16, 14, 19, 35,  7,  6,  5, 16, 22,\n",
      "       19, 13,  8, 26,  9, 14, 16, 11,  9, 10, 21, 22, 26, 15, 14, 18,  9,\n",
      "       13, 23, 21, 14, 29, 20, 11,  3, 11, 10, 11, 11,  8, 12, 17, 25,  8,\n",
      "        5, 22, 14,  9, 16, 17, 14, 16, 18, 29, 15, 24, 12, 15,  8, 13, 16,\n",
      "        6, 20, 13, 22, 26, 20, 11, 12, 11, 16,  7, 20, 32, 16, 19, 41, 11,\n",
      "       10, 12, 15, 17, 17, 32, 10, 14, 18, 16, 12,  5,  8, 30, 19, 14, 46,\n",
      "       44,  5, 28, 14, 14, 22,  9, 19,  4, 29,  8, 16, 10, 10, 14, 25, 31,\n",
      "       19,  9, 10,  9, 20, 22, 13, 13, 10, 16,  4,  6,  8,  6, 22, 12, 13,\n",
      "        8, 18, 15,  9, 10,  5, 11, 10,  9, 26,  7, 16,  9,  4,  8,  5, 11,\n",
      "       20, 13, 13, 10, 21, 12, 19, 24, 11, 27, 14, 18,  6, 18, 11, 17,  9,\n",
      "       17, 17, 30, 18, 17, 11, 18, 16, 11,  4, 16, 15,  4, 21,  8, 18, 11,\n",
      "       18, 14, 20,  7, 11, 24, 24, 23, 33, 14, 11,  8, 19,  7, 32,  8,  7,\n",
      "       15, 11, 30, 17,  8, 11, 10, 24, 11, 25, 32,  7, 11, 14, 16, 14, 13,\n",
      "       10,  8, 27,  7, 14, 19, 31,  6, 21, 29, 10, 32, 14, 18,  7, 16, 17,\n",
      "       28, 34,  5, 11, 22,  8,  9,  7, 14,  7, 13, 22,  8,  7, 14,  9, 47,\n",
      "        8, 47, 15, 16,  8,  3, 11,  8,  7,  8, 16,  9, 48,  6,  2, 20, 15,\n",
      "       23, 22,  5, 14,  4, 12, 21, 11, 10, 20,  9, 11, 40, 18, 26, 10, 17,\n",
      "       14,  7, 14, 16, 27,  3, 17, 28, 11, 12, 10, 17,  9,  4, 12,  4,  8,\n",
      "       15, 18, 12, 33, 22,  5, 21, 23, 14, 15,  7, 13, 18, 13, 26, 15, 10,\n",
      "       25, 11, 14, 32, 16, 16, 26,  6, 17, 10, 11, 21, 16, 12, 27, 12, 28,\n",
      "       11, 17, 48,  4, 13, 10,  9, 11, 20, 22, 23, 11, 32, 13,  8,  8, 11,\n",
      "       14, 13, 24, 11, 14, 24, 15, 14, 11,  9, 19,  9, 12, 19,  6, 23,  5,\n",
      "       27,  3, 20, 10, 14, 16, 10, 15,  9, 10, 40, 16,  8,  4, 26, 12,  8,\n",
      "       13, 15, 21, 45,  1, 11, 10, 17, 25, 12, 12, 15, 23,  4, 17, 20,  3,\n",
      "        8, 36, 16, 13, 22,  9, 11, 21,  7, 28, 24, 20, 13, 25, 17, 45, 19,\n",
      "       20, 19,  3,  1, 10, 12,  8, 18,  8,  6, 22,  6,  8, 10, 15, 26, 19,\n",
      "       18, 17, 20, 11, 12, 12,  8,  7, 29, 33, 15,  7, 17, 13, 18, 20, 15,\n",
      "       17, 13,  6, 21,  2,  7,  7,  8, 22, 25, 40, 21, 16,  7, 26, 21,  5,\n",
      "        7, 11, 22, 16, 30,  5, 25, 14, 32, 26,  9,  8, 12,  5,  7, 18, 28,\n",
      "       13, 10, 14, 18, 15, 32,  7, 14, 40, 16, 23, 22, 22, 11,  5, 14, 16,\n",
      "       16,  5, 11,  8, 17, 10, 11, 16, 19,  4,  6,  5, 11,  5, 10, 13, 14,\n",
      "        6,  5,  6,  5,  5,  6,  5,  7, 21, 14, 13, 15, 15, 16, 20, 21, 14,\n",
      "       23, 15, 13, 19, 26,  4, 21, 19, 17, 19, 23, 12, 10, 15,  6,  3,  8,\n",
      "        1, 31,  6,  4, 10,  4, 22,  4,  7,  4,  4, 19, 18, 18]), 'FNs': array([ 5,  6, 10,  9,  7, 11,  7, 13,  6,  0,  5,  3,  3,  2,  4,  4,  7,\n",
      "        5,  2,  6,  8, 12,  2,  2,  3,  2, 18, 14,  5,  5, 10,  7, 31, 12,\n",
      "       20, 19, 27,  6,  8,  8, 19,  4, 10,  7, 16, 11, 24, 11,  4, 17,  7,\n",
      "        5, 13,  5, 20, 22,  8,  6, 12, 19, 31, 10, 21,  8, 17, 11, 23, 10,\n",
      "       32,  1,  5,  3,  2, 29, 18,  8,  4,  9, 14,  9,  4,  9,  8,  3,  3,\n",
      "        4, 12,  3,  2,  3,  1,  4,  2,  2,  4,  3,  5,  4,  5, 10,  1, 19,\n",
      "        1, 13,  6,  6, 14,  6, 16,  5, 10,  6, 13,  9, 10,  9, 10, 10,  8,\n",
      "       17, 18,  7, 10,  9, 23,  6, 14,  6,  8,  0,  2,  5,  5,  5, 15,  1,\n",
      "        2,  5,  4,  1,  7,  4,  4,  3,  4,  4,  4,  7,  5,  7, 10, 14, 13,\n",
      "       11,  7, 11,  5,  2, 20,  9,  5, 10, 10, 28,  6, 23, 16, 35, 13,  6,\n",
      "       16, 10, 15, 15,  4, 20,  8, 10,  5, 15, 19,  5,  7, 10, 16, 15, 18,\n",
      "       14, 19, 14, 11, 11, 11, 21,  9,  2, 13, 12,  7, 12, 14, 19, 18,  4,\n",
      "       16, 12, 11,  6,  8, 10, 10,  9, 12,  7,  5,  6,  4,  4,  9, 13, 12,\n",
      "        9, 17, 10, 10,  3, 20, 11,  7,  7,  9, 20,  9, 12,  4, 11, 16, 10,\n",
      "       17,  5, 35, 12, 14,  8,  4,  7, 15,  2, 29, 11, 24,  1,  9,  4,  2,\n",
      "        0,  8, 10,  0,  1,  5,  6,  2,  6, 13, 18, 28,  8,  3, 13,  5, 19,\n",
      "       21, 13,  5,  1,  7, 20, 16,  3, 15, 14, 39,  5,  4, 31,  5, 16, 10,\n",
      "        5, 12,  4,  3,  4,  3,  6,  5, 13, 15,  7,  3,  8, 16, 12, 13, 10,\n",
      "        9,  6,  7, 10, 15, 22, 19, 15, 11, 15,  5,  5, 11, 12,  3,  0,  2,\n",
      "        3,  5,  4,  5,  6,  7, 17, 11,  8,  3,  0,  5,  9,  5, 12,  8,  3,\n",
      "        1, 25,  6,  4,  3, 19,  8,  4, 16, 15,  3,  3,  8, 15,  5,  9, 29,\n",
      "       11, 28, 12,  9,  3, 10,  5,  1,  7, 11,  9, 11, 15,  7, 15,  8, 14,\n",
      "       21,  8,  0, 12,  9,  7, 19, 30, 11, 17,  4, 17, 21,  4,  2, 10, 16,\n",
      "       10,  3,  5, 14, 13,  3,  6, 10, 12, 28, 11, 20,  7,  5, 13, 19,  7,\n",
      "       16, 26,  5, 19, 33, 24, 31, 25,  8,  5, 22, 15,  6, 15, 22, 15, 20,\n",
      "        5,  9, 17, 14, 11,  3, 13,  9, 14, 21, 36, 16, 12, 24,  9, 19, 15,\n",
      "       17, 21,  8, 24, 21, 22,  6, 11,  7, 12, 16, 16, 21, 15, 17, 14,  5,\n",
      "       22, 21, 31, 18, 24, 30, 20,  6, 12, 18, 29, 22,  7,  2, 19, 14,  5,\n",
      "        4, 18, 23, 32, 12, 22, 32, 12, 14, 25,  7, 14, 35, 18, 12,  7, 20,\n",
      "       36, 22,  7,  4, 16, 17, 40,  4, 30, 23, 20, 25, 24, 22, 12, 19, 23,\n",
      "        8, 16,  8, 23, 15, 17, 38, 10,  3, 21, 11, 17, 10, 27, 27, 11, 26,\n",
      "       19,  4, 14, 17, 18,  9,  3, 21,  2, 23,  4, 12, 23,  6, 24, 21, 21,\n",
      "       18,  8, 14,  8,  4, 24, 16, 16,  9, 11,  3, 12, 23, 14, 30, 13,  4,\n",
      "        7,  4,  8,  7,  1, 13, 28,  8,  4,  9, 10, 20,  4,  9, 11,  3, 20,\n",
      "       17, 15,  8, 13, 16,  9, 22, 26, 12, 22, 16, 18, 23, 10, 12, 14,  4,\n",
      "       13, 22, 14, 20, 17, 42, 17, 18,  5,  1,  9, 12,  1, 17, 11,  8,  5,\n",
      "        3, 16,  6, 15, 12,  9, 40, 28, 43, 10, 23, 36, 20,  3, 19, 11,  5,\n",
      "        9,  5, 17, 25, 31, 12, 20, 16, 13, 35, 27,  3, 14,  9, 20, 14,  2,\n",
      "       11, 15, 22, 10, 26, 21, 19, 18, 17, 17, 30, 26, 13, 11, 17,  1, 17,\n",
      "       21, 29, 19, 10, 19,  2,  3,  8, 12,  6, 30,  6, 29, 23, 21, 18,  4,\n",
      "       12, 30, 11, 17,  7,  2, 23,  7,  3, 34, 10, 24, 24, 17,  4, 15, 15,\n",
      "       16, 16,  8, 17,  4, 23, 13,  8, 26, 21,  9, 26, 12, 25, 12, 19,  2,\n",
      "       12, 10,  7, 15, 24,  8, 12, 18,  9,  7, 10, 23,  6,  3, 30, 25, 13,\n",
      "       24,  7, 26,  9, 21,  8, 16, 10,  3, 27, 14, 29, 19, 41, 17,  6, 21,\n",
      "       30, 14, 21,  9, 11, 14, 20,  3, 12, 10, 21, 15, 13, 11, 28, 11, 28,\n",
      "       15,  6, 19, 10, 12,  8,  9, 24, 19, 14, 19, 17, 14, 23,  5, 10,  5,\n",
      "       44,  5, 34, 11, 12, 18,  6,  7, 26, 10, 17, 14, 17, 10, 13, 19, 16,\n",
      "       29,  3,  3,  3,  4, 24,  4, 18, 14, 18, 22, 27, 26,  5, 37,  3, 11,\n",
      "        3, 24, 38, 10,  3,  8,  7, 22, 25, 11, 20, 24, 17,  7, 21, 11,  6,\n",
      "        9, 18, 16, 40, 34, 37, 17,  8, 37, 16, 10, 21, 21, 17,  9, 33, 12,\n",
      "       12, 17, 15,  8, 12, 20, 21, 15, 14, 20, 24, 16, 17,  2, 19, 19,  9,\n",
      "        9, 25, 22,  9, 11, 15,  5,  1, 15, 28,  8, 17, 21,  9, 14, 15, 25,\n",
      "        9, 43,  4, 19,  9, 16,  5, 17, 19, 20, 14,  8,  8, 11, 24, 36,  5,\n",
      "       16, 13,  9, 17, 23, 36, 27, 20, 28, 22, 30, 15,  8, 11,  2,  2, 16,\n",
      "        8, 12,  7, 24,  8, 28, 14, 20,  9,  4, 19, 16, 19, 17, 13,  5, 11,\n",
      "       12,  5,  5,  6, 13, 11,  8, 14, 20,  7,  7,  5, 34,  6, 21, 13, 11,\n",
      "        7,  2,  7,  3,  6,  6,  9,  6, 21, 34, 16, 12, 17,  8, 18, 19, 30,\n",
      "       26, 24,  9, 22, 12,  0, 21, 22, 19, 35, 10, 12, 11, 15,  7,  2,  1,\n",
      "        1, 30,  1,  3,  3,  3,  7,  3,  8,  1,  7, 15, 25, 28]), 'accuracy': 0.73726, 'per_class_accuracy': array([0.9999 , 0.9998 , 0.99954, 0.9996 , 0.99962, 0.99958, 0.99946,\n",
      "       0.99968, 0.99968, 0.99996, 0.99976, 0.99988, 0.99988, 0.99992,\n",
      "       0.99988, 0.99988, 0.99978, 0.99984, 0.99988, 0.99986, 0.99978,\n",
      "       0.99966, 0.99986, 0.99978, 0.99986, 0.9999 , 0.99914, 0.99962,\n",
      "       0.99976, 0.9998 , 0.99952, 0.99968, 0.99912, 0.99946, 0.99944,\n",
      "       0.99928, 0.99918, 0.99954, 0.99976, 0.9996 , 0.99926, 0.9996 ,\n",
      "       0.99958, 0.9997 , 0.99944, 0.99972, 0.99882, 0.99964, 0.99976,\n",
      "       0.9995 , 0.9996 , 0.99986, 0.9993 , 0.99958, 0.99918, 0.99914,\n",
      "       0.99966, 0.99978, 0.99932, 0.99946, 0.9989 , 0.99948, 0.99936,\n",
      "       0.99968, 0.99926, 0.99952, 0.9991 , 0.99954, 0.9991 , 0.99986,\n",
      "       0.99968, 0.99968, 0.99958, 0.99922, 0.9992 , 0.99968, 0.99982,\n",
      "       0.99934, 0.99956, 0.99974, 0.99972, 0.99976, 0.9993 , 0.9999 ,\n",
      "       0.9999 , 0.99972, 0.9996 , 0.99992, 0.9999 , 0.99986, 0.9999 ,\n",
      "       0.99984, 0.99992, 0.99984, 0.99972, 0.99986, 0.99982, 0.99982,\n",
      "       0.99988, 0.9996 , 0.99998, 0.99918, 0.99996, 0.99956, 0.99954,\n",
      "       0.9998 , 0.9996 , 0.9998 , 0.99952, 0.9997 , 0.99966, 0.9998 ,\n",
      "       0.9995 , 0.99958, 0.99944, 0.99964, 0.99972, 0.99976, 0.99962,\n",
      "       0.99908, 0.9995 , 0.9996 , 0.99978, 0.99964, 0.99926, 0.99962,\n",
      "       0.99968, 0.99976, 0.99976, 1.     , 0.99994, 0.9997 , 0.99974,\n",
      "       0.99986, 0.99962, 0.99996, 0.99988, 0.99982, 0.99984, 0.99992,\n",
      "       0.99976, 0.99988, 0.99978, 0.99986, 0.99982, 0.99992, 0.99982,\n",
      "       0.99968, 0.99972, 0.99974, 0.99968, 0.99932, 0.9997 , 0.99948,\n",
      "       0.99964, 0.99938, 0.99982, 0.99976, 0.99954, 0.99938, 0.99984,\n",
      "       0.99942, 0.99922, 0.99938, 0.99972, 0.99944, 0.99924, 0.99926,\n",
      "       0.99942, 0.9998 , 0.99934, 0.99948, 0.99946, 0.99958, 0.99968,\n",
      "       0.99956, 0.99958, 0.99964, 0.99976, 0.9994 , 0.99926, 0.99978,\n",
      "       0.99964, 0.99974, 0.99932, 0.99936, 0.99932, 0.99932, 0.99952,\n",
      "       0.99934, 0.9997 , 0.99946, 0.99924, 0.99936, 0.99968, 0.99974,\n",
      "       0.99958, 0.9994 , 0.99964, 0.99946, 0.99936, 0.9994 , 0.99936,\n",
      "       0.9996 , 0.99938, 0.99946, 0.99964, 0.99958, 0.99932, 0.99962,\n",
      "       0.9997 , 0.99948, 0.99954, 0.9997 , 0.99982, 0.99956, 0.99982,\n",
      "       0.99958, 0.99968, 0.99954, 0.99974, 0.99968, 0.99942, 0.99954,\n",
      "       0.99946, 0.9997 , 0.99932, 0.99944, 0.99982, 0.99978, 0.99958,\n",
      "       0.99932, 0.99938, 0.9995 , 0.9994 , 0.99958, 0.99932, 0.99954,\n",
      "       0.99906, 0.99968, 0.99892, 0.99944, 0.99946, 0.99964, 0.99986,\n",
      "       0.9996 , 0.99952, 0.99986, 0.99904, 0.99926, 0.999  , 0.99988,\n",
      "       0.99974, 0.99978, 0.99978, 0.99988, 0.99962, 0.99958, 0.99978,\n",
      "       0.9998 , 0.99986, 0.99986, 0.99986, 0.99958, 0.99954, 0.999  ,\n",
      "       0.99918, 0.99956, 0.9999 , 0.99942, 0.99978, 0.99936, 0.9993 ,\n",
      "       0.99958, 0.99966, 0.99992, 0.9998 , 0.99928, 0.9993 , 0.99988,\n",
      "       0.9994 , 0.99882, 0.99898, 0.99976, 0.9997 , 0.99914, 0.99982,\n",
      "       0.99944, 0.9996 , 0.99982, 0.99954, 0.9998 , 0.9996 , 0.9998 ,\n",
      "       0.9998 , 0.99956, 0.99978, 0.99972, 0.99952, 0.99976, 0.99972,\n",
      "       0.99968, 0.99946, 0.9995 , 0.99956, 0.99972, 0.99958, 0.99976,\n",
      "       0.9997 , 0.9997 , 0.99936, 0.99912, 0.99916, 0.99946, 0.99964,\n",
      "       0.99938, 0.9997 , 0.99976, 0.99962, 0.99968, 0.99974, 0.99992,\n",
      "       0.99982, 0.99994, 0.99984, 0.9999 , 0.99988, 0.99962, 0.99978,\n",
      "       0.99952, 0.99956, 0.9997 , 0.99976, 0.99986, 0.99976, 0.99966,\n",
      "       0.99968, 0.99968, 0.99974, 0.9999 , 0.99998, 0.99938, 0.99958,\n",
      "       0.99976, 0.9998 , 0.99948, 0.99968, 0.9998 , 0.9993 , 0.9994 ,\n",
      "       0.99988, 0.99992, 0.99954, 0.99952, 0.99976, 0.99978, 0.9992 ,\n",
      "       0.9994 , 0.99908, 0.99918, 0.99958, 0.99986, 0.99968, 0.99986,\n",
      "       0.99988, 0.9997 , 0.99956, 0.9996 , 0.99964, 0.99946, 0.99976,\n",
      "       0.99944, 0.99962, 0.99936, 0.99946, 0.99976, 0.9999 , 0.9996 ,\n",
      "       0.9995 , 0.99946, 0.9992 , 0.99908, 0.99928, 0.99962, 0.99946,\n",
      "       0.99924, 0.99938, 0.99984, 0.99988, 0.9997 , 0.9994 , 0.99956,\n",
      "       0.9999 , 0.9998 , 0.99962, 0.99954, 0.99984, 0.99982, 0.9996 ,\n",
      "       0.99944, 0.9991 , 0.99954, 0.99932, 0.99966, 0.99968, 0.99964,\n",
      "       0.99912, 0.99966, 0.99954, 0.99922, 0.99964, 0.99902, 0.99898,\n",
      "       0.99916, 0.99906, 0.99872, 0.9995 , 0.99968, 0.99932, 0.99916,\n",
      "       0.99974, 0.99916, 0.9993 , 0.99942, 0.99854, 0.99972, 0.9997 ,\n",
      "       0.99938, 0.99934, 0.99968, 0.99986, 0.99918, 0.99952, 0.9994 ,\n",
      "       0.9993 , 0.9989 , 0.99898, 0.99962, 0.9994 , 0.99972, 0.9993 ,\n",
      "       0.99926, 0.99928, 0.99932, 0.99968, 0.999  , 0.9994 , 0.99928,\n",
      "       0.99956, 0.99956, 0.99968, 0.99956, 0.99926, 0.99924, 0.99906,\n",
      "       0.9994 , 0.99938, 0.99936, 0.99972, 0.9993 , 0.99912, 0.99896,\n",
      "       0.99936, 0.99894, 0.999  , 0.99938, 0.99982, 0.99954, 0.99944,\n",
      "       0.9992 , 0.99934, 0.9997 , 0.99972, 0.99928, 0.99922, 0.99974,\n",
      "       0.99982, 0.9992 , 0.99926, 0.99918, 0.99944, 0.99922, 0.99908,\n",
      "       0.99944, 0.99936, 0.99892, 0.99956, 0.99924, 0.99906, 0.99934,\n",
      "       0.9996 , 0.9996 , 0.99928, 0.99916, 0.99916, 0.9996 , 0.99948,\n",
      "       0.99916, 0.99926, 0.99898, 0.99968, 0.99918, 0.99922, 0.99946,\n",
      "       0.9991 , 0.99888, 0.99924, 0.99938, 0.9988 , 0.99932, 0.99964,\n",
      "       0.99944, 0.99954, 0.9992 , 0.99936, 0.99902, 0.99904, 0.99952,\n",
      "       0.99958, 0.99926, 0.99954, 0.99956, 0.99964, 0.99886, 0.99908,\n",
      "       0.9995 , 0.99856, 0.99874, 0.99982, 0.99916, 0.99938, 0.99936,\n",
      "       0.99938, 0.99976, 0.9992 , 0.99988, 0.99896, 0.99976, 0.99944,\n",
      "       0.99934, 0.99968, 0.99924, 0.99908, 0.99896, 0.99926, 0.99966,\n",
      "       0.99952, 0.99966, 0.99952, 0.99908, 0.99942, 0.99942, 0.99962,\n",
      "       0.99946, 0.99986, 0.99964, 0.99938, 0.9996 , 0.99896, 0.9995 ,\n",
      "       0.99966, 0.9997 , 0.99956, 0.99954, 0.99968, 0.99978, 0.99964,\n",
      "       0.99922, 0.99964, 0.99974, 0.9993 , 0.99966, 0.99928, 0.99974,\n",
      "       0.99974, 0.99962, 0.99984, 0.99938, 0.99926, 0.99944, 0.99958,\n",
      "       0.99954, 0.99926, 0.99958, 0.99918, 0.999  , 0.99954, 0.99902,\n",
      "       0.9994 , 0.99928, 0.99942, 0.99944, 0.99954, 0.99938, 0.99974,\n",
      "       0.9994 , 0.99922, 0.99912, 0.99924, 0.99932, 0.99894, 0.9993 ,\n",
      "       0.99932, 0.99968, 0.9999 , 0.9995 , 0.99946, 0.9999 , 0.99924,\n",
      "       0.99962, 0.99948, 0.99968, 0.99958, 0.9994 , 0.99948, 0.99956,\n",
      "       0.99954, 0.99934, 0.99872, 0.99898, 0.99848, 0.99952, 0.99932,\n",
      "       0.99912, 0.99922, 0.9998 , 0.99898, 0.99962, 0.99976, 0.99952,\n",
      "       0.99968, 0.99906, 0.99916, 0.99922, 0.99954, 0.9994 , 0.9992 ,\n",
      "       0.99952, 0.9988 , 0.99882, 0.9998 , 0.9995 , 0.99954, 0.99928,\n",
      "       0.99944, 0.9997 , 0.99958, 0.99954, 0.99902, 0.99966, 0.9992 ,\n",
      "       0.9992 , 0.999  , 0.99952, 0.99924, 0.99908, 0.9992 , 0.99884,\n",
      "       0.99946, 0.99942, 0.99952, 0.99966, 0.99932, 0.99902, 0.99874,\n",
      "       0.99952, 0.99958, 0.99918, 0.9998 , 0.99976, 0.9997 , 0.99948,\n",
      "       0.99974, 0.99914, 0.99944, 0.99926, 0.9994 , 0.9993 , 0.99946,\n",
      "       0.99898, 0.9996 , 0.99846, 0.99948, 0.99934, 0.9997 , 0.9999 ,\n",
      "       0.99932, 0.9997 , 0.9998 , 0.99916, 0.99948, 0.99934, 0.99856,\n",
      "       0.99954, 0.99988, 0.9993 , 0.9994 , 0.99922, 0.99924, 0.99974,\n",
      "       0.99938, 0.99984, 0.9993 , 0.99932, 0.99962, 0.99928, 0.99918,\n",
      "       0.99964, 0.99926, 0.99896, 0.99914, 0.99924, 0.99942, 0.99962,\n",
      "       0.99948, 0.99966, 0.99958, 0.99938, 0.99898, 0.99978, 0.99942,\n",
      "       0.99908, 0.9996 , 0.99962, 0.9996 , 0.9992 , 0.9997 , 0.99986,\n",
      "       0.99916, 0.99942, 0.99958, 0.99922, 0.9995 , 0.99924, 0.99916,\n",
      "       0.99914, 0.99974, 0.99926, 0.99934, 0.99966, 0.99916, 0.99958,\n",
      "       0.99916, 0.99926, 0.99892, 0.99914, 0.99958, 0.99938, 0.9989 ,\n",
      "       0.9995 , 0.9993 , 0.99918, 0.99946, 0.9994 , 0.99908, 0.99982,\n",
      "       0.99942, 0.9996 , 0.99936, 0.99928, 0.99942, 0.99954, 0.9989 ,\n",
      "       0.99954, 0.99888, 0.99948, 0.99954, 0.99866, 0.99972, 0.9995 ,\n",
      "       0.99964, 0.99964, 0.9993 , 0.99922, 0.99928, 0.99916, 0.99944,\n",
      "       0.99908, 0.99928, 0.99974, 0.99964, 0.99968, 0.99884, 0.99964,\n",
      "       0.99884, 0.99956, 0.99948, 0.99916, 0.99958, 0.99958, 0.99926,\n",
      "       0.99962, 0.99928, 0.99954, 0.99942, 0.99942, 0.99962, 0.99916,\n",
      "       0.99958, 0.99888, 0.99988, 0.99954, 0.99974, 0.99964, 0.9992 ,\n",
      "       0.99972, 0.99934, 0.99954, 0.99944, 0.99876, 0.99914, 0.99932,\n",
      "       0.99982, 0.99874, 0.9997 , 0.99962, 0.99968, 0.99922, 0.99882,\n",
      "       0.9989 , 0.99992, 0.99962, 0.99966, 0.99922, 0.999  , 0.99954,\n",
      "       0.99936, 0.99922, 0.9992 , 0.99978, 0.99924, 0.99938, 0.99982,\n",
      "       0.99966, 0.99892, 0.99936, 0.99894, 0.99888, 0.99908, 0.99944,\n",
      "       0.99942, 0.99912, 0.99912, 0.99932, 0.99918, 0.99932, 0.99916,\n",
      "       0.99948, 0.99844, 0.99938, 0.99936, 0.99928, 0.99964, 0.99982,\n",
      "       0.99956, 0.99936, 0.99942, 0.99934, 0.99956, 0.99948, 0.99908,\n",
      "       0.99956, 0.9995 , 0.99976, 0.99932, 0.9991 , 0.99944, 0.99946,\n",
      "       0.99916, 0.99916, 0.9996 , 0.99954, 0.99946, 0.99974, 0.99984,\n",
      "       0.99912, 0.99878, 0.99954, 0.99952, 0.99924, 0.99956, 0.99936,\n",
      "       0.9993 , 0.9992 , 0.99948, 0.99888, 0.9998 , 0.9992 , 0.99978,\n",
      "       0.99954, 0.99976, 0.9995 , 0.99918, 0.9991 , 0.99892, 0.99942,\n",
      "       0.99952, 0.99964, 0.999  , 0.99886, 0.9998 , 0.99954, 0.99952,\n",
      "       0.99938, 0.99934, 0.99894, 0.99918, 0.99896, 0.99932, 0.9988 ,\n",
      "       0.99904, 0.99922, 0.99954, 0.9996 , 0.99968, 0.99982, 0.9996 ,\n",
      "       0.99912, 0.99958, 0.99956, 0.99958, 0.99916, 0.99954, 0.9988 ,\n",
      "       0.99958, 0.99932, 0.99902, 0.9996 , 0.99916, 0.99924, 0.99918,\n",
      "       0.99944, 0.99964, 0.99962, 0.99946, 0.99944, 0.9998 , 0.99968,\n",
      "       0.99972, 0.9994 , 0.99958, 0.99962, 0.9994 , 0.99922, 0.99978,\n",
      "       0.99974, 0.9998 , 0.9991 , 0.99978, 0.99938, 0.99948, 0.9995 ,\n",
      "       0.99974, 0.99986, 0.99974, 0.99984, 0.99978, 0.99976, 0.99972,\n",
      "       0.99974, 0.99916, 0.99904, 0.99942, 0.99946, 0.99936, 0.99952,\n",
      "       0.99924, 0.9992 , 0.99912, 0.99902, 0.99922, 0.99956, 0.99918,\n",
      "       0.99924, 0.99992, 0.99916, 0.99918, 0.99928, 0.99892, 0.99934,\n",
      "       0.99952, 0.99958, 0.9994 , 0.99974, 0.9999 , 0.99982, 0.99996,\n",
      "       0.99878, 0.99986, 0.99986, 0.99974, 0.99986, 0.99942, 0.99986,\n",
      "       0.9997 , 0.9999 , 0.99978, 0.99932, 0.99914, 0.99908]), 'per_class_accuracy_mean': 0.99947452, 'recall': array([0.9 , 0.88, 0.8 , 0.82, 0.86, 0.78, 0.86, 0.74, 0.88, 1.  , 0.9 ,\n",
      "       0.94, 0.94, 0.96, 0.92, 0.92, 0.86, 0.9 , 0.96, 0.88, 0.84, 0.76,\n",
      "       0.96, 0.96, 0.94, 0.96, 0.64, 0.72, 0.9 , 0.9 , 0.8 , 0.86, 0.38,\n",
      "       0.76, 0.6 , 0.62, 0.46, 0.88, 0.84, 0.84, 0.62, 0.92, 0.8 , 0.86,\n",
      "       0.68, 0.78, 0.52, 0.78, 0.92, 0.66, 0.86, 0.9 , 0.74, 0.9 , 0.6 ,\n",
      "       0.56, 0.84, 0.88, 0.76, 0.62, 0.38, 0.8 , 0.58, 0.84, 0.66, 0.78,\n",
      "       0.54, 0.8 , 0.36, 0.98, 0.9 , 0.94, 0.96, 0.42, 0.64, 0.84, 0.92,\n",
      "       0.82, 0.72, 0.82, 0.92, 0.82, 0.84, 0.94, 0.94, 0.92, 0.76, 0.94,\n",
      "       0.96, 0.94, 0.98, 0.92, 0.96, 0.96, 0.92, 0.94, 0.9 , 0.92, 0.9 ,\n",
      "       0.8 , 0.98, 0.62, 0.98, 0.74, 0.88, 0.88, 0.72, 0.88, 0.68, 0.9 ,\n",
      "       0.8 , 0.88, 0.74, 0.82, 0.8 , 0.82, 0.8 , 0.8 , 0.84, 0.66, 0.64,\n",
      "       0.86, 0.8 , 0.82, 0.54, 0.88, 0.72, 0.88, 0.84, 1.  , 0.96, 0.9 ,\n",
      "       0.9 , 0.9 , 0.7 , 0.98, 0.96, 0.9 , 0.92, 0.98, 0.86, 0.92, 0.92,\n",
      "       0.94, 0.92, 0.92, 0.92, 0.86, 0.9 , 0.86, 0.8 , 0.72, 0.74, 0.78,\n",
      "       0.86, 0.78, 0.9 , 0.96, 0.6 , 0.82, 0.9 , 0.8 , 0.8 , 0.44, 0.88,\n",
      "       0.54, 0.68, 0.3 , 0.74, 0.88, 0.68, 0.8 , 0.7 , 0.7 , 0.92, 0.6 ,\n",
      "       0.84, 0.8 , 0.9 , 0.7 , 0.62, 0.9 , 0.86, 0.8 , 0.68, 0.7 , 0.64,\n",
      "       0.72, 0.62, 0.72, 0.78, 0.78, 0.78, 0.58, 0.82, 0.96, 0.74, 0.76,\n",
      "       0.86, 0.76, 0.72, 0.62, 0.64, 0.92, 0.68, 0.76, 0.78, 0.88, 0.84,\n",
      "       0.8 , 0.8 , 0.82, 0.76, 0.86, 0.9 , 0.88, 0.92, 0.92, 0.82, 0.74,\n",
      "       0.76, 0.82, 0.66, 0.8 , 0.8 , 0.94, 0.6 , 0.78, 0.86, 0.86, 0.82,\n",
      "       0.6 , 0.82, 0.76, 0.92, 0.78, 0.68, 0.8 , 0.66, 0.9 , 0.3 , 0.76,\n",
      "       0.72, 0.84, 0.92, 0.86, 0.7 , 0.96, 0.42, 0.78, 0.52, 0.98, 0.82,\n",
      "       0.92, 0.96, 1.  , 0.84, 0.8 , 1.  , 0.98, 0.9 , 0.88, 0.96, 0.88,\n",
      "       0.74, 0.64, 0.44, 0.84, 0.94, 0.74, 0.9 , 0.62, 0.58, 0.74, 0.9 ,\n",
      "       0.98, 0.86, 0.6 , 0.68, 0.94, 0.7 , 0.72, 0.22, 0.9 , 0.92, 0.38,\n",
      "       0.9 , 0.68, 0.8 , 0.9 , 0.76, 0.92, 0.94, 0.92, 0.94, 0.88, 0.9 ,\n",
      "       0.74, 0.7 , 0.86, 0.94, 0.84, 0.68, 0.76, 0.74, 0.8 , 0.82, 0.88,\n",
      "       0.86, 0.8 , 0.7 , 0.56, 0.62, 0.7 , 0.78, 0.7 , 0.9 , 0.9 , 0.78,\n",
      "       0.76, 0.94, 1.  , 0.96, 0.94, 0.9 , 0.92, 0.9 , 0.88, 0.86, 0.66,\n",
      "       0.78, 0.84, 0.94, 1.  , 0.9 , 0.82, 0.9 , 0.76, 0.84, 0.94, 0.98,\n",
      "       0.5 , 0.88, 0.92, 0.94, 0.62, 0.84, 0.92, 0.68, 0.7 , 0.94, 0.94,\n",
      "       0.84, 0.7 , 0.9 , 0.82, 0.42, 0.78, 0.44, 0.76, 0.82, 0.94, 0.8 ,\n",
      "       0.9 , 0.98, 0.86, 0.78, 0.82, 0.78, 0.7 , 0.86, 0.7 , 0.84, 0.72,\n",
      "       0.58, 0.84, 1.  , 0.76, 0.82, 0.86, 0.62, 0.4 , 0.78, 0.66, 0.92,\n",
      "       0.66, 0.58, 0.92, 0.96, 0.8 , 0.68, 0.8 , 0.94, 0.9 , 0.72, 0.74,\n",
      "       0.94, 0.88, 0.8 , 0.76, 0.44, 0.78, 0.6 , 0.86, 0.9 , 0.74, 0.62,\n",
      "       0.86, 0.68, 0.48, 0.9 , 0.62, 0.34, 0.52, 0.38, 0.5 , 0.84, 0.9 ,\n",
      "       0.56, 0.7 , 0.88, 0.7 , 0.56, 0.7 , 0.6 , 0.9 , 0.82, 0.66, 0.72,\n",
      "       0.78, 0.94, 0.74, 0.82, 0.72, 0.58, 0.28, 0.68, 0.76, 0.52, 0.82,\n",
      "       0.62, 0.7 , 0.66, 0.58, 0.84, 0.52, 0.58, 0.56, 0.88, 0.78, 0.86,\n",
      "       0.76, 0.68, 0.68, 0.58, 0.7 , 0.66, 0.72, 0.9 , 0.56, 0.58, 0.38,\n",
      "       0.64, 0.52, 0.4 , 0.6 , 0.88, 0.76, 0.64, 0.42, 0.56, 0.86, 0.96,\n",
      "       0.62, 0.72, 0.9 , 0.92, 0.64, 0.54, 0.36, 0.76, 0.56, 0.36, 0.76,\n",
      "       0.72, 0.5 , 0.86, 0.72, 0.3 , 0.64, 0.76, 0.86, 0.6 , 0.28, 0.56,\n",
      "       0.86, 0.92, 0.68, 0.66, 0.2 , 0.92, 0.4 , 0.54, 0.6 , 0.5 , 0.52,\n",
      "       0.56, 0.76, 0.62, 0.54, 0.84, 0.68, 0.84, 0.54, 0.7 , 0.66, 0.24,\n",
      "       0.8 , 0.94, 0.58, 0.78, 0.66, 0.8 , 0.46, 0.46, 0.78, 0.48, 0.62,\n",
      "       0.92, 0.72, 0.66, 0.64, 0.82, 0.94, 0.58, 0.96, 0.54, 0.92, 0.76,\n",
      "       0.54, 0.88, 0.52, 0.58, 0.58, 0.64, 0.84, 0.72, 0.84, 0.92, 0.52,\n",
      "       0.68, 0.68, 0.82, 0.78, 0.94, 0.76, 0.54, 0.72, 0.4 , 0.74, 0.92,\n",
      "       0.86, 0.92, 0.84, 0.86, 0.98, 0.74, 0.44, 0.84, 0.92, 0.82, 0.8 ,\n",
      "       0.6 , 0.92, 0.82, 0.78, 0.94, 0.6 , 0.66, 0.7 , 0.84, 0.74, 0.68,\n",
      "       0.82, 0.56, 0.48, 0.76, 0.56, 0.68, 0.64, 0.54, 0.8 , 0.76, 0.72,\n",
      "       0.92, 0.74, 0.56, 0.72, 0.6 , 0.66, 0.16, 0.66, 0.64, 0.9 , 0.98,\n",
      "       0.82, 0.76, 0.98, 0.66, 0.78, 0.84, 0.9 , 0.94, 0.68, 0.88, 0.7 ,\n",
      "       0.76, 0.82, 0.2 , 0.44, 0.14, 0.8 , 0.54, 0.28, 0.6 , 0.94, 0.62,\n",
      "       0.78, 0.9 , 0.82, 0.9 , 0.66, 0.5 , 0.38, 0.76, 0.6 , 0.68, 0.74,\n",
      "       0.3 , 0.46, 0.94, 0.72, 0.82, 0.6 , 0.72, 0.96, 0.78, 0.7 , 0.56,\n",
      "       0.8 , 0.48, 0.58, 0.62, 0.64, 0.66, 0.66, 0.4 , 0.48, 0.74, 0.78,\n",
      "       0.66, 0.98, 0.66, 0.58, 0.42, 0.62, 0.8 , 0.62, 0.96, 0.94, 0.84,\n",
      "       0.76, 0.88, 0.4 , 0.88, 0.42, 0.54, 0.58, 0.64, 0.92, 0.76, 0.4 ,\n",
      "       0.78, 0.66, 0.86, 0.96, 0.54, 0.86, 0.94, 0.32, 0.8 , 0.52, 0.52,\n",
      "       0.66, 0.92, 0.7 , 0.7 , 0.68, 0.68, 0.84, 0.66, 0.92, 0.54, 0.74,\n",
      "       0.84, 0.48, 0.58, 0.82, 0.48, 0.76, 0.5 , 0.76, 0.62, 0.96, 0.76,\n",
      "       0.8 , 0.86, 0.7 , 0.52, 0.84, 0.76, 0.64, 0.82, 0.86, 0.8 , 0.54,\n",
      "       0.88, 0.94, 0.4 , 0.5 , 0.74, 0.52, 0.86, 0.48, 0.82, 0.58, 0.84,\n",
      "       0.68, 0.8 , 0.94, 0.46, 0.72, 0.42, 0.62, 0.18, 0.66, 0.88, 0.58,\n",
      "       0.4 , 0.72, 0.58, 0.82, 0.78, 0.72, 0.6 , 0.94, 0.76, 0.8 , 0.58,\n",
      "       0.7 , 0.74, 0.78, 0.44, 0.78, 0.44, 0.7 , 0.88, 0.62, 0.8 , 0.76,\n",
      "       0.84, 0.82, 0.52, 0.62, 0.72, 0.62, 0.66, 0.72, 0.54, 0.9 , 0.8 ,\n",
      "       0.9 , 0.12, 0.9 , 0.32, 0.78, 0.76, 0.64, 0.88, 0.86, 0.48, 0.8 ,\n",
      "       0.66, 0.72, 0.66, 0.8 , 0.74, 0.62, 0.68, 0.42, 0.94, 0.94, 0.94,\n",
      "       0.92, 0.52, 0.92, 0.64, 0.72, 0.64, 0.56, 0.46, 0.48, 0.9 , 0.26,\n",
      "       0.94, 0.78, 0.94, 0.52, 0.24, 0.8 , 0.94, 0.84, 0.86, 0.56, 0.5 ,\n",
      "       0.78, 0.6 , 0.52, 0.66, 0.86, 0.58, 0.78, 0.88, 0.82, 0.64, 0.68,\n",
      "       0.2 , 0.32, 0.26, 0.66, 0.84, 0.26, 0.68, 0.8 , 0.58, 0.58, 0.66,\n",
      "       0.82, 0.34, 0.76, 0.76, 0.66, 0.7 , 0.84, 0.76, 0.6 , 0.58, 0.7 ,\n",
      "       0.72, 0.6 , 0.52, 0.68, 0.66, 0.96, 0.62, 0.62, 0.82, 0.82, 0.5 ,\n",
      "       0.56, 0.82, 0.78, 0.7 , 0.9 , 0.98, 0.7 , 0.44, 0.84, 0.66, 0.58,\n",
      "       0.82, 0.72, 0.7 , 0.5 , 0.82, 0.14, 0.92, 0.62, 0.82, 0.68, 0.9 ,\n",
      "       0.66, 0.62, 0.6 , 0.72, 0.84, 0.84, 0.78, 0.52, 0.28, 0.9 , 0.68,\n",
      "       0.74, 0.82, 0.66, 0.54, 0.28, 0.46, 0.6 , 0.44, 0.56, 0.4 , 0.7 ,\n",
      "       0.84, 0.78, 0.96, 0.96, 0.68, 0.84, 0.76, 0.86, 0.52, 0.84, 0.44,\n",
      "       0.72, 0.6 , 0.82, 0.92, 0.62, 0.68, 0.62, 0.66, 0.74, 0.9 , 0.78,\n",
      "       0.76, 0.9 , 0.9 , 0.88, 0.74, 0.78, 0.84, 0.72, 0.6 , 0.86, 0.86,\n",
      "       0.9 , 0.32, 0.88, 0.58, 0.74, 0.78, 0.86, 0.96, 0.86, 0.94, 0.88,\n",
      "       0.88, 0.82, 0.88, 0.58, 0.32, 0.68, 0.76, 0.66, 0.84, 0.64, 0.62,\n",
      "       0.4 , 0.48, 0.52, 0.82, 0.56, 0.76, 1.  , 0.58, 0.56, 0.62, 0.3 ,\n",
      "       0.8 , 0.76, 0.78, 0.7 , 0.86, 0.96, 0.98, 0.98, 0.4 , 0.98, 0.94,\n",
      "       0.94, 0.94, 0.86, 0.94, 0.84, 0.98, 0.86, 0.7 , 0.5 , 0.44]), 'recall_mean': 0.73726, 'precision': array([1.        , 0.91666667, 0.75471698, 0.78846154, 0.78181818,\n",
      "       0.79591837, 0.68253968, 0.925     , 0.81481481, 0.96153846,\n",
      "       0.86538462, 0.94      , 0.94      , 0.96      , 0.95833333,\n",
      "       0.95833333, 0.91489362, 0.9375    , 0.92307692, 0.97777778,\n",
      "       0.93333333, 0.88372093, 0.90566038, 0.84210526, 0.92156863,\n",
      "       0.94117647, 0.56140351, 0.87804878, 0.86538462, 0.9       ,\n",
      "       0.74074074, 0.82692308, 0.59375   , 0.71698113, 0.78947368,\n",
      "       0.64583333, 0.62162162, 0.72131148, 0.91304348, 0.77777778,\n",
      "       0.63265306, 0.74193548, 0.78431373, 0.84313725, 0.73913043,\n",
      "       0.92857143, 0.42622951, 0.84782609, 0.85185185, 0.80487805,\n",
      "       0.76785714, 0.95744681, 0.62711864, 0.73770492, 0.58823529,\n",
      "       0.57142857, 0.82352941, 0.89795918, 0.63333333, 0.79487179,\n",
      "       0.44186047, 0.71428571, 0.725     , 0.84      , 0.62264151,\n",
      "       0.75      , 0.55102041, 0.75471698, 0.58064516, 0.89090909,\n",
      "       0.80357143, 0.78333333, 0.71641791, 0.67741935, 0.59259259,\n",
      "       0.84      , 0.90196078, 0.63076923, 0.81818182, 0.91111111,\n",
      "       0.82142857, 0.93181818, 0.60869565, 0.95918367, 0.95918367,\n",
      "       0.82142857, 0.82608696, 0.97916667, 0.94117647, 0.92156863,\n",
      "       0.9245283 , 0.92      , 0.96      , 0.88888889, 0.82142857,\n",
      "       0.92156863, 0.91836735, 0.90196078, 0.97826087, 0.8       ,\n",
      "       1.        , 0.58490566, 0.98      , 0.80434783, 0.72131148,\n",
      "       0.91666667, 0.85714286, 0.91666667, 0.80952381, 0.81818182,\n",
      "       0.85106383, 0.91666667, 0.75510204, 0.77358491, 0.68965517,\n",
      "       0.82      , 0.90909091, 0.95238095, 0.79245283, 0.53225806,\n",
      "       0.82051282, 0.76785714, 0.97560976, 0.82      , 0.65853659,\n",
      "       0.77192982, 0.94736842, 0.88      , 0.91304348, 1.        ,\n",
      "       0.97959184, 0.81818182, 0.8490566 , 0.95744681, 0.8974359 ,\n",
      "       0.98      , 0.92307692, 0.91836735, 0.92      , 0.94230769,\n",
      "       0.89583333, 0.95833333, 0.86792453, 0.92156863, 0.90196078,\n",
      "       1.        , 0.90196078, 0.82692308, 0.83333333, 0.87755102,\n",
      "       0.86956522, 0.64285714, 0.94871795, 0.72222222, 0.7962963 ,\n",
      "       0.66101695, 0.91836735, 0.82758621, 0.90909091, 0.65079365,\n",
      "       0.9375    , 0.6779661 , 0.57971014, 0.88      , 0.84615385,\n",
      "       0.84375   , 0.60714286, 0.88235294, 0.69811321, 0.91666667,\n",
      "       0.66666667, 0.71428571, 0.74468085, 0.85365854, 0.79310345,\n",
      "       0.9375    , 0.76363636, 0.83333333, 0.86538462, 0.7       ,\n",
      "       0.63265306, 0.88235294, 0.7962963 , 0.93023256, 0.65384615,\n",
      "       0.67307692, 0.66666667, 0.64285714, 0.86111111, 0.65454545,\n",
      "       0.90697674, 0.70909091, 0.59090909, 0.725     , 0.85416667,\n",
      "       0.81355932, 0.82222222, 0.67857143, 0.7962963 , 0.71698113,\n",
      "       0.66666667, 0.73809524, 0.69565217, 0.74193548, 0.69387755,\n",
      "       0.71698113, 0.84782609, 0.74576271, 0.61764706, 0.81632653,\n",
      "       0.88888889, 0.70689655, 0.7755102 , 0.84313725, 0.91836735,\n",
      "       0.73333333, 0.90196078, 0.73015873, 0.85416667, 0.78723404,\n",
      "       0.97435897, 0.85416667, 0.73333333, 0.75471698, 0.70175439,\n",
      "       0.79661017, 0.68181818, 0.69642857, 0.95555556, 0.91489362,\n",
      "       0.77358491, 0.68181818, 0.65079365, 0.74509804, 0.63888889,\n",
      "       0.79591837, 0.65384615, 0.75471698, 0.52380952, 0.80357143,\n",
      "       0.44117647, 0.7037037 , 0.73469388, 0.80769231, 0.93877551,\n",
      "       0.76785714, 0.79545455, 0.90566038, 0.525     , 0.6       ,\n",
      "       0.5       , 0.90740741, 0.91111111, 0.86792453, 0.84210526,\n",
      "       0.89285714, 0.79245283, 0.78431373, 0.81967213, 0.84482759,\n",
      "       0.95744681, 0.97777778, 0.90566038, 0.74576271, 0.78723404,\n",
      "       0.5       , 0.62857143, 0.75      , 0.95918367, 0.69811321,\n",
      "       0.88235294, 0.70454545, 0.6744186 , 0.82222222, 0.78947368,\n",
      "       0.94230769, 0.93478261, 0.65217391, 0.64150943, 0.94      ,\n",
      "       0.7       , 0.44444444, 0.47826087, 0.86538462, 0.80701754,\n",
      "       0.61290323, 0.91836735, 0.73913043, 0.8       , 0.91836735,\n",
      "       0.7755102 , 0.88461538, 0.734375  , 0.88461538, 0.87037037,\n",
      "       0.73333333, 0.88235294, 0.97368421, 0.79545455, 0.89583333,\n",
      "       0.81034483, 0.84      , 0.75555556, 0.74509804, 0.80434783,\n",
      "       0.90909091, 0.77358491, 0.88      , 0.84313725, 0.88888889,\n",
      "       0.67307692, 0.56      , 0.57407407, 0.74468085, 0.84782609,\n",
      "       0.68627451, 0.81818182, 0.86538462, 0.82978723, 0.9047619 ,\n",
      "       0.8245614 , 0.92592593, 0.87272727, 1.        , 0.9375    ,\n",
      "       0.9787234 , 0.97826087, 0.77192982, 0.91489362, 0.825     ,\n",
      "       0.78      , 0.85714286, 0.83928571, 0.87719298, 0.86538462,\n",
      "       0.83673469, 0.80357143, 0.9047619 , 0.89361702, 0.95918367,\n",
      "       1.        , 0.80645161, 0.74576271, 0.85185185, 0.87037037,\n",
      "       0.81578947, 0.84      , 0.88461538, 0.64150943, 0.7       ,\n",
      "       0.94      , 0.97916667, 0.73684211, 0.79545455, 0.86538462,\n",
      "       0.95348837, 0.65625   , 0.67241379, 0.55      , 0.56716418,\n",
      "       0.77358491, 0.92156863, 0.86956522, 0.95744681, 0.90740741,\n",
      "       0.84313725, 0.78      , 0.78846154, 0.84782609, 0.74468085,\n",
      "       0.89583333, 0.72916667, 0.79245283, 0.66666667, 0.82857143,\n",
      "       0.91304348, 0.90909091, 0.82608696, 0.71929825, 0.68253968,\n",
      "       0.59615385, 0.55555556, 0.609375  , 0.94285714, 0.66666667,\n",
      "       0.61111111, 0.74358974, 0.92      , 0.92307692, 0.88888889,\n",
      "       0.70833333, 0.76923077, 0.95918367, 0.9       , 0.87804878,\n",
      "       0.78723404, 0.90384615, 0.93617021, 0.8       , 0.7037037 ,\n",
      "       0.56410256, 0.76470588, 0.68181818, 0.81132075, 0.80357143,\n",
      "       0.88095238, 0.55357143, 0.81132075, 0.82926829, 0.64864865,\n",
      "       0.77586207, 0.50819672, 0.48571429, 0.59090909, 0.54285714,\n",
      "       0.390625  , 0.71186441, 0.80357143, 0.7       , 0.56451613,\n",
      "       0.8627451 , 0.56451613, 0.68292683, 0.71428571, 0.36144578,\n",
      "       0.83333333, 0.87234043, 0.70212766, 0.65454545, 0.88636364,\n",
      "       0.92156863, 0.56923077, 0.73214286, 0.69230769, 0.6744186 ,\n",
      "       0.42424242, 0.49275362, 0.84444444, 0.8125    , 0.89130435,\n",
      "       0.65957447, 0.61403509, 0.63461538, 0.69047619, 0.84      ,\n",
      "       0.5       , 0.76315789, 0.66666667, 0.73333333, 0.78      ,\n",
      "       0.82692308, 0.79166667, 0.61818182, 0.60714286, 0.52727273,\n",
      "       0.7       , 0.70212766, 0.66666667, 0.83333333, 0.68292683,\n",
      "       0.55769231, 0.475     , 0.69565217, 0.47272727, 0.5       ,\n",
      "       0.73170732, 0.93617021, 0.7755102 , 0.76190476, 0.65625   ,\n",
      "       0.71794872, 0.84313725, 0.8       , 0.64583333, 0.59016393,\n",
      "       0.8490566 , 0.90196078, 0.59259259, 0.65853659, 0.66666667,\n",
      "       0.7037037 , 0.62222222, 0.5625    , 0.7037037 , 0.66666667,\n",
      "       0.46296296, 0.74137931, 0.6       , 0.55555556, 0.68085106,\n",
      "       0.82608696, 0.76785714, 0.65217391, 0.7       , 0.58333333,\n",
      "       0.76785714, 0.67647059, 0.56666667, 0.62264151, 0.47619048,\n",
      "       0.79310345, 0.64516129, 0.62790698, 0.81081081, 0.55555556,\n",
      "       0.44827586, 0.63636364, 0.66666667, 0.43055556, 0.71052632,\n",
      "       0.80769231, 0.73913043, 0.73684211, 0.61363636, 0.67307692,\n",
      "       0.50769231, 0.54545455, 0.74074074, 0.72307692, 0.64444444,\n",
      "       0.76470588, 0.86842105, 0.83333333, 0.43396226, 0.54761905,\n",
      "       0.73584906, 0.34285714, 0.41333333, 0.90196078, 0.5625    ,\n",
      "       0.70212766, 0.69565217, 0.65079365, 0.83928571, 0.60416667,\n",
      "       0.92307692, 0.48214286, 0.85185185, 0.7037037 , 0.72972973,\n",
      "       0.81481481, 0.65      , 0.53703704, 0.48333333, 0.62745098,\n",
      "       0.82352941, 0.7826087 , 0.82352941, 0.6969697 , 0.54166667,\n",
      "       0.72340426, 0.72340426, 0.80392157, 0.70909091, 0.92156863,\n",
      "       0.86363636, 0.77142857, 0.85714286, 0.47619048, 0.75510204,\n",
      "       0.77966102, 0.84313725, 0.71875   , 0.73684211, 0.82692308,\n",
      "       0.83050847, 0.88095238, 0.66666667, 0.80769231, 0.83636364,\n",
      "       0.6119403 , 0.85106383, 0.65217391, 0.83636364, 0.91111111,\n",
      "       0.82978723, 0.90384615, 0.73170732, 0.62264151, 0.72916667,\n",
      "       0.76363636, 0.78723404, 0.61818182, 0.77358491, 0.59574468,\n",
      "       0.5       , 0.7755102 , 0.50909091, 0.70833333, 0.64      ,\n",
      "       0.81818182, 0.68965517, 0.7755102 , 0.67924528, 0.83636364,\n",
      "       0.68518519, 0.62222222, 0.54545455, 0.625     , 0.66      ,\n",
      "       0.42105263, 0.64705882, 0.66666667, 0.80357143, 0.9245283 ,\n",
      "       0.71929825, 0.71698113, 0.9245283 , 0.61111111, 0.82978723,\n",
      "       0.7       , 0.80357143, 0.72307692, 0.70833333, 0.6875    ,\n",
      "       0.83333333, 0.7755102 , 0.63076923, 0.29411765, 0.48888889,\n",
      "       0.175     , 0.74074074, 0.71052632, 0.63636364, 0.6122449 ,\n",
      "       0.87037037, 0.49206349, 0.82978723, 0.86538462, 0.73214286,\n",
      "       0.80357143, 0.52380952, 0.5952381 , 0.7037037 , 0.7755102 ,\n",
      "       0.75      , 0.5862069 , 0.77083333, 0.375     , 0.41818182,\n",
      "       0.87037037, 0.76595745, 0.74545455, 0.65217391, 0.72      ,\n",
      "       0.78688525, 0.79591837, 0.81395349, 0.50909091, 0.85106383,\n",
      "       0.63157895, 0.60416667, 0.5       , 0.84210526, 0.61111111,\n",
      "       0.53225806, 0.66666667, 0.42857143, 0.7254902 , 0.68421053,\n",
      "       0.825     , 0.75384615, 0.66      , 0.50877193, 0.38181818,\n",
      "       0.86111111, 0.78431373, 0.58490566, 0.85714286, 0.83928571,\n",
      "       0.85714286, 0.73076923, 0.8627451 , 0.60606061, 0.66666667,\n",
      "       0.72413793, 0.79411765, 0.6744186 , 0.7804878 , 0.49462366,\n",
      "       0.82608696, 0.29850746, 0.72222222, 0.67346939, 0.84313725,\n",
      "       0.94117647, 0.71052632, 0.84313725, 0.87037037, 0.66666667,\n",
      "       0.71428571, 0.74285714, 0.35135135, 0.84615385, 0.95833333,\n",
      "       0.63636364, 0.7       , 0.59649123, 0.60714286, 0.89361702,\n",
      "       0.70212766, 0.92      , 0.69230769, 0.63793103, 0.79245283,\n",
      "       0.70588235, 0.59183673, 0.82      , 0.68571429, 0.48717949,\n",
      "       0.58139535, 0.59375   , 0.75609756, 0.73846154, 0.73076923,\n",
      "       0.85106383, 0.75438596, 0.68627451, 0.49056604, 0.93333333,\n",
      "       0.69090909, 0.53333333, 0.78846154, 0.78181818, 0.8       ,\n",
      "       0.61363636, 0.83018868, 0.92156863, 0.625     , 0.86206897,\n",
      "       0.82222222, 0.63414634, 0.70491803, 0.66666667, 0.55405405,\n",
      "       0.56862745, 0.89361702, 0.61818182, 0.63492063, 0.7704918 ,\n",
      "       0.60526316, 0.8372093 , 0.61764706, 0.63265306, 0.40909091,\n",
      "       0.55932203, 0.74576271, 0.74358974, 0.44444444, 0.76595745,\n",
      "       0.6744186 , 0.56164384, 0.70909091, 0.69230769, 0.53571429,\n",
      "       0.88679245, 0.69090909, 0.8       , 0.725     , 0.625     ,\n",
      "       0.69811321, 0.76470588, 0.44897959, 0.76470588, 0.44      ,\n",
      "       0.76086957, 0.72131148, 0.39240506, 0.90909091, 0.74509804,\n",
      "       0.80769231, 0.82      , 0.7027027 , 0.60784314, 0.62068966,\n",
      "       0.57407407, 0.75      , 0.52941176, 0.675     , 0.8490566 ,\n",
      "       0.83333333, 0.80357143, 0.3       , 0.77586207, 0.4       ,\n",
      "       0.78      , 0.73076923, 0.57142857, 0.74576271, 0.75438596,\n",
      "       0.68571429, 0.81632653, 0.63461538, 0.8       , 0.73333333,\n",
      "       0.6779661 , 0.86046512, 0.57407407, 0.87179487, 0.4375    ,\n",
      "       0.94      , 0.70149254, 0.8245614 , 0.76666667, 0.61904762,\n",
      "       0.82142857, 0.68085106, 0.8       , 0.76190476, 0.41176471,\n",
      "       0.58974359, 0.75      , 0.91836735, 0.33333333, 0.79661017,\n",
      "       0.82978723, 0.78333333, 0.63414634, 0.36363636, 0.47058824,\n",
      "       0.97916667, 0.79245283, 0.81132075, 0.62222222, 0.5       ,\n",
      "       0.76470588, 0.71428571, 0.63414634, 0.58928571, 0.91489362,\n",
      "       0.63043478, 0.66101695, 0.93617021, 0.83673469, 0.47058824,\n",
      "       0.68      , 0.43478261, 0.42105263, 0.59090909, 0.75      ,\n",
      "       0.66666667, 0.65      , 0.5483871 , 0.625     , 0.59183673,\n",
      "       0.69047619, 0.56896552, 0.70689655, 0.27419355, 0.66666667,\n",
      "       0.65517241, 0.63461538, 0.92105263, 0.97674419, 0.79166667,\n",
      "       0.71428571, 0.78378378, 0.66037736, 0.81818182, 0.83333333,\n",
      "       0.54166667, 0.85      , 0.80487805, 0.82758621, 0.67391304,\n",
      "       0.54385965, 0.68333333, 0.69491525, 0.5952381 , 0.58333333,\n",
      "       0.78846154, 0.76470588, 0.74468085, 0.8490566 , 0.875     ,\n",
      "       0.546875  , 0.4       , 0.73684211, 0.825     , 0.63043478,\n",
      "       0.75925926, 0.66666667, 0.63636364, 0.625     , 0.70689655,\n",
      "       0.35      , 0.88461538, 0.59615385, 0.95348837, 0.82926829,\n",
      "       0.86538462, 0.80487805, 0.58490566, 0.54545455, 0.47368421,\n",
      "       0.66666667, 0.72413793, 0.84782609, 0.5       , 0.4       ,\n",
      "       0.9       , 0.82926829, 0.77083333, 0.65079365, 0.67346939,\n",
      "       0.47368421, 0.73684211, 0.47916667, 0.68181818, 0.40740741,\n",
      "       0.51851852, 0.68965517, 0.81395349, 0.77777778, 0.88636364,\n",
      "       0.87272727, 0.72727273, 0.5483871 , 0.76363636, 0.79166667,\n",
      "       0.75438596, 0.59090909, 0.73684211, 0.40740741, 0.8372093 ,\n",
      "       0.68181818, 0.50617284, 0.74193548, 0.57407407, 0.60714286,\n",
      "       0.58490566, 0.75      , 0.88095238, 0.76271186, 0.70909091,\n",
      "       0.7037037 , 0.9       , 0.80357143, 0.84615385, 0.68518519,\n",
      "       0.79591837, 0.79245283, 0.69230769, 0.6122449 , 0.91489362,\n",
      "       0.87755102, 0.9       , 0.59259259, 0.89795918, 0.74358974,\n",
      "       0.74      , 0.73584906, 0.87755102, 0.90566038, 0.87755102,\n",
      "       0.90384615, 0.89795918, 0.88      , 0.89130435, 0.8627451 ,\n",
      "       0.58      , 0.53333333, 0.72340426, 0.71698113, 0.6875    ,\n",
      "       0.72413793, 0.61538462, 0.59615385, 0.58823529, 0.5106383 ,\n",
      "       0.63414634, 0.75925926, 0.59574468, 0.59375   , 0.92592593,\n",
      "       0.58      , 0.59574468, 0.64583333, 0.44117647, 0.63492063,\n",
      "       0.76      , 0.79591837, 0.7       , 0.87755102, 0.94117647,\n",
      "       0.85964912, 0.98      , 0.39215686, 0.89090909, 0.92156863,\n",
      "       0.8245614 , 0.92156863, 0.66153846, 0.92156863, 0.85714286,\n",
      "       0.9245283 , 0.91489362, 0.64814815, 0.58139535, 0.55      ]), 'precision_mean': 0.740527886021879, 'predicted_class_distribution': array([45, 48, 53, 52, 55, 49, 63, 40, 54, 52, 52, 50, 50, 50, 48, 48, 47,\n",
      "       48, 52, 45, 45, 43, 53, 57, 51, 51, 57, 41, 52, 50, 54, 52, 32, 53,\n",
      "       38, 48, 37, 61, 46, 54, 49, 62, 51, 51, 46, 42, 61, 46, 54, 41, 56,\n",
      "       47, 59, 61, 51, 49, 51, 49, 60, 39, 43, 56, 40, 50, 53, 52, 49, 53,\n",
      "       31, 55, 56, 60, 67, 31, 54, 50, 51, 65, 44, 45, 56, 44, 69, 49, 49,\n",
      "       56, 46, 48, 51, 51, 53, 50, 50, 54, 56, 51, 49, 51, 46, 50, 49, 53,\n",
      "       50, 46, 61, 48, 42, 48, 42, 55, 47, 48, 49, 53, 58, 50, 44, 42, 53,\n",
      "       62, 39, 56, 41, 50, 41, 57, 38, 50, 46, 50, 49, 55, 53, 47, 39, 50,\n",
      "       52, 49, 50, 52, 48, 48, 53, 51, 51, 46, 51, 52, 54, 49, 46, 56, 39,\n",
      "       54, 54, 59, 49, 58, 33, 63, 48, 59, 69, 25, 52, 32, 56, 17, 53, 48,\n",
      "       51, 56, 47, 41, 58, 32, 55, 48, 52, 50, 49, 51, 54, 43, 52, 52, 48,\n",
      "       56, 36, 55, 43, 55, 66, 40, 48, 59, 45, 56, 54, 53, 54, 42, 46, 62,\n",
      "       49, 53, 46, 59, 68, 49, 45, 58, 49, 51, 49, 60, 51, 63, 48, 47, 39,\n",
      "       48, 45, 53, 57, 59, 44, 56, 45, 47, 53, 44, 63, 51, 72, 49, 52, 53,\n",
      "       63, 56, 34, 54, 49, 52, 49, 56, 44, 53, 40, 65, 52, 54, 45, 53, 57,\n",
      "       56, 53, 51, 61, 58, 47, 45, 53, 59, 47, 64, 35, 56, 49, 53, 51, 44,\n",
      "       43, 45, 57, 52, 46, 46, 53, 50, 50, 81, 23, 52, 57, 31, 49, 46, 50,\n",
      "       49, 49, 52, 64, 52, 54, 60, 51, 38, 44, 48, 58, 50, 45, 51, 46, 44,\n",
      "       53, 50, 51, 45, 52, 50, 54, 47, 46, 51, 55, 52, 47, 42, 57, 54, 55,\n",
      "       47, 48, 47, 46, 57, 47, 40, 50, 49, 56, 57, 52, 49, 56, 42, 47, 49,\n",
      "       49, 31, 59, 54, 54, 38, 50, 52, 53, 50, 50, 48, 57, 44, 52, 43, 32,\n",
      "       58, 40, 67, 53, 51, 46, 47, 54, 51, 50, 52, 46, 47, 48, 48, 53, 54,\n",
      "       35, 46, 55, 46, 57, 63, 52, 36, 64, 35, 69, 54, 39, 50, 52, 45, 48,\n",
      "       52, 49, 50, 41, 47, 52, 47, 50, 54, 39, 51, 44, 53, 56, 42, 56, 53,\n",
      "       41, 37, 58, 61, 35, 44, 35, 64, 59, 56, 40, 62, 51, 62, 41, 49, 83,\n",
      "       54, 47, 47, 55, 44, 51, 65, 56, 52, 43, 33, 69, 45, 32, 46, 47, 57,\n",
      "       52, 42, 50, 52, 38, 42, 60, 50, 52, 48, 55, 56, 55, 50, 47, 54, 54,\n",
      "       41, 52, 40, 46, 55, 40, 41, 47, 49, 42, 32, 39, 51, 60, 48, 61, 53,\n",
      "       51, 54, 41, 27, 54, 45, 32, 54, 54, 54, 58, 60, 27, 47, 46, 56, 46,\n",
      "       20, 48, 56, 68, 60, 53, 21, 58, 31, 43, 37, 45, 58, 44, 57, 72, 38,\n",
      "       52, 46, 57, 44, 52, 65, 22, 54, 65, 45, 51, 38, 48, 53, 42, 53, 70,\n",
      "       75, 51, 64, 47, 46, 63, 56, 48, 52, 56, 54, 54, 37, 54, 40, 54, 60,\n",
      "       51, 51, 46, 51, 66, 48, 47, 47, 51, 55, 51, 44, 35, 42, 42, 49, 59,\n",
      "       51, 64, 57, 52, 59, 42, 33, 52, 55, 67, 47, 46, 55, 45, 47, 52, 41,\n",
      "       53, 48, 55, 47, 55, 53, 47, 48, 49, 55, 48, 50, 33, 58, 49, 53, 55,\n",
      "       54, 45, 66, 48, 50, 19, 51, 48, 56, 53, 57, 53, 53, 54, 47, 60, 56,\n",
      "       65, 48, 64, 42, 49, 65, 34, 45, 40, 54, 38, 22, 49, 54, 63, 47, 52,\n",
      "       56, 56, 63, 42, 27, 49, 40, 58, 48, 40, 55, 54, 47, 55, 46, 50, 61,\n",
      "       49, 43, 55, 47, 38, 48, 62, 38, 54, 62, 30, 56, 51, 57, 40, 65, 50,\n",
      "       57, 55, 36, 51, 53, 56, 56, 49, 52, 51, 33, 66, 29, 34, 43, 41, 93,\n",
      "       46, 67, 54, 49, 51, 51, 38, 51, 54, 24, 56, 35, 74, 39, 48, 55, 50,\n",
      "       57, 56, 47, 47, 50, 39, 58, 53, 34, 49, 50, 35, 78, 43, 64, 41, 65,\n",
      "       52, 47, 57, 51, 53, 45, 55, 60, 52, 55, 50, 44, 53, 51, 32, 29, 45,\n",
      "       41, 61, 36, 74, 51, 47, 55, 63, 61, 38, 43, 34, 49, 22, 59, 59, 39,\n",
      "       45, 47, 43, 73, 55, 52, 56, 53, 55, 50, 40, 56, 53, 51, 49, 51, 50,\n",
      "       46, 61, 79, 44, 51, 52, 50, 37, 51, 58, 54, 44, 68, 40, 53, 48, 56,\n",
      "       20, 58, 40, 50, 52, 56, 59, 57, 35, 49, 52, 45, 45, 59, 43, 54, 39,\n",
      "       48, 50, 67, 57, 60, 42, 56, 47, 45, 42, 68, 39, 32, 49, 39, 59, 47,\n",
      "       60, 41, 33, 85, 48, 53, 53, 45, 50, 51, 42, 41, 56, 47, 46, 59, 47,\n",
      "       49, 68, 50, 23, 38, 22, 44, 63, 20, 62, 64, 49, 42, 58, 58, 62, 57,\n",
      "       58, 52, 38, 43, 48, 42, 37, 53, 44, 36, 48, 40, 41, 58, 46, 57, 60,\n",
      "       59, 42, 48, 52, 51, 47, 53, 56, 64, 55, 57, 40, 46, 54, 54, 55, 40,\n",
      "       58, 20, 52, 52, 43, 41, 52, 41, 53, 55, 76, 63, 58, 46, 52, 35, 50,\n",
      "       41, 48, 63, 49, 57, 19, 48, 44, 54, 54, 29, 43, 54, 44, 55, 66, 62,\n",
      "       55, 48, 57, 44, 57, 54, 43, 44, 81, 62, 54, 56, 53, 44, 42, 59, 55,\n",
      "       54, 50, 56, 52, 54, 49, 53, 52, 49, 47, 49, 50, 27, 49, 39, 50, 53,\n",
      "       49, 53, 49, 52, 49, 50, 46, 51, 50, 30, 47, 53, 48, 58, 52, 52, 34,\n",
      "       47, 41, 54, 47, 64, 54, 50, 47, 48, 34, 63, 50, 49, 50, 49, 51, 57,\n",
      "       50, 51, 55, 51, 57, 51, 65, 51, 49, 53, 47, 54, 43, 40]), 'f1': array([0.94736842, 0.89795918, 0.77669903, 0.80392157, 0.81904762,\n",
      "       0.78787879, 0.76106195, 0.82222222, 0.84615385, 0.98039216,\n",
      "       0.88235294, 0.94      , 0.94      , 0.96      , 0.93877551,\n",
      "       0.93877551, 0.88659794, 0.91836735, 0.94117647, 0.92631579,\n",
      "       0.88421053, 0.8172043 , 0.93203883, 0.89719626, 0.93069307,\n",
      "       0.95049505, 0.59813084, 0.79120879, 0.88235294, 0.9       ,\n",
      "       0.76923077, 0.84313725, 0.46341463, 0.73786408, 0.68181818,\n",
      "       0.63265306, 0.52873563, 0.79279279, 0.875     , 0.80769231,\n",
      "       0.62626263, 0.82142857, 0.79207921, 0.85148515, 0.70833333,\n",
      "       0.84782609, 0.46846847, 0.8125    , 0.88461538, 0.72527473,\n",
      "       0.81132075, 0.92783505, 0.67889908, 0.81081081, 0.59405941,\n",
      "       0.56565657, 0.83168317, 0.88888889, 0.69090909, 0.69662921,\n",
      "       0.40860215, 0.75471698, 0.64444444, 0.84      , 0.6407767 ,\n",
      "       0.76470588, 0.54545455, 0.77669903, 0.44444444, 0.93333333,\n",
      "       0.8490566 , 0.85454545, 0.82051282, 0.51851852, 0.61538462,\n",
      "       0.84      , 0.91089109, 0.71304348, 0.76595745, 0.86315789,\n",
      "       0.86792453, 0.87234043, 0.70588235, 0.94949495, 0.94949495,\n",
      "       0.86792453, 0.79166667, 0.95918367, 0.95049505, 0.93069307,\n",
      "       0.95145631, 0.92      , 0.96      , 0.92307692, 0.86792453,\n",
      "       0.93069307, 0.90909091, 0.91089109, 0.9375    , 0.8       ,\n",
      "       0.98989899, 0.60194175, 0.98      , 0.77083333, 0.79279279,\n",
      "       0.89795918, 0.7826087 , 0.89795918, 0.73913043, 0.85714286,\n",
      "       0.82474227, 0.89795918, 0.74747475, 0.7961165 , 0.74074074,\n",
      "       0.82      , 0.85106383, 0.86956522, 0.81553398, 0.58928571,\n",
      "       0.71910112, 0.81132075, 0.87912088, 0.82      , 0.59340659,\n",
      "       0.82242991, 0.81818182, 0.88      , 0.875     , 1.        ,\n",
      "       0.96969697, 0.85714286, 0.87378641, 0.92783505, 0.78651685,\n",
      "       0.98      , 0.94117647, 0.90909091, 0.92      , 0.96078431,\n",
      "       0.87755102, 0.93877551, 0.89320388, 0.93069307, 0.91089109,\n",
      "       0.95833333, 0.91089109, 0.84313725, 0.86538462, 0.86868687,\n",
      "       0.83333333, 0.67924528, 0.83146067, 0.75      , 0.82692308,\n",
      "       0.71559633, 0.90909091, 0.88888889, 0.72289157, 0.72566372,\n",
      "       0.91836735, 0.73394495, 0.67226891, 0.58666667, 0.8627451 ,\n",
      "       0.65853659, 0.64150943, 0.44776119, 0.7184466 , 0.89795918,\n",
      "       0.67326733, 0.75471698, 0.72164948, 0.76923077, 0.85185185,\n",
      "       0.73170732, 0.8       , 0.81632653, 0.88235294, 0.7       ,\n",
      "       0.62626263, 0.89108911, 0.82692308, 0.86021505, 0.66666667,\n",
      "       0.68627451, 0.65306122, 0.67924528, 0.72093023, 0.68571429,\n",
      "       0.83870968, 0.74285714, 0.67241379, 0.64444444, 0.83673469,\n",
      "       0.88073394, 0.77894737, 0.71698113, 0.82692308, 0.73786408,\n",
      "       0.69230769, 0.67391304, 0.66666667, 0.82142857, 0.68686869,\n",
      "       0.73786408, 0.8125    , 0.80733945, 0.71186441, 0.80808081,\n",
      "       0.84210526, 0.75925926, 0.76767677, 0.85148515, 0.90909091,\n",
      "       0.8       , 0.91089109, 0.81415929, 0.83673469, 0.7628866 ,\n",
      "       0.85393258, 0.83673469, 0.69473684, 0.77669903, 0.74766355,\n",
      "       0.86238532, 0.63829787, 0.73584906, 0.90526316, 0.88659794,\n",
      "       0.7961165 , 0.63829787, 0.72566372, 0.75247525, 0.75409836,\n",
      "       0.78787879, 0.66666667, 0.77669903, 0.5840708 , 0.8490566 ,\n",
      "       0.35714286, 0.73076923, 0.72727273, 0.82352941, 0.92929293,\n",
      "       0.81132075, 0.74468085, 0.93203883, 0.46666667, 0.67826087,\n",
      "       0.50980392, 0.94230769, 0.86315789, 0.89320388, 0.89719626,\n",
      "       0.94339623, 0.81553398, 0.79207921, 0.9009009 , 0.90740741,\n",
      "       0.92783505, 0.92631579, 0.93203883, 0.80733945, 0.7628866 ,\n",
      "       0.56140351, 0.51764706, 0.79245283, 0.94949495, 0.7184466 ,\n",
      "       0.89108911, 0.65957447, 0.62365591, 0.77894737, 0.8411215 ,\n",
      "       0.96078431, 0.89583333, 0.625     , 0.66019417, 0.94      ,\n",
      "       0.7       , 0.54961832, 0.30136986, 0.88235294, 0.85981308,\n",
      "       0.4691358 , 0.90909091, 0.70833333, 0.8       , 0.90909091,\n",
      "       0.76767677, 0.90196078, 0.8245614 , 0.90196078, 0.90384615,\n",
      "       0.8       , 0.89108911, 0.84090909, 0.74468085, 0.87755102,\n",
      "       0.87037037, 0.84      , 0.71578947, 0.75247525, 0.77083333,\n",
      "       0.85106383, 0.7961165 , 0.88      , 0.85148515, 0.84210526,\n",
      "       0.68627451, 0.56      , 0.59615385, 0.72164948, 0.8125    ,\n",
      "       0.69306931, 0.85714286, 0.88235294, 0.80412371, 0.82608696,\n",
      "       0.87850467, 0.96153846, 0.91428571, 0.96907216, 0.91836735,\n",
      "       0.94845361, 0.9375    , 0.82242991, 0.88659794, 0.73333333,\n",
      "       0.78      , 0.84848485, 0.88679245, 0.93457944, 0.88235294,\n",
      "       0.82828283, 0.8490566 , 0.82608696, 0.86597938, 0.94949495,\n",
      "       0.98989899, 0.61728395, 0.80733945, 0.88461538, 0.90384615,\n",
      "       0.70454545, 0.84      , 0.90196078, 0.66019417, 0.7       ,\n",
      "       0.94      , 0.95918367, 0.78504673, 0.74468085, 0.88235294,\n",
      "       0.88172043, 0.51219512, 0.72222222, 0.48888889, 0.64957265,\n",
      "       0.7961165 , 0.93069307, 0.83333333, 0.92783505, 0.94230769,\n",
      "       0.85148515, 0.78      , 0.80392157, 0.8125    , 0.72164948,\n",
      "       0.87755102, 0.71428571, 0.81553398, 0.69230769, 0.68235294,\n",
      "       0.875     , 0.95238095, 0.79166667, 0.76635514, 0.76106195,\n",
      "       0.60784314, 0.46511628, 0.68421053, 0.77647059, 0.77310924,\n",
      "       0.63461538, 0.65168539, 0.92      , 0.94117647, 0.84210526,\n",
      "       0.69387755, 0.78431373, 0.94949495, 0.9       , 0.79120879,\n",
      "       0.7628866 , 0.92156863, 0.90721649, 0.8       , 0.73076923,\n",
      "       0.49438202, 0.77227723, 0.63829787, 0.83495146, 0.8490566 ,\n",
      "       0.80434783, 0.58490566, 0.83495146, 0.74725275, 0.55172414,\n",
      "       0.83333333, 0.55855856, 0.4       , 0.55319149, 0.44705882,\n",
      "       0.43859649, 0.7706422 , 0.8490566 , 0.62222222, 0.625     ,\n",
      "       0.87128713, 0.625     , 0.61538462, 0.70707071, 0.45112782,\n",
      "       0.86538462, 0.84536082, 0.68041237, 0.68571429, 0.82978723,\n",
      "       0.93069307, 0.64347826, 0.77358491, 0.70588235, 0.62365591,\n",
      "       0.3373494 , 0.57142857, 0.8       , 0.63414634, 0.85416667,\n",
      "       0.63917526, 0.65420561, 0.64705882, 0.63043478, 0.84      ,\n",
      "       0.50980392, 0.65909091, 0.60869565, 0.8       , 0.78      ,\n",
      "       0.84313725, 0.7755102 , 0.64761905, 0.64150943, 0.55238095,\n",
      "       0.7       , 0.68041237, 0.69230769, 0.86538462, 0.61538462,\n",
      "       0.56862745, 0.42222222, 0.66666667, 0.4952381 , 0.44444444,\n",
      "       0.65934066, 0.90721649, 0.76767677, 0.69565217, 0.51219512,\n",
      "       0.62921348, 0.85148515, 0.87272727, 0.63265306, 0.64864865,\n",
      "       0.87378641, 0.91089109, 0.61538462, 0.59340659, 0.46753247,\n",
      "       0.73076923, 0.58947368, 0.43902439, 0.73076923, 0.69230769,\n",
      "       0.48076923, 0.7962963 , 0.65454545, 0.38961039, 0.65979381,\n",
      "       0.79166667, 0.81132075, 0.625     , 0.4       , 0.57142857,\n",
      "       0.81132075, 0.77966102, 0.61818182, 0.6407767 , 0.28169014,\n",
      "       0.85185185, 0.49382716, 0.58064516, 0.68965517, 0.52631579,\n",
      "       0.48148148, 0.59574468, 0.71028037, 0.50819672, 0.61363636,\n",
      "       0.82352941, 0.70833333, 0.78504673, 0.57446809, 0.68627451,\n",
      "       0.57391304, 0.33333333, 0.76923077, 0.8173913 , 0.61052632,\n",
      "       0.77227723, 0.75      , 0.81632653, 0.44660194, 0.5       ,\n",
      "       0.75728155, 0.4       , 0.496     , 0.91089109, 0.63157895,\n",
      "       0.68041237, 0.66666667, 0.72566372, 0.88679245, 0.59183673,\n",
      "       0.94117647, 0.50943396, 0.88461538, 0.73076923, 0.62068966,\n",
      "       0.84615385, 0.57777778, 0.55769231, 0.52727273, 0.63366337,\n",
      "       0.83168317, 0.75      , 0.83168317, 0.79310345, 0.53061224,\n",
      "       0.70103093, 0.70103093, 0.81188119, 0.74285714, 0.93069307,\n",
      "       0.80851064, 0.63529412, 0.7826087 , 0.43478261, 0.74747475,\n",
      "       0.8440367 , 0.85148515, 0.80701754, 0.78504673, 0.84313725,\n",
      "       0.89908257, 0.80434783, 0.53012048, 0.82352941, 0.87619048,\n",
      "       0.7008547 , 0.82474227, 0.625     , 0.87619048, 0.86315789,\n",
      "       0.80412371, 0.92156863, 0.65934066, 0.6407767 , 0.71428571,\n",
      "       0.8       , 0.7628866 , 0.64761905, 0.7961165 , 0.57731959,\n",
      "       0.48979592, 0.76767677, 0.53333333, 0.69387755, 0.64      ,\n",
      "       0.65060241, 0.74074074, 0.76767677, 0.69902913, 0.87619048,\n",
      "       0.71153846, 0.58947368, 0.62068966, 0.6122449 , 0.66      ,\n",
      "       0.23188406, 0.65346535, 0.65306122, 0.8490566 , 0.95145631,\n",
      "       0.76635514, 0.73786408, 0.95145631, 0.63461538, 0.80412371,\n",
      "       0.76363636, 0.8490566 , 0.8173913 , 0.69387755, 0.77192982,\n",
      "       0.76086957, 0.76767677, 0.71304348, 0.23809524, 0.46315789,\n",
      "       0.15555556, 0.76923077, 0.61363636, 0.38888889, 0.60606061,\n",
      "       0.90384615, 0.54867257, 0.80412371, 0.88235294, 0.77358491,\n",
      "       0.8490566 , 0.5840708 , 0.54347826, 0.49350649, 0.76767677,\n",
      "       0.66666667, 0.62962963, 0.75510204, 0.33333333, 0.43809524,\n",
      "       0.90384615, 0.74226804, 0.78095238, 0.625     , 0.72      ,\n",
      "       0.86486486, 0.78787879, 0.75268817, 0.53333333, 0.82474227,\n",
      "       0.54545455, 0.59183673, 0.55357143, 0.72727273, 0.63461538,\n",
      "       0.58928571, 0.5       , 0.45283019, 0.73267327, 0.72897196,\n",
      "       0.73333333, 0.85217391, 0.66      , 0.54205607, 0.4       ,\n",
      "       0.72093023, 0.79207921, 0.60194175, 0.90566038, 0.88679245,\n",
      "       0.84848485, 0.74509804, 0.87128713, 0.48192771, 0.75862069,\n",
      "       0.53164557, 0.64285714, 0.62365591, 0.7032967 , 0.64335664,\n",
      "       0.79166667, 0.34188034, 0.75      , 0.66666667, 0.85148515,\n",
      "       0.95049505, 0.61363636, 0.85148515, 0.90384615, 0.43243243,\n",
      "       0.75471698, 0.61176471, 0.41935484, 0.74157303, 0.93877551,\n",
      "       0.66666667, 0.7       , 0.63551402, 0.64150943, 0.86597938,\n",
      "       0.68041237, 0.92      , 0.60674157, 0.68518519, 0.81553398,\n",
      "       0.57142857, 0.58585859, 0.82      , 0.56470588, 0.59375   ,\n",
      "       0.53763441, 0.66666667, 0.68131868, 0.83478261, 0.74509804,\n",
      "       0.82474227, 0.80373832, 0.69306931, 0.50485437, 0.88421053,\n",
      "       0.72380952, 0.58181818, 0.80392157, 0.81904762, 0.8       ,\n",
      "       0.57446809, 0.85436893, 0.93069307, 0.48780488, 0.63291139,\n",
      "       0.77894737, 0.57142857, 0.77477477, 0.55813953, 0.66129032,\n",
      "       0.57425743, 0.86597938, 0.64761905, 0.7079646 , 0.84684685,\n",
      "       0.52272727, 0.77419355, 0.5       , 0.62626263, 0.25      ,\n",
      "       0.60550459, 0.80733945, 0.65168539, 0.42105263, 0.74226804,\n",
      "       0.62365591, 0.66666667, 0.74285714, 0.70588235, 0.56603774,\n",
      "       0.91262136, 0.72380952, 0.8       , 0.64444444, 0.66037736,\n",
      "       0.7184466 , 0.77227723, 0.44444444, 0.77227723, 0.44      ,\n",
      "       0.72916667, 0.79279279, 0.48062016, 0.85106383, 0.75247525,\n",
      "       0.82352941, 0.82      , 0.59770115, 0.61386139, 0.66666667,\n",
      "       0.59615385, 0.70212766, 0.61016949, 0.6       , 0.87378641,\n",
      "       0.81632653, 0.8490566 , 0.17142857, 0.83333333, 0.35555556,\n",
      "       0.78      , 0.74509804, 0.60377358, 0.80733945, 0.80373832,\n",
      "       0.56470588, 0.80808081, 0.64705882, 0.75789474, 0.69473684,\n",
      "       0.73394495, 0.79569892, 0.59615385, 0.76404494, 0.42857143,\n",
      "       0.94      , 0.8034188 , 0.87850467, 0.83636364, 0.56521739,\n",
      "       0.86792453, 0.65979381, 0.75789474, 0.69565217, 0.47457627,\n",
      "       0.51685393, 0.58536585, 0.90909091, 0.29213483, 0.86238532,\n",
      "       0.80412371, 0.85454545, 0.57142857, 0.28915663, 0.59259259,\n",
      "       0.95918367, 0.81553398, 0.83495146, 0.58947368, 0.5       ,\n",
      "       0.77227723, 0.65217391, 0.57142857, 0.62264151, 0.88659794,\n",
      "       0.60416667, 0.71559633, 0.90721649, 0.82828283, 0.54237288,\n",
      "       0.68      , 0.2739726 , 0.36363636, 0.36111111, 0.70212766,\n",
      "       0.74336283, 0.37142857, 0.60714286, 0.70175439, 0.58585859,\n",
      "       0.63043478, 0.61111111, 0.75925926, 0.30357143, 0.71028037,\n",
      "       0.7037037 , 0.64705882, 0.79545455, 0.90322581, 0.7755102 ,\n",
      "       0.65217391, 0.66666667, 0.67961165, 0.76595745, 0.69767442,\n",
      "       0.53061224, 0.75555556, 0.72527473, 0.88888889, 0.64583333,\n",
      "       0.57943925, 0.74545455, 0.75229358, 0.54347826, 0.57142857,\n",
      "       0.80392157, 0.77227723, 0.72164948, 0.87378641, 0.9245283 ,\n",
      "       0.61403509, 0.41904762, 0.78504673, 0.73333333, 0.60416667,\n",
      "       0.78846154, 0.69230769, 0.66666667, 0.55555556, 0.75925926,\n",
      "       0.2       , 0.90196078, 0.60784314, 0.88172043, 0.74725275,\n",
      "       0.88235294, 0.72527473, 0.60194175, 0.57142857, 0.57142857,\n",
      "       0.74336283, 0.77777778, 0.8125    , 0.50980392, 0.32941176,\n",
      "       0.9       , 0.74725275, 0.75510204, 0.72566372, 0.66666667,\n",
      "       0.5046729 , 0.4057971 , 0.46938776, 0.63829787, 0.42307692,\n",
      "       0.53846154, 0.50632911, 0.75268817, 0.80769231, 0.82978723,\n",
      "       0.91428571, 0.82758621, 0.60714286, 0.8       , 0.7755102 ,\n",
      "       0.80373832, 0.55319149, 0.78504673, 0.42307692, 0.77419355,\n",
      "       0.63829787, 0.6259542 , 0.82142857, 0.59615385, 0.64150943,\n",
      "       0.60194175, 0.70212766, 0.80434783, 0.82568807, 0.74285714,\n",
      "       0.73076923, 0.9       , 0.8490566 , 0.8627451 , 0.71153846,\n",
      "       0.78787879, 0.81553398, 0.70588235, 0.60606061, 0.88659794,\n",
      "       0.86868687, 0.9       , 0.41558442, 0.88888889, 0.65168539,\n",
      "       0.74      , 0.75728155, 0.86868687, 0.93203883, 0.86868687,\n",
      "       0.92156863, 0.88888889, 0.88      , 0.85416667, 0.87128713,\n",
      "       0.58      , 0.4       , 0.70103093, 0.73786408, 0.67346939,\n",
      "       0.77777778, 0.62745098, 0.60784314, 0.47619048, 0.49484536,\n",
      "       0.57142857, 0.78846154, 0.57731959, 0.66666667, 0.96153846,\n",
      "       0.58      , 0.57731959, 0.63265306, 0.35714286, 0.7079646 ,\n",
      "       0.76      , 0.78787879, 0.7       , 0.86868687, 0.95049505,\n",
      "       0.91588785, 0.98      , 0.3960396 , 0.93333333, 0.93069307,\n",
      "       0.87850467, 0.93069307, 0.74782609, 0.93069307, 0.84848485,\n",
      "       0.95145631, 0.88659794, 0.67307692, 0.53763441, 0.48888889]), 'f1_mean': 0.7334358303820108, 'bump_amount': -1.5}\n"
     ]
    }
   ],
   "source": [
    "pre_log = predict_with_bump(\n",
    "    data_loader=val_loader,\n",
    "    model=model,\n",
    "    loss_fn=None,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device,\n",
    "    # target_class_idx=0,\n",
    "    bump_amounts=np.zeros(n_classes),\n",
    "    output_save_path=None,\n",
    "    log_save_path=None)\n",
    "\n",
    "print(\"Pre edit results:\")\n",
    "print(\"Overall Accuracy: {}\".format(pre_log['metrics']['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1563/1563 [02:32<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "post_log = predict_with_bump(\n",
    "    data_loader=val_loader,\n",
    "    model=model,\n",
    "    loss_fn=None,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device,\n",
    "    # target_class_idx=0,\n",
    "    bump_amounts=accumulated_bump_amounts,\n",
    "    output_save_path=None,\n",
    "    log_save_path=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "Change in metrics:\n",
      "Overall accuracy: 0.7373 -> 0.7365\n",
      "Examining per class metrics for snowmobile (802)\n",
      "accuracy: 0.9997 -> 0.9999\n",
      "recall: 0.9400 -> 0.9200\n",
      "precision: 0.8246 -> 0.9388\n",
      "---***---\n",
      "Examining per class metrics for racer, race car, racing car (751)\n",
      "accuracy: 0.9992 -> 0.9981\n",
      "recall: 0.8200 -> 0.8600\n",
      "precision: 0.5616 -> 0.3258\n",
      "---***---\n",
      "Examining per class metrics for snowplow, snowplough (803)\n",
      "accuracy: 0.9996 -> 0.9997\n",
      "recall: 0.9200 -> 0.8400\n",
      "precision: 0.7667 -> 0.8936\n",
      "---***---\n",
      "Examining per class metrics for motor scooter, scooter (670)\n",
      "accuracy: 0.9997 -> 0.9997\n",
      "recall: 0.8400 -> 0.7600\n",
      "precision: 0.8571 -> 0.9048\n",
      "---***---\n",
      "Examining per class metrics for school bus (779)\n",
      "accuracy: 0.9997 -> 0.9997\n",
      "recall: 0.9000 -> 0.9200\n",
      "precision: 0.8491 -> 0.7931\n",
      "---***---\n",
      "Examining per class metrics for dalmatian, coach dog, carriage dog (251)\n",
      "accuracy: 0.9999 -> 0.9998\n",
      "recall: 0.9800 -> 0.9800\n",
      "precision: 0.9074 -> 0.8305\n",
      "---***---\n",
      "Examining per class metrics for fire engine, fire truck (555)\n",
      "accuracy: 0.9996 -> 0.9997\n",
      "recall: 0.7600 -> 0.7200\n",
      "precision: 0.8636 -> 0.9231\n",
      "---***---\n",
      "Examining per class metrics for trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi (867)\n",
      "accuracy: 0.9995 -> 0.9991\n",
      "recall: 0.8200 -> 0.8400\n",
      "precision: 0.6949 -> 0.5385\n",
      "---***---\n",
      "Examining per class metrics for tractor (866)\n",
      "accuracy: 0.9994 -> 0.9992\n",
      "recall: 0.8200 -> 0.9200\n",
      "precision: 0.6833 -> 0.5679\n",
      "---***---\n",
      "Examining per class metrics for amphibian, amphibious vehicle (408)\n",
      "accuracy: 0.9995 -> 0.9996\n",
      "recall: 0.6800 -> 0.6600\n",
      "precision: 0.8293 -> 0.8919\n",
      "---***---\n",
      "Examining per class metrics for car wheel (479)\n",
      "accuracy: 0.9992 -> 0.9992\n",
      "recall: 0.3600 -> 0.3600\n",
      "precision: 0.6667 -> 0.6923\n",
      "---***---\n",
      "Examining per class metrics for traffic light, traffic signal, stoplight (920)\n",
      "accuracy: 0.9996 -> 0.9993\n",
      "recall: 0.8600 -> 0.8800\n",
      "precision: 0.7544 -> 0.6027\n",
      "---***---\n",
      "Examining per class metrics for moped (665)\n",
      "accuracy: 0.9995 -> 0.9993\n",
      "recall: 0.6200 -> 0.7200\n",
      "precision: 0.8611 -> 0.6545\n",
      "---***---\n",
      "Examining per class metrics for tank, army tank, armored combat vehicle, armoured combat vehicle (847)\n",
      "accuracy: 0.9995 -> 0.9995\n",
      "recall: 0.8200 -> 0.8400\n",
      "precision: 0.7069 -> 0.7000\n",
      "---***---\n"
     ]
    }
   ],
   "source": [
    "pre_metrics = pre_log['metrics']\n",
    "post_metrics = post_log['metrics']\n",
    "\n",
    "print(\"Change in metrics:\")\n",
    "print(\"Overall accuracy: {:.4f} -> {:.4f}\".format(pre_metrics['accuracy'], post_metrics['accuracy']))\n",
    "for selected_class in selected_classes:\n",
    "    print(\"Examining per class metrics for {} ({})\".format(CD[selected_class], selected_class))\n",
    "    print(\"accuracy: {:.4f} -> {:.4f}\".format(\n",
    "        pre_metrics['per_class_accuracy'][selected_class],\n",
    "        post_metrics['per_class_accuracy'][selected_class]))\n",
    "    print(\"recall: {:.4f} -> {:.4f}\".format(\n",
    "        pre_metrics['recall'][selected_class],\n",
    "        post_metrics['recall'][selected_class]))\n",
    "    print(\"precision: {:.4f} -> {:.4f}\".format(\n",
    "        pre_metrics['precision'][selected_class],\n",
    "        post_metrics['precision'][selected_class]))\n",
    "    print(\"---***---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze edited model (using images) in ImageNet validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = classifier_helpers.get_default_paths(DATASET_NAME, arch=ARCH)\n",
    "DATASET_PATH, MODEL_PATH, MODEL_CLASS, ARCH, CD = ret\n",
    "ret = classifier_helpers.load_classifier(MODEL_PATH, MODEL_CLASS, ARCH,\n",
    "                            DATASET_NAME, LAYERNUM) \n",
    "edited_model, edited_context_model, edited_target_model = ret[:3]\n",
    "edited_state_dict = torch.load('edited_checkpoints/vehicles_on_snow/imagenet_vgg.pt.best')\n",
    "edited_model.load_state_dict(edited_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 779/school bus | Accuracy: 77.27\n",
      "Class: 670/motor scooter, scooter | Accuracy: 42.86\n",
      "Class: 920/traffic light, traffic signal, stoplight | Accuracy: 77.78\n",
      "Class: 555/fire engine, fire truck | Accuracy: 85.00\n",
      "Class: 847/tank, army tank, armored combat vehicle, armoured combat vehicle | Accuracy: 52.94\n",
      "Class: 751/racer, race car, racing car | Accuracy: 85.00\n",
      "Class: 479/car wheel | Accuracy: 45.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1563/1563 [02:31<00:00, 10.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run on test set first to verify #'s\n",
    "quick_predict_with_bump(\n",
    "    bump_amounts=np.zeros(n_classes),\n",
    "    data=test_data,\n",
    "    model=edited_model,\n",
    "    debug=True)\n",
    "# Run edited model on the ImageNet validation set\n",
    "edited_log = predict_with_bump(\n",
    "    data_loader=val_loader,\n",
    "    model=edited_model,\n",
    "    loss_fn=None,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device,\n",
    "    # target_class_idx=0,\n",
    "    bump_amounts=np.zeros(n_classes),\n",
    "    output_save_path=None,\n",
    "    log_save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 1000])\n",
      "Metric: [Pre] -> [Logit Bumped] / [Edited]\n",
      "Overall accuracy: 0.7373 -> 0.7365 / 0.7348\n",
      "Examining per class metrics for snowmobile (802)\n",
      "accuracy: 0.9997 -> 0.9999 / 0.9998\n",
      "precision: 0.8246 -> 0.9388 / 0.8704\n",
      "---***---\n",
      "Examining per class metrics for racer, race car, racing car (751)\n",
      "accuracy: 0.9992 -> 0.9981 / 0.9992\n",
      "precision: 0.5616 -> 0.3258 / 0.5634\n",
      "---***---\n",
      "Examining per class metrics for snowplow, snowplough (803)\n",
      "accuracy: 0.9996 -> 0.9997 / 0.9997\n",
      "precision: 0.7667 -> 0.8936 / 0.8036\n",
      "---***---\n",
      "Examining per class metrics for motor scooter, scooter (670)\n",
      "accuracy: 0.9997 -> 0.9997 / 0.9997\n",
      "precision: 0.8571 -> 0.9048 / 0.8400\n",
      "---***---\n",
      "Examining per class metrics for school bus (779)\n",
      "accuracy: 0.9997 -> 0.9997 / 0.9997\n",
      "precision: 0.8491 -> 0.7931 / 0.8491\n",
      "---***---\n",
      "Examining per class metrics for dalmatian, coach dog, carriage dog (251)\n",
      "accuracy: 0.9999 -> 0.9998 / 0.9998\n",
      "precision: 0.9074 -> 0.8305 / 0.8596\n",
      "---***---\n",
      "Examining per class metrics for fire engine, fire truck (555)\n",
      "accuracy: 0.9996 -> 0.9997 / 0.9997\n",
      "precision: 0.8636 -> 0.9231 / 0.8837\n",
      "---***---\n",
      "Examining per class metrics for trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi (867)\n",
      "accuracy: 0.9995 -> 0.9991 / 0.9994\n",
      "precision: 0.6949 -> 0.5385 / 0.6721\n",
      "---***---\n",
      "Examining per class metrics for tractor (866)\n",
      "accuracy: 0.9994 -> 0.9992 / 0.9995\n",
      "precision: 0.6833 -> 0.5679 / 0.7018\n",
      "---***---\n",
      "Examining per class metrics for amphibian, amphibious vehicle (408)\n",
      "accuracy: 0.9995 -> 0.9996 / 0.9995\n",
      "precision: 0.8293 -> 0.8919 / 0.8462\n",
      "---***---\n",
      "Examining per class metrics for car wheel (479)\n",
      "accuracy: 0.9992 -> 0.9992 / 0.9992\n",
      "precision: 0.6667 -> 0.6923 / 0.6429\n",
      "---***---\n",
      "Examining per class metrics for traffic light, traffic signal, stoplight (920)\n",
      "accuracy: 0.9996 -> 0.9993 / 0.9996\n",
      "precision: 0.7544 -> 0.6027 / 0.7414\n",
      "---***---\n",
      "Examining per class metrics for moped (665)\n",
      "accuracy: 0.9995 -> 0.9993 / 0.9995\n",
      "precision: 0.8611 -> 0.6545 / 0.8824\n",
      "---***---\n",
      "Examining per class metrics for tank, army tank, armored combat vehicle, armoured combat vehicle (847)\n",
      "accuracy: 0.9995 -> 0.9995 / 0.9995\n",
      "precision: 0.7069 -> 0.7000 / 0.7069\n",
      "---***---\n"
     ]
    }
   ],
   "source": [
    "edited_metrics = edited_log['metrics']\n",
    "print(\"Metric: [Pre] -> [Logit Bumped] / [Edited]\")\n",
    "print(\"Overall accuracy: {:.4f} -> {:.4f} / {:.4f}\".format(\n",
    "    pre_metrics['accuracy'], \n",
    "    post_metrics['accuracy'],\n",
    "    edited_metrics['accuracy']))\n",
    "\n",
    "for selected_class in selected_classes:\n",
    "    print(\"Examining per class metrics for {} ({})\".format(CD[selected_class], selected_class))\n",
    "    print(\"accuracy: {:.4f} -> {:.4f} / {:.4f}\".format(\n",
    "        pre_metrics['per_class_accuracy'][selected_class],\n",
    "        post_metrics['per_class_accuracy'][selected_class],\n",
    "        edited_metrics['per_class_accuracy'][selected_class]))\n",
    "    # print(\"recall: {:.4f} -> {:.4f} / {:.4f}\".format(\n",
    "    #     pre_metrics['recall'][selected_class],\n",
    "    #     post_metrics['recall'][selected_class],\n",
    "    #     edited_metrics['recall'][selected_class]))\n",
    "    print(\"precision: {:.4f} -> {:.4f} / {:.4f}\".format(\n",
    "        pre_metrics['precision'][selected_class],\n",
    "        post_metrics['precision'][selected_class],\n",
    "        edited_metrics['precision'][selected_class]))\n",
    "    print(\"---***---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(restore_dir, 'original_imagenet_vgg.pt.best'))\n",
    "torch.save(accumulated_bump_amounts, os.path.join(restore_dir, 'logit_calibration.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_val_results = {\n",
    "    'original': pre_log,\n",
    "    'edit': edited_log,\n",
    "    'calibrated': post_log\n",
    "}\n",
    "\n",
    "torch.save(imagenet_val_results, os.path.join(restore_dir, 'imagenet_val_results.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
