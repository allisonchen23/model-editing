{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build HTML file to visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from airium import Airium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists, ensure_dir\n",
    "from utils.df_utils import load_and_preprocess_csv, get_sorted_idxs\n",
    "from utils.html_utils import save_visualizations_separately, build_html\n",
    "from utils.visualizations import bar_graph\n",
    "from parse_config import ConfigParser\n",
    "from data_loader import data_loaders\n",
    "import model.model as module_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "results_timestamp = '0125_114341'\n",
    "target_class = 'cat'\n",
    "n_select = '50'\n",
    "paths_timestamp = '0125_112421'\n",
    "data_type = 'softmax'\n",
    "sort_columns = ['Post Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID Regex\n",
    "id_regex = '/+[a-z0-9_]*\\-[a-z0-9_]*\\-[a-z0-9_]*/.*/'\n",
    "# Constant paths\n",
    "class_list_path = os.path.join('metadata', 'cinic-10', 'class_names.txt')\n",
    "# Results paths\n",
    "results_dir = os.path.join('saved', 'edit', 'trials', 'CINIC10_ImageNet-VGG_16', results_timestamp)\n",
    "csv_path = os.path.join(results_dir, 'results_table.csv')\n",
    "trial_paths_path = os.path.join(results_dir, 'trial_paths.txt')\n",
    "\n",
    "paths_dir = os.path.join('paths', 'edits', 'semantics', \n",
    "                         '{}_{}'.format(target_class, n_select), \n",
    "                         paths_timestamp)\n",
    "value_image_paths_path = os.path.join(paths_dir, 'value_images_{}.txt'.format(data_type))\n",
    "\n",
    "# HTML file directories\n",
    "html_save_dir = os.path.join('html', '{}_{}'.format(target_class, n_select))\n",
    "html_assets_dir = os.path.join(html_save_dir, 'assets')\n",
    "ensure_dir(html_assets_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class list\n",
    "class_list = read_lists(class_list_path)\n",
    "# Load CSV and paths\n",
    "df = load_and_preprocess_csv(\n",
    "    csv_path,\n",
    "    drop_duplicates=['ID'])\n",
    "\n",
    "value_image_paths = read_lists(value_image_paths_path)\n",
    "trial_paths = read_lists(trial_paths_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "67 rows in paths; 27 rows in data frame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sanity check same number of rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value_image_paths) \u001b[38;5;241m==\u001b[39m n_rows, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m rows in paths; \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m rows in data frame\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(value_image_paths), n_rows)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Sanity check that each row corresponds to one another\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_id, value_image_path, trial_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], value_image_paths, trial_paths):\n",
      "\u001b[0;31mAssertionError\u001b[0m: 67 rows in paths; 27 rows in data frame"
     ]
    }
   ],
   "source": [
    "# Sanity check same number of rows\n",
    "n_rows = len(df)\n",
    "assert len(value_image_paths) == n_rows, \"{} rows in paths; {} rows in data frame\".format(len(value_image_paths), n_rows)\n",
    "\n",
    "# Sanity check that each row corresponds to one another\n",
    "for image_id, value_image_path, trial_path in zip(df['ID'], value_image_paths, trial_paths):\n",
    "    image_id = image_id.split('/')\n",
    "    for id_part in image_id:\n",
    "        assert id_part in value_image_path\n",
    "        assert id_part in trial_path\n",
    "\n",
    "# Check columns in sort_columns are in dataframe\n",
    "for column in sort_columns:\n",
    "    assert column in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted idxs based on sort columns\n",
    "sorted_df, sorted_idxs = get_sorted_idxs(\n",
    "    df=df,\n",
    "    columns=sort_columns,\n",
    "    increasing=False)\n",
    "\n",
    "# Sort image paths and trial paths accordingly\n",
    "sorted_value_image_paths = [value_image_paths[idx] for idx in sorted_idxs]\n",
    "sorted_trial_paths = [trial_paths[idx] for idx in sorted_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics for each data point as string\n",
    "sorted_df = sorted_df.round(3)\n",
    "metrics = ['Recall', 'Precision', 'F1']\n",
    "groups = ['Mean', 'Target', 'Orig Pred']\n",
    "metric_strings = []\n",
    "for idx in range(n_rows):\n",
    "    metric_string = ''\n",
    "    key = 'Post Accuracy'\n",
    "    metric_string += \"Accuracy: {}\".format(sorted_df[key].iloc[idx])\n",
    "\n",
    "    for group in groups:\n",
    "        metric_string += \"\\n{}\".format(group)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            key = 'Post {} {}'.format(group, metric)\n",
    "            metric_string += \"\\n\\t{:<15} {}\".format(metric, sorted_df[key].iloc[idx])\n",
    "\n",
    "    metric_strings.append(metric_string)\n",
    "assert len(metric_strings) == n_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paths to all things we want to visualize: \n",
    "\n",
    "1) cumulative masking graphic\n",
    "2) cumulative masking graph\n",
    "3) class distribution pre/post edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files from segmentation process\n",
    "file_names = [\n",
    "    '{}_cumulative_modifying.png'.format(data_type),\n",
    "    'target_{}_v_n_images.png'.format(data_type)]\n",
    "input_dirs = [os.path.dirname(path) for path in sorted_value_image_paths]\n",
    "html_asset_save_dirs, save_id_paths = save_visualizations_separately(\n",
    "    input_dirs=input_dirs,\n",
    "    file_names=file_names,\n",
    "    output_dir=html_assets_dir,\n",
    "    overwrite=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create class distribution bar graphs per row\n",
    "columns = ['Pre Class Dist', 'Post Class Dist']\n",
    "bar_graph_save_paths = []\n",
    "for idx, (trial_dir, html_asset_save_dir) in enumerate(zip(sorted_trial_paths, html_asset_save_dirs)):\n",
    "    image_id = os.path.join(os.path.basename(os.path.dirname(html_asset_save_dir)),\n",
    "                            os.path.basename(html_asset_save_dir))\n",
    "    assert image_id in trial_dir\n",
    "    \n",
    "    data = []\n",
    "    for column in columns:\n",
    "        data.append(sorted_df.iloc[idx][column])\n",
    "    data = np.stack(data, axis=0)\n",
    "    \n",
    "    bar_graph_save_path = os.path.join(html_asset_save_dir, 'class_distribution_bar_graph.png')\n",
    "    bar_graph_save_paths.append(bar_graph_save_path)\n",
    "    \n",
    "    bar_graph(\n",
    "        data=data,\n",
    "        labels=class_list,\n",
    "        groups=columns,\n",
    "        title='Class Distribution for {}'.format(image_id),\n",
    "        xlabel_rotation=30,\n",
    "        ylabel='Counts',\n",
    "        save_path=bar_graph_save_path,\n",
    "        show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the paths \n",
    "image_ids, save_visualization_paths = save_id_paths\n",
    "\n",
    "asset_paths = save_visualization_paths + bar_graph_save_paths\n",
    "asset_paths = sorted(asset_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HTML file to html/dog_50/visualization.html\n"
     ]
    }
   ],
   "source": [
    "html_save_path = os.path.join(html_save_dir, 'visualization.html')\n",
    "html_string = build_html(\n",
    "    asset_paths,\n",
    "    html_save_path=html_save_path)           \n",
    "\n",
    "with open(html_save_path, 'wb') as f:\n",
    "    f.write(bytes(html_string, encoding='utf-8'))\n",
    "print(\"Saved HTML file to {}\".format(html_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cat-train-n01322898_3222/felzenszwalb_gaussian/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = 'html/cat_50/assets/cat-train-n01322898_3222/felzenszwalb_gaussian/class_distribution_bar_graph.png'\n",
    "found = re.search('/+[a-z0-9_]*\\-[a-z0-9_]*\\-[a-z0-9_]*/.*/', string).group()\n",
    "print(found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
