{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide list of paths for edits and run trials -> (maybe analyze results and add to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, 'src')\n",
    "from utils import read_json, read_lists, informal_log, list_to_dict, write_lists, write_json\n",
    "from utils.model_utils import prepare_device\n",
    "from parse_config import ConfigParser\n",
    "# from data_loader import data_loaders\n",
    "import datasets.datasets as module_data\n",
    "import model.model as module_arch\n",
    "from utils.knn_utils import load_and_analyze_knn\n",
    "from utils.results_to_csv import combine_results\n",
    "from edit_knn import main as edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain timestamp\n",
    "timestamp = datetime.now().strftime(r'%m%d_%H%M%S')\n",
    "# timestamp = '0120_155829'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 edit image pairs\n",
      "First key image path: data/cinic-10-imagenet/train/cat/n02123159_5240.png\n",
      "First value image path: saved/segmentations/semantics/cat_50/cat-train-n02123159_5240/felzenszwalb_masked/felzenszwalb_masked_softmax.png\n"
     ]
    }
   ],
   "source": [
    "# Define constants, paths\n",
    "config_path = 'configs/copies/cinic10_imagenet_segmentation_edit_trials.json'\n",
    "class_list_path = 'metadata/cinic-10/class_names.txt'\n",
    "# key_image_id = 'dog-train-n02114712_211'\n",
    "target_class_name = 'cat'\n",
    "\n",
    "analyze_in_edit = True\n",
    "# paths_dir = os.path.join('paths', 'edits', key_image_id)\n",
    "# paths_dir = os.path.join('paths', 'edits', target_class_name, '0113_120339')\n",
    "paths_dir = os.path.join('paths', 'edits', 'semantics', target_class_name, '0125_112421')\n",
    "\n",
    "# key_image_paths = read_lists(os.path.join(paths_dir, 'key_images.txt'))\n",
    "# value_image_paths = read_lists(os.path.join(paths_dir, 'value_images.txt'))\n",
    "sort_type = 'softmax'\n",
    "key_image_paths = read_lists(os.path.join(paths_dir, 'key_images_{}.txt'.format(sort_type)))\n",
    "value_image_paths = read_lists(os.path.join(paths_dir, 'value_images_{}.txt'.format(sort_type)))\n",
    "n_trials = len(value_image_paths)\n",
    "assert len(key_image_paths) == n_trials\n",
    "\n",
    "print(\"{} edit image pairs\".format(n_trials))\n",
    "print(\"First key image path: {}\".format(key_image_paths[0]))\n",
    "print(\"First value image path: {}\".format(value_image_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_dict = read_json(config_path)\n",
    "# Load class list and obtain target class idx\n",
    "class_list = read_lists(class_list_path)\n",
    "class_idx_dict = list_to_dict(class_list)\n",
    "target_class_idx = class_idx_dict[target_class_name]\n",
    "\n",
    "# Set K\n",
    "K = config_dict['editor']['K']\n",
    "\n",
    "device, device_ids = prepare_device(config_dict['n_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_loader_args = dict(config_dict[\"data_loader\"][\"args\"])\n",
    "dataset_args = dict(config_dict[\"dataset_args\"])\n",
    "\n",
    "# Create validation data loader\n",
    "val_image_paths = read_lists(config_dict['dataset_paths']['valid_images'])\n",
    "val_labels = read_lists(config_dict['dataset_paths']['valid_labels'])\n",
    "val_paths_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=val_image_paths,\n",
    "        labels=val_labels,\n",
    "        return_paths=True,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")\n",
    "\n",
    "# Create data loader for covariance matrix\n",
    "covariance_image_paths = read_lists(config_dict['covariance_dataset']['images'])\n",
    "covariance_labels = read_lists(config_dict['covariance_dataset']['labels'])\n",
    "\n",
    "covariance_data_loader = torch.utils.data.DataLoader(\n",
    "    module_data.CINIC10Dataset(\n",
    "        data_dir=\"\",\n",
    "        image_paths=covariance_image_paths,\n",
    "        labels=covariance_labels,\n",
    "        **dataset_args\n",
    "    ),\n",
    "    **data_loader_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log and save paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving path to directories for each trial to saved/edit/trials/CINIC10_ImageNet-VGG_16/0125_114341/trial_paths.txt\n",
      "Printing progress reports to saved/edit/trials/CINIC10_ImageNet-VGG_16/0125_114341/progress_report.txt\n"
     ]
    }
   ],
   "source": [
    "# create log path to store the paths to each trial\n",
    "save_root = config_dict['trainer']['save_dir']\n",
    "save_trials_path = os.path.join(save_root, config_dict['name'], timestamp, 'trial_paths.txt')\n",
    "progress_report_path = os.path.join(save_root, config_dict['name'], timestamp, 'progress_report.txt')\n",
    "if os.path.exists(save_trials_path):\n",
    "    # os.remove(save_trials_path)\n",
    "    print(\"Path {} already exists. Aborting.\".format(save_trials_path))\n",
    "else:\n",
    "    # progress_report_path = os.path.join(save_root, config_dict['name'], timestamp, 'progress_report.txt')\n",
    "    if os.path.exists(progress_report_path):\n",
    "        os.remove(progress_report_path)\n",
    "    print(\"Saving path to directories for each trial to {}\".format(save_trials_path))\n",
    "    print(\"Printing progress reports to {}\".format(progress_report_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure all paths for keys and values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_existent_key_paths = []\n",
    "non_existent_value_paths = []\n",
    "for key_path, value_path in zip(key_image_paths, value_image_paths):\n",
    "    if not os.path.exists(key_path):\n",
    "        non_existent_key_paths.append(key_path)\n",
    "    if not os.path.exists(value_path):\n",
    "        non_existent_value_paths.append(value_path)\n",
    "\n",
    "if len(non_existent_key_paths) > 0:\n",
    "    raise ValueError(\"Following paths are non existent: {}\".format(non_existent_key_paths))\n",
    "    \n",
    "if len(non_existent_value_paths) > 0:\n",
    "    raise ValueError(\"Following paths are non existent: {}\".format(non_existent_value_paths))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run edit for each modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0125_114456) Starting Trial 1/67...\n",
      "Current run_id: 0125_114341/results/cat-train-n02123159_5240/felzenszwalb_masked_softmax\n",
      "saved/edit/trials/CINIC10_ImageNet-VGG_16/0125_114341/results/cat-train-n02123159_5240/felzenszwalb_masked_softmax\n",
      "Calling edit()...\n",
      "Created CIFAR10PretrainedModelEdit model with 33646666 trainable parameters\n",
      "Restored weights from external_code/PyTorch_CIFAR10/cifar10_models/state_dicts/vgg16_bn.pt\n",
      "Using passed in data loader for validation.\n",
      "Key images: data/cinic-10-imagenet/train/cat/n02123159_5240.png\n",
      "Value images: saved/segmentations/semantics/cat_50/cat-train-n02123159_5240/felzenszwalb_masked/felzenszwalb_masked_softmax.png\n",
      "Masks: None\n",
      "Prepared data for editing\n",
      "Performing pre-edit metric & KNN calculations on validation set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████▋             | 221/274 [00:49<00:13,  3.97it/s]"
     ]
    }
   ],
   "source": [
    "for idx, (key_path, value_path) in enumerate(zip(key_image_paths, value_image_paths)):\n",
    "    split = os.path.basename(os.path.dirname(os.path.dirname(key_path)))\n",
    "    class_name = os.path.basename(os.path.dirname(key_path))\n",
    "    file_name = os.path.basename(key_path).split(\".\")[0]\n",
    "    key_image_id = \"{}-{}-{}\".format(class_name, split, file_name)\n",
    "    # Print Progress\n",
    "    informal_log(\"({}) Starting Trial {}/{}...\".format(datetime.now().strftime(r'%m%d_%H%M%S'), idx + 1, n_trials), progress_report_path)\n",
    "    \n",
    "    # Create run id \n",
    "    value_image_id = os.path.splitext(os.path.basename(value_path))[0]\n",
    "    run_id = os.path.join(timestamp, 'results', key_image_id, value_image_id)\n",
    "    informal_log(\"Current run_id: {}\".format(run_id), progress_report_path)\n",
    "    \n",
    "    # Read config file as json and make updates to key and value paths\n",
    "    config_dict = read_json(config_path)\n",
    "    config_dict['editor'].update({\n",
    "        'key_paths_file': key_path,\n",
    "        'value_paths_file': value_path\n",
    "    })\n",
    "    \n",
    "    # Create config object\n",
    "    config = ConfigParser(config_dict, run_id=run_id)\n",
    "    \n",
    "    # Log the current trial path\n",
    "    informal_log(os.path.dirname(config.save_dir), save_trials_path)\n",
    "    \n",
    "    informal_log(\"Calling edit()...\", progress_report_path)\n",
    "    \n",
    "    edit(\n",
    "        config=config,\n",
    "        val_paths_data_loader=val_paths_data_loader,\n",
    "        covariance_data_loader=covariance_data_loader,\n",
    "        do_analyze_knn=analyze_in_edit)\n",
    "    \n",
    "    # Print progress\n",
    "    informal_log(\"Finished trial {}/{}. Results saved to {}\".format(idx + 1, n_trials, os.path.dirname(config.save_dir)),\n",
    "                progress_report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trials_path = 'saved/edit/trials/CINIC10_ImageNet-VGG_16/0113_160154/trial_paths.txt'\n",
    "trial_dirs = read_lists(save_trials_path)\n",
    "knn_analysis_filename = 'knn_analysis_results.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining trial paths from saved/edit/trials/CINIC10_ImageNet-VGG_16/0113_160154/trial_paths.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if not os.path.exists(save_trials_path):\n",
    "        print(\"Path {} does not exist\".format(save_trials_path))\n",
    "    else:\n",
    "        print(\"Obtaining trial paths from {}\".format(save_trials_path))\n",
    "except:\n",
    "    print(\"Need to define save_trials_path.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/37 trials. Currently processing felzenszwalb_gaussian_0\n",
      "Analyzing KNN results from saved/edit/trials/CINIC10_ImageNet-VGG_16/0112_121958/dog-train-n02114712_211/felzenszwalb_gaussian_0/models\n",
      "Logging and saving visualizations to saved/edit/trials/CINIC10_ImageNet-VGG_16/0112_121958/dog-train-n02114712_211/felzenszwalb_gaussian_0/models/knn_visualizations/knn_analysis_log.txt\n",
      "Saving results to saved/edit/trials/CINIC10_ImageNet-VGG_16/0112_121958/dog-train-n02114712_211/felzenszwalb_gaussian_0/models/knn_analysis_results.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/edit/trials/CINIC10_ImageNet-VGG_16/0112_121958/dog-train-n02114712_211/felzenszwalb_gaussian_0/models/edited_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m informal_log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m trials. Currently processing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     10\u001b[0m     trial_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n_trials, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(trial_dir)), progress_report_path)\n\u001b[1;32m     12\u001b[0m results_save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(trial_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mload_and_analyze_knn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_save_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_edit_knn_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_save_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpre_edit_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m-nn.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_edit_knn_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_save_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_edit_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m-nn.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknn_analysis_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknn_analysis_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_class_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_report_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_report_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_plots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/src/utils/knn_utils.py:647\u001b[0m, in \u001b[0;36mload_and_analyze_knn\u001b[0;34m(restore_dir, pre_edit_knn_path, post_edit_knn_path, knn_analysis_filename, target_class_idx, class_list, progress_report_path, save_images, save_plots)\u001b[0m\n\u001b[1;32m    645\u001b[0m edited_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(restore_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medited_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    646\u001b[0m edited_model \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m, module_arch, layernum\u001b[38;5;241m=\u001b[39mlayernum)\n\u001b[0;32m--> 647\u001b[0m \u001b[43medited_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43medited_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# edited_context_model = edited_model.context_model\u001b[39;00m\n\u001b[1;32m    649\u001b[0m edited_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/n/fs/ac-editing/model-editing/src/base/base_model.py:62\u001b[0m, in \u001b[0;36mBaseModel.restore_model\u001b[0;34m(self, restore_path, optimizer)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, restore_path, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Restore model from the given restore_path\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m            epoch and loaded optimizer\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/editing/lib/python3.8/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/edit/trials/CINIC10_ImageNet-VGG_16/0112_121958/dog-train-n02114712_211/felzenszwalb_gaussian_0/models/edited_model.pth'"
     ]
    }
   ],
   "source": [
    "## Process KNN results for each\n",
    "n_trials = len(trial_dirs)\n",
    "n_log = n_trials // 10 + 1  # log every 10%\n",
    "progress_report_path = os.path.join(os.path.dirname(save_trials_path), 'progress_report_analysis.txt')\n",
    "\n",
    "informal_log(\"Starting KNN analysis...\", progress_report_path)\n",
    "for trial_idx, trial_dir in tqdm(enumerate(trial_dirs)):\n",
    "    # if trial_idx % n_log == 0:\n",
    "    informal_log(\"Processing {}/{} trials. Currently processing {}\".format(\n",
    "        trial_idx+1, n_trials, os.path.basename(trial_dir)), progress_report_path)\n",
    "                     \n",
    "    results_save_dir = os.path.join(trial_dir, 'models')\n",
    "    load_and_analyze_knn(\n",
    "        restore_dir=results_save_dir,\n",
    "        pre_edit_knn_path=os.path.join(results_save_dir, 'pre_edit_{}-nn.pth'.format(K)),\n",
    "        post_edit_knn_path=os.path.join(results_save_dir, 'post_edit_{}-nn.pth'.format(K)),\n",
    "        knn_analysis_filename=knn_analysis_filename,\n",
    "        target_class_idx=target_class_idx,\n",
    "        class_list=class_list,\n",
    "        progress_report_path=progress_report_path,\n",
    "        save_images=False,\n",
    "        save_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV for all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2008it [00:16, 120.03it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# Iterate through all trials\n",
    "for trial_idx, trial_dir in tqdm(enumerate(trial_dirs)):\n",
    "    # Obtain key ID from path\n",
    "    key_id = os.path.basename(os.path.dirname(trial_dir))\n",
    "    id_class = key_id.split('-')[0]\n",
    "    if id_class not in class_list:\n",
    "        raise ValueError(\"Invalid key_id {}\".format(key_id))\n",
    "    # Obtain value ID from path\n",
    "    val_id = os.path.basename(trial_dir)\n",
    "    # Join to make a data ID\n",
    "    data_id = os.path.join(key_id, val_id)\n",
    "    \n",
    "    # Load results from knn, pre-edit metrics, and post-edit metrics\n",
    "    restore_dir = os.path.join(trial_dir, 'models')\n",
    "    knn_analysis_results = torch.load(os.path.join(restore_dir, knn_analysis_filename))\n",
    "    pre_edit_metrics = torch.load(os.path.join(restore_dir, 'pre_edit_metrics.pth'))\n",
    "    post_edit_metrics = torch.load(os.path.join(restore_dir, 'post_edit_metrics.pth'))\n",
    "    \n",
    "    # Combine results into one dictionary\n",
    "    combined_results = combine_results(\n",
    "        data_id=data_id,\n",
    "        knn_analysis=knn_analysis_results,\n",
    "        pre_edit_metrics=pre_edit_metrics,\n",
    "        post_edit_metrics=post_edit_metrics)\n",
    "    \n",
    "    # Save column headers in first trial run\n",
    "    if trial_idx == 0:\n",
    "        column_headers = list(combined_results.keys())\n",
    "    # Convert results to np.array & append to list\n",
    "    combined_results = np.expand_dims(np.array(list(combined_results.values())), axis=0)\n",
    "    data.append(combined_results)\n",
    "\n",
    "# Convert data from list of np.arrays -> pd.DataFrame    \n",
    "data = np.concatenate(data, axis=0)\n",
    "df = pd.DataFrame(data, columns=column_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to saved/edit/trials/CINIC10_ImageNet-VGG_16/0113_160154/results_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "csv_save_path = os.path.join(os.path.dirname(save_trials_path), 'results_table.csv')\n",
    "df.to_csv(csv_save_path)\n",
    "print(\"Saved CSV to {}\".format(csv_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editing",
   "language": "python",
   "name": "editing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
